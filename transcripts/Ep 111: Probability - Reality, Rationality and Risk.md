# Ep 111: Probability - Reality, Rationality and Risk

Original Episode: [Ep 111: Probability - Reality, Rationality and Risk](https://www.podbean.com/site/EpisodeDownload/PB11F056AZNC7W)

Audio Download: [MP3](https://mcdn.podbean.com/mf/download/7q7j4q/Probability_-_Realism_Rationality_and_Riskawikb.mp3)

## Transcript

### 0m

Welcome to TopCast for an episode I'm titling Probability, Risk, Rationality and Reality. Now, I know this is an esoteric channel, but even for me, this is an esoteric episode. I'm not discussing a book or primarily a written piece at all. I'm discussing a video lecture, a talk by David Deutsch. It is, his TED Talks aside, perhaps my favourite of his public talks. Now, the reason I am doing this is that I just do not understand why it, this talk that I'm talking about, has not made more waves. I think it should get more traction. So, in this episode, what I am doing is providing my take on David's lecture. I emphasise that this is my take because, as I like to say, errors are my own and I expect to have made mistakes in understanding or misunderstanding what David has said in his lecture. Let me, in another... By the way, say for the third time, these are my words.

### 1m

If I directly quote David, I will say so. I don't expect to, except where I've provided a literal clip of him speaking. I might get closer sometimes to using his exact words, but I'm belabouring this point because I have added quite a bit of personally indulgent accoutrement, we might say, window dressing and emphasis, and maybe some topspin, just because I find it fun. So, in other words, this is all inspiring. Inspired by David's talk, I certainly cannot say endorsed by him in any way. If you want David's words, go directly to his lecture and double check there that what I say is representing what he says before, I don't know, you decide to start tweeting or emailing him. Dear Professor Deutsch, I heard Brett Hall claim that you claim... and so on. Okay, we don't want that. I am making no such claims. I am summarising ideas and my summary is my own. Not David's. So, blame me for the mistakes. Now, I'm also going to augment what I am saying here today with primarily a paper called The Constructor Theory of Probability by Chiara Marletto.

### 2m

Now, why am I bothering with all this? Well, the main reason is, the main reason I do any of this, just because I want to, I find it fun to try and understand these ideas more deeply, because at first they are always counterintuitive. And then, after spending some time trying to understand them, rather than thinking, well, that can't work. Well, that contradicts what I've known since primary school, so I'll just reject that outright, and so on. After taking the time to really digest ideas like this one that I'm going to present today, and meditate on these ideas, so to speak, you end up thinking, how could it be otherwise? This is one of those cases, and that process is fun. So, that's the first reason I'm doing any of this. The second reason is that, as some listeners are aware, I'm in the midst of completing a series on Steven Pinker's book called... Now, in that book, he devotes entire chapters to probability.

### 3m

Basically, half the book is devoted to trying to explain how important probability theory is to rationality. Chapter 4 is called Probability and Randomness. Chapter 5, Beliefs and Evidence, subtitled Bayesian Reasoning, which is just probability as applied to a false epistemology. And Chapter 6 is Risk and Reward, more probability. And Chapter 7 is Decision Theory, using probability, among other things, to make decisions. Chapter 9 is Correlation and Causation, which is all couched in terms of, you guessed it, statistics and probability. Now, I'm not just fixated on Steven Pinker. Pinker, as a thinker, is not the issue. It is what his book, Rationality, represents. It is emblematic of the, can I underline, boldface, and italicize that, the way in which rationality, how to think, how to reason, is seen by academia. It is how people are schooled in this, insofar as they take an interest. The book represents that worldview.

### 4m

I'm interested in misconceptions of that worldview. Misconceptions of that kind that Pinker explains. The ones that are so deeply a part of culture, they are formalized into causes and passed on generation after generation. Now, admittedly, there is an asymmetry lurking here. A book like Rationality is summarizing what is the inherited wisdom, false though it is in places, of the expert class. It is not trying to illuminate a new and better way. The work of David Deutsch, on the other hand, is trying to do something different. It is, what I would say, the cutting edge of reason and science. So it is unsurprising there is conflict in places. Or sometimes just tension. In my series on Pinker's book, I should emphasize, I'm not doing much more than encouraging people to purchase it. I think it is worth the price. There is good stuff in there. But equally, there are misconceptions. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand.

### 5m

And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. And those misconceptions are indeed misconceptions which only a small number of people understand. thinking about rationality better than what is explained in that book titled Rationality. Because what we're going to talk about today is new, very new, and to begin to understand it takes our best epistemology as well as our best physics. In short, it takes us taking realism seriously. We want to know what reality is really like. We don't just want to make use of useful fictions as instruments to help us predict stuff. Sure, sometimes that is useful. The ideal gas law used in chemistry and physics fails for many reasons, but among other things it assumes, let's say, molecules have no forces between them. But as a rough and ready estimate, it will do in many situations. It's better than a random guess. But it doesn't represent reality, what is really going on with gases. Gases aren't ideal, so too with probability as we're about to find out. Similarly,

### 6m

any calculation involving classical mechanics of the relative velocity of two objects, by ignoring them, is not ideal. Or any calculation of the distance to a star that doesn't involve parallax. These things are only approximations to reality, rather than trying to provide a literal explanation of reality, our best understanding of reality at a particular time. Science is, of course, replete with useful fictions, but none of them are good explanations once we know where exactly they're false. They are not literal accounts of reality. We know they are false, and how they are false. In science, we basically have once good explanations, now known to be false, and explanations yet to be shown false. As always, by way of illustration on that, I'm going to use Newtonian gravity in the former category, a once upon a time good explanation, but which we now know to be false. And in the latter category, we have

### 7m

general relativity, a good explanation of gravity, of space and time, yet to be shown false. And that brings us today to probability. Probability purports to be a scientific theory of a kind. It seeks to explain what is going on in the real, physical world. So you take a so-called fair coin, and you toss it, and the probability it comes up heads is, so we are told, 1 in 2, 50%. That's the science of coin tosses. 50% of the time it will be heads, and 50% of the time it will be tails, in the real world. Except, of course, it also comes up heads. And that's the theory. It almost never is. Just try it yourself. Try a large number of coin tosses, more than 100. It only approximately is 1 in 2. It's only approximately 50% of the time, exactly 50% heads. Indeed, tossing a real coin a thousand times, one should not expect precisely 500 heads, only approximately 500 heads. But why? Well, so the theory goes, if you

### 8m

could toss it an infinite number of times, then in the limit, which is the limit, you are told, the number of heads would approach 50%. But then we've left the real world. We've left science. Because we can't toss a coin an infinite number of times. Infinite coin tosses are not science. Actual scientific theories, actual theories of physics, purport to be actual explanations of the real world, of what happens in the physical world. The world being everything in physical existence. But if the actual explanation almost never accurately models what is going on, then what is going on? Well, some might argue it's true a priori. It's an idealised mathematical model. Well, once more, that's not physics exactly, then is it? It's pure mathematics. Again, what is going on if not the precise probabilities suggested by the probability calculus for something as simple as a coin toss? Well,

### 9m

we'll get there, don't worry. But before we do, just a few more remarks about probability and mathematics generally in terms of the real world. In the general educated populace, mathematical ability, or knowledge, or whatever you want to call it, serves as a proxy for intelligence rather often. According to some, anyway. But in academia itself, this often isn't enough. You do see what appears to be an academic litmus test used on fellow members of the intelligentsia, and that litmus test isn't as broad as mathematical proficiency in general. It's statistics and probability. And that's what we're going to discuss today. It's not how good were your calculus scores, or how far along in geometry did you get? Have you completed any topology courses yet? No, the measure of mathematical proficiency often is probability and statistics. You see it, iconoclasts, on social media. Twitter is where I notice it most obviously. One great mind berating another for not knowing

### 10m

enough probability, or not having a good enough grip of it, or having bad intuitions on that front. The probability front. And haven't we all felt chastised at some point or another by some media outlet where each time a terror attack happens, some pundit has to point out, you've more chance of being hit by lightning than by being blown up by a jihadist bomb. We all just have bad intuitions about risk, we are told. Of course, never mind that terrorist bombs going off have behind them sets of bad ideas, while lightning strikes are not so motivated. There's the matter of intent to contend with, and intent, can be changed, which makes a world of difference in these cases. They are not the same kind of thing, because mitigating them does not come down to the same kind of thing, precisely. So of course, that talk of comparative risk, when it comes to terror incidents versus plain old tragic accidents, is to avoid any discussion about the causes and perpetrators of terror

### 11m

attacks. Motivated reasoning, some might call it, or holding certain ideas immune from criticism, others might say. And just on that note, thank you so much for watching this video, and I'll see you next time. Thank you for watching, and I'll see you next time. Thank you for watching, and I'll see you next time.

### 12m

Thank you for watching, and I'll see you next time. Thank you for watching, and I'll see you next time.

### 13m

apply it to the real physical world. So we're going to take that claim seriously. Can we do it? Can we apply probability to the real world and get accurate predictions? And to what extent? This is what David's talk is about. You can find it online by searching YouTube with the keywords David Deutsch probability. It should come up. Now the talk is called physics without probability, but I've always found that a little misleading because it is far more wide ranging than that. I'll link to the talk itself in the descriptions of this podcast. And I accept it's quite fair to ask if that talk's already out there, why am I talking about a talk? Well, again, just to unpack these very new ideas in a slightly different language, and maybe it will inspire some to go to the original source material, which is very much worth the time. So let's begin. And throughout this unpacking of David's talk, I'm going to be stealing with his permission, the slides that

### 14m

were used in his talk. David Deutsch, as listeners will know, as almost all listeners will know, is a pioneer in quantum information theory. He's interested in drilling down to the foundations of what we know. What are the absolute fundamentals that underlie everything else? There's an irony here because David Deutsch is simultaneously someone who denies there are actual foundations. So he's looking at foundations and denying they are there. Well, not quite. What this all means is that he looks at the deepest knowledge we have so far. And he's looking at the foundations of what we know. And he's looking at the deepest knowledge we have so far. And he tries to go deeper. He just does not think like so many others who work in this area or people who are interested in the philosophy of this, that once you have found the deepest knowledge hitherto, that this is where progress stops. It's rather the opposite. Anywhere at all is a place to make progress. And he chooses digging ever deeper beneath what we already know. Quantum computation goes further than regular quantum theory. It goes

### 15m

deeper. It goes deeper than quantum theory. It goes deeper than regular quantum theory. It goes deeper than regular quantum theory. It goes deeper than regular quantum theory. It goes deeper than quantum computation. And now David has generalized, gone deeper than quantum computation, the field that he began by creating constructor theory, creating or discovering, if you like. His theory of physics, constructor theory, goes beyond laws and initial conditions, the way physics until now has always been done. And the consequence of constructor theory is the notion that things either can happen or cannot happen. They do not probably happen. We'll keep coming back to this very notion. But the point for now is that constructor theory showed that probability can be removed from our vision of reality. This is not all it does, but for our purposes today, that is what it does do. Constructor theory, as David says, is a mode of explanation, a new mode of explanation. Probability is a mode of explanation. The initial conditions and laws of physics are a mode of

### 16m

explanation. David lists more here on this slide. These modes of explanations are, ways of understanding the world, ways of explaining things. The initial conditions and laws of motion thing is where you have some dynamical law and you plug in certain conditions. They could be the conditions at the beginning of time, the conditions at some time X, or the conditions sometime in the future. And you can post-dict or predict what is going to happen. The other ones listed there include things like, well, emergent laws, the laws of thermodynamics. We've got things there like variation and selection. In other words, evolutionary principle, the theory of evolution. And by natural selection, Darwinism. Anthropic selection, this idea that human beings exist, so therefore what follows about the universe, especially the laws of the universe. Or we could explain things in terms of human creativity. In other words, what happens out there in reality is due to people making choices, people creating stuff, people coming to generate knowledge, particularly explanatory knowledge. So these are the modes of explanation that David refers to.

### 17m

And they are ways of explaining what happens in the world. Each of them purport to be about reality. Actually, what's physically going on and why? So today we're looking carefully at what's in red there. Can things in reality be predicted? Which in this case includes explained by recourse to probability. We are taking this seriously and literally as a description of reality, as proponents of probability often do. And by the way, constructor theory seeks to go down the line of probability. It will see any of them, to the extent they are valid at all, to be approximations to it, but false in the final analysis. It will explain why they, superficially perhaps, appear to be plausible, why they appear to work in some narrow domain, and why they end up failing. Explanation in the constructor theoretic mode is via the dichotomy between transformations

### 18m

that are either possible or impossible. And we can see here the slide of the Great Great First Principle of Constructor Theory, which says all other laws of physics are expressible entirely in terms of statements about which physical state but it will happen with non-zero probability, end quote. An approximation is not a literal description of reality. It is closer to a metaphor. Newtonian mechanics, we know, is no longer an actual description of reality. There is no force of gravity. There is no action at a distance. There is no universal time ticking away for all of the universe. Some of the very things, therefore, referred to as existing by that theory don't exist.

### 19m

At best, Newton's mechanics is a low-velocity, low-mass approximation that can provide a much better-than-random-guess estimation of some physical quantities under some conditions, some of the time, useful for building houses and aiming rockets and so on. But as soon as you're near a massive star or moving closer to the speed of light, operating particle accelerators and so on, it fails to work. Only relativity or, in other circumstances, quantum theory provide the actual answer without correction in physics, because we can take them, literally, as descriptions of reality. And as far as we know, they are. But probability is not like relativity or quantum theory. It is not accurate to the limits of our measuring devices. It does not survive all tests. We've already seen that. Real-life experiments with flipping coins or rolling dice almost never match what the probability calculus says. They only approximately do. But if that's not a falsification, then, by that measure,

### 20m

Eddington's test failed to falsify Newtonian mechanics. But if that's not a falsification, then, by that measure, Eddington's test failed to falsify Newtonian mechanics. Of course, in that case, we had two theories to choose between. Here, what are our choices? Well, the choices are rationality, which includes relying on quantum theory, as it realistically is, where we discuss what actually happens in reality, and, apparently, probability, which is more about all those things that might have happened in reality, but did not, and the tiny proportion of things that did happen, which is overkill when you think about it. Probability is at best an approximation, although an approximation to probability. Probability is an approximation to probability. Probability is an approximation to probability. Probability is at best an approximation, although an approximation to what happens. Probability is at best an approximation, what we might wonder. In short, there is no place for probability at the foundations of physics. And as David says in his talk, he doesn't make the case against probability from constructor theory. He doesn't need to, because independent of constructor theory, the world is not probabilistic. That's just an illusion. Probability theory is like the flat earth theory. It's useful, perhaps, for gardening. But if you are thinking about what the laws of nature are, then false theories are an

### 21m

impediment to understanding reality. Let's pause there for a moment, reflect, and say that all over again. If you are thinking about what the laws of nature are, then false theories are an impediment to understanding reality. Probability was invented by people in the 16th century, like Cardano, who wanted to win in games of chance. And this began the mathematical field, known as game theory. Probability is supposed to be a mathematical model for the intuitive idea that certain things are fair, like dice and card shuffling and so on. But the originators of that theory did not think the physical objects literally had the properties of fairness and literal randomness. They seemed to understand that the perfect idealization of dice and card shuffling were not like actual physical dice and card shuffling. Cardano and his contemporaries were not like that. They were not like the physical dice and card shuffling. In other words, did not assume games of chance were stochastic processes. A stochastic process

### 22m

is a literally random one. One governed not by deterministic laws of nature as we usually understand them, or as they were understood at that time even. Now, this was of course before Newtonian physics, this pre-Newtonian idea being basically Aristotle's. There were deterministic laws, even if they were not well understood. Whatever the case, games of chance did not literally have the properties of fairness and literal randomness. They were not like the properties of actual randomness that the probability calculus requires. It would never have occurred to them, the creators of probability, to connect physics to probability because the former, physics, was deterministic, not random. Probability was used because, in a sense, it was too strong. It assumed literal randomness, where they thought things were perhaps seemingly only approximately so. And in that sense, probability is a mathematical trick. The reason game theory is possible at all was that its conclusions do not depend on physics in the real world in the end.

### 23m

The theory of probability, in truth, was about modelling human social behaviour of a certain kind, namely playing certain games, playing cards, rolling dice, flipping coins. These are things people do for entertainment, perhaps to earn money sometimes. They are not features of the natural environment outside human societies. This mathematical trick about human social games nonetheless has found applications in diverse fields, as if it's fundamental in them. David lists them roughly in historic order here. And throughout his talk, he just goes through one by one, redlining them, putting a red line straight through them, as he refutes the use of probability in each of them, when taken seriously as a literal description of reality. So what we've got there is probability apparently being used in the theory of experimental errors. This is basically experimental errors in, in, in, in, in, in, in, in, in, in, in, in, in, in, in, in, come down to two kinds, systematic and random. I'll come back to those towards the end.

### 24m

Actuarial science is listed there next. This is where we look at risk, the risk of an investment or return, or the chance of a disaster, or whether and to what extent some customer is worth insuring or lending to. And I'll come back to this idea about risk at the end and just give some remarks about this. People have asked me over the years to do an episode on how to interpret risk using a critical rationalist framework, okay? Having the idea, having Papirian epistemology, how do we think about risk? Well, I'm going to do that today, towards the end of today's episode. Biology is listed there. Evolution by random variation and natural selection. Is it truly random? Does it need to be probabilistic? Does it need to be random? The foundations of classical and quantum statistical mechanics, principles of equal a priori probability. Brownian motion. This, this was studied by Einstein in one of his first papers. It's where you have particles suspended in a liquid, for example. A colloid is one kind. And those, usually solid particles, are jostled around in the liquid by the motion of the molecules,

### 25m

usually water molecules. And that motion seems to be random. Next, we've got listed there the quantum theory, the Born rule. We're going to come to that presently. General decision theory, how to make decisions based on probability, when you think that things only probably might happen. Information theory, classical then quantum, Bayesian philosophy of science. Here's where we aim to increase our credences, which are supposedly probabilities. And last of all, the pricing of derivative securities, using the Black-Scholes equation. The attempt to try and predict what is going to happen in the stock market. The motivation for removing probability from all of those areas is just like the motivation for removing the celestial sphere from cosmology, and the force of gravity from physics, and elsewhere for that matter. In the process, we explain why it has been and remains a useful fiction. It can be useful to think of something as risky, but notice that the whole notion of risky

### 26m

often refers to something that never happens. You might put $100 through a poker machine each weekend, and it might be described as risky, regardless of whether you consistently win or not. If you win time and time again, then the word risky refers to the thing that never happened. Assertions about probabilities do not refer to the physical world. Either a thing happens or not. Saying something is likely or probable to happen, is not about the real world where things happen. They don't probably happen. They happen. And it's no good saying that because something happens frequently, that this means it is probable. Because exactly what is the probability? Exactly equal to the frequency? How do you know? Is that an axiom? Why do you say it's because it's probably the case that frequencies equal probabilities? If you toss a coin a thousand times, and it comes up heads 492 times, and tails, 508 times, that's a frequency. So do we say the probability of heads in that case is

### 27m

492 out of a thousand for the next thousand throws? So why do we say it's 1 in 2? Is it just probably 1 in 2 because it's approximately 1 in 2? Why is that the case? Is it 1 in 2 because a priori, by definition, before we do any experiments in the world, it must be 1 in 2 because the coin has two sides and it's perfectly fair. How do we know it's perfectly fair? Again, that's not science because our experiment has just refuted the claim that it was exactly 1 in 2 at all. The claim that heads has a probability of 1 in 2 is a bad explanation because it's almost never matched, and we have no good reason why it's not matched. Except that we do, on physics, actual physics, but not on probability theory. The thing is that frequencies in real life do not exactly equal the supposed ideal probabilities, and any kind of frequencies should not be expected to be exactly replicated in real life, as

### 28m

David says, so let me allow him to speak in his own words. It's no good saying that they equal them approximately because they don't. They only probably equal them approximately. Similarly, you can't say that probability statements are about what will happen in the long run. No, they aren't. All you can deduce from them are statements about what will probably happen in the long run. But frequencies in an infinite sequence of measurements, of experiments, do equal the probabilities exactly, and this inspires yet another desperate denial to the effect that the finite sequences are approximations to infinite ones. But nothing about a finite subsequence of an infinite sequence can possibly follow from a statement about relative frequencies in the infinite sequence. Unless the subsequence is a typical one.

### 29m

So probabilities only equal frequencies in theory if we have an infinite sequence. But we don't have access to infinite sequences of events like coin tosses. And any finite sequence is not equal to an infinite sequence. And we only ever have finite sequences. And how can we know any finite sequence is a typical sequence? We can't. We can only say we probably have a typical sequence. So we're going in circles. It could be that probability is merely about ignorance. Subjective ignorance. It could all just be about beliefs, for example, and a lack of knowledge in the minds of people. It could be a very parochial set of heuristics about how human minds work that reaches into the real world in some way. Okay, in some way, but what way exactly? What connects those claims about our minds to what's going on out there in the objective world? What is the rule? Apparently, this is what Bayesianism is all about, perhaps. David Lewis tried to do this through his so-called principle principle. And the principle principle from David Lewis is that rational agents conform their credences to physical probabilities. But that gives no explanation as to why rational people should or do believe it. Why should you conform your credence to the physical probability? You may as well say why rational people avoid black cats or ladders. It's not fair.

### 30m

physics. There's no explanation. If we are rational, then in what way should I conform my credence to a physical probability? After all, probably winning is not the same as winning. So do I make the bet or not? A rational person is interested in what really is the case or in what really is going to be the case, not what probably is the case. If I am told when buying a house with wooden foundations that there's probably not a termite infestation, that's not the same as being told there's not a termite infestation. The rational thing to do is to employ

### 31m

a termite expert to check if there is and fix that problem. Either there is or there isn't. In this area, it's very rare for there to be termites. 99.9% of houses are free of termites. The risk of termites is vanishingly small. Therefore, you probably don't have termites. It really is like, well, luck is on your side. Again, that's not rational. What's rational is to check and correct. But what if it's prohibitively expensive to check? Isn't there then a reasonable case to do a cost-benefit analysis on the probabilities, on the fact that so few people have termites? Well, is it rational to gamble? That depends. If I have all my life savings almost being thrown into a house, no, it's not rational when one knows there exist termites that could reduce your investment to near zero. And if checking is prohibitively expensive, then don't buy. Ah, but someone else took that gamble and won. Turns out, there was a termite infestation. There were no termites after all. Okay, some people win the lottery, but it's still not rational. If you use the poker machine, the gambling machine, and you have a streak of

### 32m

wins, the fact that you won over and again doesn't make what you did rational. We are interested in rationality and reality here. And anyways, in real life, in the termite case, it's not prohibitively expensive. And insofar as that is a metaphor for other situations, there will be explanations that allow one to gain the knowledge needed to find out what the risk really is. As I will come to, risk assessment is about having good explanations, or not. Not about what will probably happen, but what is known to happen and what we know about how to mitigate when the worst is a possibility. That hypothetical rational actor in probability scenarios is not the same as a real person. There are physical things and imaginary things, and they're not the same. To illuminate the way in which probability is disconnected from reality, consider dividing statements about the world into factual ones and probabilistic ones.

### 33m

And by comparison, then, magical ones, or thermatological ones, as David has here. What makes the magical one worse than the probabilistic one? Let's go through the table here. So a factual one about poker. A straight flush beats a full house. It's factual. Probabilistic. Drawing to an inside straight is very risky. Thermatological. This amulet will increase your luck. Or we can just speak about things that will happen. X will happen. Probabilistic. X is likely, or probable. Or magical. X has favourable omens. X cannot happen. Compared to X is unlikely or improbable to happen. Or magical. X has unfavourable omens. We can see here that the probabilistic and the magical are basically telling you to do the same thing. There is this weird force that either can encourage you to do a thing, or dissuade you from doing a thing. If we say, factually, X causes Y, the probabilistic thing is

### 34m

that X is correlated with Y. And a magical thing might be X is an omen of Y. And last of all, X has happened in the past more often than Y. Factual. The probabilistic claim is X will typically happen. And the magical claim is X will happen if you truly believe. So it is strange that the column about probability, X will happen if you truly believe. So it is strange that the column about probability, X will happen if you truly believe. So it is strange that the column about probability, X will happen if you truly believe. So it is strange that the column about probability, contains normative statements. Statements about what you should do. Which is strange for science or physics. Because you can't get an ought from an is. Remember, as David likes to say, never mind so much being unable to derive an ought from an is. You cannot derive an is from an is either. That the sun is hot and produces light does not logically entail that there is fusion reactions going on at the core. That explanation had to be conjectured. And that then goes to explain why the sun is hot and shines light. And that is why the sun is hot and shines light. It is quite the other way around. David goes on to summarise what a stochastic physical theory is all about. What it consists of. So if probability purports to be a part of reality, then the theory

### 35m

of probability, the stochastic physical theory, really consists of a factual part of the stochastic theory. Which asserts that some quantities, X1, X2, etc. have probabilities, P1, P2, etc. Which are physical in some sense. So these things that may or may not be physical, but they are physical in some way. We don't know how. But the principle principle then goes on to say that if you think the probabilities are P1, P2, etc. Then your credences, your belief in these things should be set to those probabilities. And last of all, this apparently helps you make decisions because under suitable circumstances, you can treat the prospect of possible outcomes with values X1, X2, etc. And credences C1, C2, etc. As if you believed that a single outcome with value C1, X1, plus C2, X2, etc. Is the expectation value. As if that was going to happen. Even though

### 36m

we know it's possible it won't. And all of this leads us straight into quantum theory. Because those other non-realistic models of quantum theory assert that the universe is stochastic in some way. That there is this randomness going on in actual physical reality. It's wrong of course, but how do they do it? Let's explain how these other versions of quantum theory, these non-unitary so they're called, versions of quantum theory, the versions of quantum theory that deny most of physical reality, that deny the multiverse. How do they do it? Especially given that the formalism of quantum theory, which we all agree on, does not explain in any way why some of the possibilities are actual and why some of them are never actualized. They remain only probable but never happen. How is that the case? Well, they use something called the Born Rule. The Born Rule is if some observable is measured, then the state of vector of a quantum system collapses to some particular value, an eigenvalue, with probability which is the square of the

### 37m

amplitude of the wave function. Okay in my words, and much more roughly speaking than what's on the screen there, my words are that quantum theory describes observables, physical properties of a system, like for example the position of a particle is the one that I like to use. which is the most basic one. And that position of the particle can be many-valued simultaneously. And we like to say not sharp. And it does this because it really isn't. It really isn't sharp. It doesn't have a single value, as it does in classical mechanics. But when you measure a thing, say the position, you do get a sharp value, basically a single value. A value for whatever the observable is, like that position. You know, the electron, the particle is there at that position x, which is sharp. But the Born rule says that each possible value has a probability associated with it, which is the square of the amplitude of the wave function.

### 38m

So the probabilities are physical. They are part of physics on this view, because they are the squares of how tall the amplitude of the wave function is in the system. And that is the only way that probability ever came into realistic objective science or physics. All that assumes collapse of the wave function. And, of course, we know this does not happen. I say we know, I mean those who understand Everettian quantum theory or unitary quantum theory, which is to say the multiverse, the many worlds. The way out of this is the decision-theoretic approach, sometimes to the Born rule, but that is kind of circular. And so here we have a gambling machine illustrating the decision-theoretic approach. And what it's saying is that, roughly speaking, in one-third of the multiverse the value that appears, on the machine, is going to be 2.7, and in the other two-thirds it's 5.9. Let's not get into the details. It has something to do with that squaring of the amplitude of the wave function.

### 39m

The decision-theoretic approach is about what a rational person should do in a situation where the outcome for them is unpredictable, given that the probabilities are not actual. What Chiara says in her paper on probability is that, quote, the decision-theoretic approach claims to explain the appearance of stochasticity in unitary quantum theory without invoking stochastic laws, rather as Darwin's theory of evolution explains the appearance of design in biological adaptations without invoking a designer, end quote. So things are not actually random in the universe. Nothing actually random happens. It's just that the laws are such that for any observer things are unpredictable because they are not able to have all the knowledge needed to know which universe their consciousness will be in after some measurement. Whether a quantum physicist or philosopher or whoever speaks in terms of so-called actual probabilities

### 40m

and actual randomness, or merely the appearance of randomness and the use of rationality makes no difference to what decision the rational person ultimately makes. It would be the same. It's just that only one of them is speaking in realistic terms, actually is speaking about what actually happens in the real world. Now, at this point, David does spend some time on the technical details of quantum theory in his talk, but I'm not going to. I'm going to move over that very quickly. I will point the listener or viewer to my series on the multiverse, if interested, or the original talk itself. Suffice it to say that alternatives to unitary quantum theory are not exactly parsimonious. They require lots more baggage and assumptions, axioms if you like, to try and produce a stochastic or probabilistic theory of quantum reality. Now, these axioms are not explanatory, so really should be ignored on that basis. They normally would be. We can reach the same conclusions without ever assuming collapse happens.

### 41m

Why assume collapse happens? Go to the beginning of infinity, look at chapter 12, titled bad philosophy, a physicist's history of bad philosophy, and the reasons are sociological, bad philosophy, irrationalities, all that sort of stuff. Not wanting to take the theory, literally, as a description of reality. But realism is parsimonious. It is the simplest explanation. In the face of quantum unpredictability, and that's unpredictability in the subjective sense of course, we can behave rationally. We can deploy reason. We can speak of having good explanations or not to inform our choices. So there are no stochastic processes in nature according to quantum theory, unitary quantum theory, the multiverse. What happens there happens according to the laws of quantum theory. So there are no credences because there is no need for credences. Credences being beliefs with numerical measures of obeying the probability calculus. And just notice that idea of credence, a central part of Bayesian epistemology,

### 42m

is once more entirely subjectivist. It is about what is happening in particular minds, this notion of belief. It is not about objective knowledge, the solution to problems out there which either do work as solutions or do not. That's an objective criterion. But rather again, belief. Belief shares some qualities with hope or fear. Though the three are different of course. What they share is that it's a private thought that something's going to happen perhaps or not. Or it could mean really truly strongly think is true. Whatever the case, it is usually accompanied by powerful feelings of a kind. The religious share it with the superstitious, who share it with the conspiratorial, who apparently share it with the Bayesians who try and quantify it. But knowledge is not primarily a bound. It is about feelings. It is about what is the case and representing what is the case, regardless of what people think is the case or how they feel about what is the case. There is knowledge without a knowing subject as Popper explains.

### 43m

And what happens in physics happens according to the laws of quantum theory. It does not say things probably happen because things do not probably happen. They happen or they do not happen. And hence we've dispensed with probability. Job done. . But just lingering over this separation between collapse theories and the unitary quantum theory, we see that on the right hand side, we don't merely derive, we have explained as we do not have to introduce unexplained postulates. Let's just return to Cardano for a moment, where in reality games of chance are determined. The outcomes of games of chance, genuine games of chance, are determined by quantum laws because the laws of the universe are quantum. They govern everything. And again, they are not literally described by the probability calculus. Decisions made based on probability theory in games of chance, therefore, are actually, literally, but then so is most gambling of course,

### 44m

literally irrational. They are made absent good explanations. Which can of course exist. Betting on games of chance seeks to make a prediction. But how? We are subjectively uncertain and the probability calculus does not hold anyway. General decision theory, cannot take the probability calculus literally as a description of what is going on, because probability is literally false. What is general decision theory by the way? Well, it's just applying probability to making certain decisions. Whatever the case, rationality means being concerned with what we know and how to error correct what we know, and allow all of that to inform our decisions. Not being concerned about what probably is the case. There is no probably. Again, things happen. They don't probably happen. And evolution does not require probability either, as David explains in his talk, because literal randomness is not needed. Random or not, the theory works, by selecting genes best suited to an environment.

### 45m

The theory doesn't depend on true randomness. The essence is that the selection, not the mutations, are the systematic part of the theory. Chiara's paper on the Constructor Theory of Biology, never even invokes randomness. None of this means the mathematical formalism of quantum theory, is not sometimes useful. Of course it is. David is saying that the quantity's core probabilities, in that formalism, never refer to any actual stochastic, actual random process in reality, nor anything in rational minds, either in physics, or in minds thinking about physics, as he says. Can there be a stochastic process in nature? Not as far as we know. As far as we know, the universe is deterministic, not random. Quantum statistical mechanics has entanglement and decoherence. It doesn't need probability. Experimental error seems to contain probability, one of the first uses of probability after the games of chance. But random errors, what are called random errors, are not really random. They can be reduced without limits,

### 46m

simply by repeating the experiment. In school or university science classes, these random errors are things like, well, you know, you measure the length of something, and then you measure it again, and the two measurements are slightly different, because, well, you know, people aren't perfect, and parallax is a thing, and so on. Or you might measure the mass of something on an analytical balance in chemistry class, and one moment it's 1.342 grams, and the next it's 1.344 grams, and, well, who knows why, but maybe the wind blew, or maybe water was being absorbed. So you have to repeat and repeat again until you get a reliable average, or you know better what you're doing and how to control the variables. Systematic errors, on the other hand, are altogether different, and they are often methodological. No amount of repeating the measurements over and again, will eliminate them. We cannot know what causes them in many cases. So it's ironic they are called systematic, because no known system causes them in most cases, until sometime later when they're corrected. I say systematic errors are methodological errors,

### 47m

because, well, let me give a very simple example from school. Students might be asked to get into groups and to measure the height of one of them. There might be five students, and another one whose height is going to be measured. Tape measures, and rulers, and lasers, everything is tried and deployed, and lots of repeats are made. Averages are calculated with error bars produced. And eventually, after half the lesson has gone by, for something as simple as measuring the height of a student, we come up with a value. This particular student's height is 1.675 plus or minus 0.004 meters. So given the size of that error bar, 0.004 meters, we have a height that is anywhere between 1.679 meters, at apparently the tallest, and 1.671 meters, at apparently the shortest. The random error there gives the limits, and the 0.004 gives us our precision. It probably arises because we've done many, many measurements, and that's the average ignoring any outliers,

### 48m

and so on and so forth. But despite all of that, we might be entirely off, inaccurate, because of systematic error. Now at the moment, no one might be aware of what's gone wrong in the system. They might never. But this sort of thing is par for the course in science. Sometimes you just cannot locate your error. But here I'll just tell you what it is. The student never took their shoes off. So really, it's not the height of the student that was ever found, even though that was the ostensive aim of the experiment, to find the height of the student, let's say. What we ended up finding was height of student plus height of shoe sole or some such. If you don't know what's gone wrong systematically, which is usually what happens with systematic errors, what's gone wrong with the procedure, no amount of repeating the experiment will fix this. All the fancy statistics in the world and sigma confidence levels won't help. Psychologists and astrophysicists alike need to take note. Repeating the experiment cannot make its conclusions more likely true or probably true.

### 49m

It's about whether there's an error or not. It doesn't matter what a scientist believes about a theory, what credence they give it. Either the theory is true or not. Their beliefs about it are irrelevant. That subjectivist epistemology makes no difference. To actual reason, actual objective knowledge. Probability can be a metaphor or a technique for an approximation, but it should be an approximation to something. So if it is to inform decisions being made, there should be an explanation rooted in a description of an actual physical world where events happen, not probably happen. It's right and proper to expunge probability, therefore, and randomness from the laws of physics to restore actual realism and rationality to the world. It's a simplification and a unification and elimination of nonsense. And it's true. The world is not probabilistic. For the umpteenth time here, things happen. They don't probably happen, but instrumentalists will resist. What's the benefit of this expunging if the formalism works anyway?

### 50m

Well, as David says, fundamental falsehoods don't always rear up and bite you. You can believe in a flat earth and it might never affect your life and thinking. But belief in a flat earth theory, could eventually conflict with a theory for avoiding asteroid strikes. Then you've got a problem, to put it mildly. So we should be concerned about what is true and how to best understand reality. Similarly, you might very well continue to think probability theory is true, or randomness is real, and so on. You might even be able to invent quantum computers using this whole misconception. But because the Born Rule contains misconceptions, then you might not end up developing successes to quantum theory. Constructor theory, for example, is incompatible with probability. If you assume that your garden is a flat bed, then you can use mathematics of flat surfaces. You don't need to say it's an approximation to the flat earth, because it isn't.

### 51m

There isn't a flat earth for it to be approximate to. So too here. We don't assume that the probability calculus is an approximation to the underlying reality. It's just some mathematics that can be useful. It's a trick. Unpredictability can be modelled by randomness. Sometimes. But that does not make the model correct. It doesn't. So that's basically the content of David's talk, and I encourage everyone listening to go to it, and just to listen to David speak in his own words about this stuff. This should give you a good grounding in what he says. What I've done here is pepper a lot of David's remarks with my own reflections and top spin, as I say. Now, I just want to mention one other thing briefly. And that's about risk mitigation. As I say, I've been asked about probability a number of times. A subset within this is the idea of risk mitigation. If we are saying something like probability is a scam, then how can we quantify risk and mitigate it?

### 52m

What is the rational approach? After all, don't actuarial scientists, people working for insurance firms and so on, aren't they using probability all the time? They can't just do away with it. If it's irrational, what's the rational thing to do? Well, not just actuarials. Everyone who might want to invest in a company, for example. How should we think about what is probably going to turn a profit? Is that even a rational way to think? Where to build a home? How to assess the likelihood of failure? For example, the mechanical failure of aircraft. So in all of these cases, rather than going through them one by one, I would just say that I have a decision fork, a risk decision fork. Consider the fact that you either have a good explanation or not, any circumstance, but let's talk risk. Let's specifically talk natural disasters and what to do about risk absent worrying about the probability of the risk, because that's a fiction, as we've already talked about. We want to talk facts, not fictions.

### 53m

So here's my three-pronged fork. One, if you have a good explanation of the risk, its effects, and where or when the bad event might happen, then prepare for the bad event. Two, if you lack a good explanation of whether and how a bad event is going to happen, then prepare for the worst when you can. Anything less is irresponsible and basically gambling. Three, if you have a good explanation that the bad event won't happen, only then can you act as if you know it won't. They are your options, and they are your only options. If someone takes probability seriously, and says the risk of a bad event is 10% or even 90%, it's no help whatsoever when it might be your home or life on the line. After all, in either case, the worst might happen tomorrow and effectively be consistent with that so-called prediction. And we might very well ask, where did this 10% or 90% number come from? Well, it's come from the frequencies.

### 54m

At best, it's come from the frequencies. By looking at past situations similar to your own, 90% of people have encountered the bad event or 10% of the people have encountered the bad event. Therefore, this applies to you as a typical representative of the population. And that's the best that actuarial science can do. And it's a useful fiction. But so long as we're not regarding it as being true, because after all, things happen or don't happen. They don't probably happen. Let's take a specific example. Here in Australia, like most other places on Earth, we are plagued by natural disasters. Still, I'd prefer here in Australia more than almost anywhere else because we tend not to get earthquakes. Basically for the same reason we don't have earthquakes. Basically for the same reason we don't have earthquakes. Luckily, we have volcanoes. Luck of the continental draw. Now, it's not impossible to have earthquakes, but comparatively speaking, this continent is very, very stable. We get storms, but very rare are they hurricane or typhoon-like cyclones. They happen, but to the north of the country. What we do get are fires and floods.

### 55m

I'll concentrate on the floods because they've been happening recently. We live on a continent that is astonishingly flat. So when it rains, it can flood. It does flood. It's predictable. Yet people build homes, towns and whole cities on the flood plain. They know the flood will happen. We have good explanations of where floods happen. They know they happen frequently, but like any weather event, not exactly when. In this situation, you know the flood will come, so you have to be ready for it. That's the rational thing. We have good explanations of floods and where they occur. Risk management says that in this situation, if you choose to build in a place prone to floods, you should expect your home to be flooded. So you cannot expect to be insured, except for a lot of money. And you should not expect the taxpayer to compensate you for choosing to live on a flood plain. No one will or should stop you building on a flood plain. It's cheap. It's cheap for a reason. So there's risk and reward. But you can, in theory, build a house that can survive the flood.

### 56m

At no point do you need to concern yourself with, it will probably flood. It won't probably flood. It will flood. Period. So here's what my decision fork says to do. The first part is, if you have a good explanation of the risk, its effects, and where or when the bad event might happen, then prepare for the bad event. So in this case, build your house on stilts, let's say. Lots of people in Australia do that, by the way. Or build on one of the rare hills. Or construct your own hill. Or just construct the house such that when it does flood, it's not completely destroyed. Or it's easy to repair. The electrical wiring is easy to get to, or whatever. Either that, or prepare by not living in the place prone to floods. This is all just logic, and at no point do we need to gamble. We know what will happen. Floods happen. We just don't know exactly when. But again, that's not probably. We cannot say, probably next week, or probably not next week. We don't know. Our best known explanation of floods in Australia also prohibits, for now, making precise predictions like that.

### 57m

All we can say is, we don't know. Which brings us to part two. Because let's say you do buy the house, but plan on living there for only the next two years. Maybe it won't flood in the next two years. We do not have a good explanation of what floods will happen in two years. We lack a good explanation. So therefore, the second part of my fork would say, if you lack a good explanation of whether and how a bad event is going to happen, then prepare for the worst when you can. Anything less is irresponsible. And basically gambling. So here we say, we don't know the flood will happen in two years. But the rational thing to do is to prepare for it as if it will. As I say, anything less is irresponsible and amounts to relying on lucky charms. Now you can avoid all of this flood talk by living somewhere where we know it does not flood. And have good reasons why it cannot flood. For example, some places in Australia are at an altitude of over 100 meters.

### 58m

On relatively steep inclines near the ocean. If you really wanted to avoid a flood, then building on the side of a sloping hill, then no matter how hard the rain comes down, it flows right by you. Out into the ocean. And the ocean cannot possibly fill up with rain. You know enough science to know that even if all the ice in Antarctica and Greenland melted, you'd still be safe up above 100 meters in altitude because the maximum sea level rise is only 72 meters. And you are up over 100 meters. Almost 30 meters of grace should even a tsunami strike. So in this case, with respect to flooding, you're safe. Which brings me to the third part of the fork. If you have a good explanation that the bad event won't happen, only then can you act as if you know it won't. Of course, you could still be hit by an asteroid. But in this case, we're in the situation of simply lacking good explanations, sufficient knowledge and wealth. Now in terms of large asteroids that might wipe out humanity, well, they are of a particular size,

### 59m

such that our telescopes and present technology can detect them. In theory, we'd have the wealth, the capacity to deflect them. But house destroying asteroids? Not quite there yet. But they're infrequent enough that it's a reasonable heuristic not to worry about the risk any more than visiting Australia and being bit by a funnel web spider. In a very similar way, when it comes to money, the same principles hold. No one rational should want to invest in a company that will probably make money because no company probably makes money. Companies make money or they lose money. Of course, some investors might want more insight than this. They might want to know how much money will be made before they invest. There are many people better placed than I to guide the rational investor through this maze. But one thing that is clear is that probabilities are not part of the picture. There is no way to know beforehand what the future holds with any precision. Because the relevant factors depend upon human creativity.

### 1h 0m

Knowing how the product, yet to be produced at scale, works in the market. All that knowledge is yet to be created. And more. The team of people coming together in that company to make things work, they are yet to get to know each other under the conditions of success or temporary failure and so on. So much knowledge is yet to be created and knowledge creation by its very nature is, as we like to say, inherently. Unpredictable. So these kinds of predictions are not possible. But here is what is possible. You can either have some relevant and specific knowledge or you can lack it. If you are an investor, or an employee, or a founder, or even the sole owner for that matter, you can know the product well. Or not. You don't say, I've probably got a good understanding of what we are selling. You either do or you don't. And the same goes for your employees, for the business. This is not to say you need to know about

### 1h 1m

the intricate details of a person to know they are competent. You need to know that they have the relevant knowledge to get the job done. So you either have that knowledge or not. It's again, not a matter of probably having that knowledge, it's black and white. In other words, to keep this part relatively brief, because I only want to make very broad brush strokes here, you either have a good explanation of why the business should succeed, or not. If you lack a good explanation of what the business is, what the market is like, and what the people working in that business are like, and you invest anyway, well, you're gambling. You might as well be putting the money through the casino where you only have a partial understanding of how the gaming machines work, or exactly what the mathematics of roulette happens to be. But if you do have good explanations, you either do or don't invest. In the case of the casino, you know the whole thing is rigged on the side of the casino.

### 1h 2m

Every game in the long run is set so that the odds are in the favour of the casino. So it's not rational to play in order to make money. You might play because you're just having fun with your friends and so on, but that's different. It's still irrational as a means of making money. It might be rational as a means of having fun so long as you expect you're going to lose your money in the long run. And so too with investing. There might be a case to be made for having fun in the market, for really taking the long-shot bet. The young up-and-coming chemistry graduate comes to you with a plan for waterproof transparent paint that generates photovoltaic electricity, solar power. You don't have the technical proficiency or time to go into the details. You don't have a good explanation. But she seems genuine. She checks out online. She could be the next Marie Curie or she could be the next Elizabeth Holmes running a Theranos-type scam. But you're wealthy and she's only asking $200,000

### 1h 3m

and if she's correct, every building on earth can be painted with transparent photovoltaic paint which during the day can power all of the lights in that building. Well maybe that qualifies as fun. You won't really miss the $200,000 and there's something to be said for this particular innovator appearing to not want to damage their reputation. But it's still a gamble. You might just change the world of technology and engineering. Or not. Now that case aside, simply having fun in the stock market rather than focusing directly on getting a good return, on making money, in all other cases, you want to have knowledge. Knowledge of what actually is. Not because it can possibly guarantee what will be when it comes to success or failure in business. But because knowledge is not a matter of probabilities. If you have a good explanation for the viability of a product, the hole in the market, lack of present competitors

### 1h 4m

and knowledge of the skill and competence of the team, then you do not need to be told by anyone else that your return on investment is probably going to be 50% over the next five years. No, probably 200%. Or any other number for that matter. The probably part, the probability, does not matter because there is no probably. Something is going to happen. Businesses often fail but you, personally, know business. Or at least you should be if you're asking this question. And so you have the knowledge of what to look for. Again, none of this possibly guarantees you won't fail. Experts fail all the time. You are still fallible. You've taken all possible measures to avoid disasters you can foresee. You've not effectively built the home on a flood plain. But in business, the equivalent of the asteroid or some other unforeseen natural disaster can still occur. But at no point have you needed to comfort yourself with the hope of good omens or protecting yourself with lucky charms.

### 1h 5m

Or the thought, I should probably be okay. The business is probably a good investment because the people are probably good at what they're doing. No, there are no certainties in life and in human affairs as much as global and cosmological events, what happens rather often is inherently unpredictable. And in the human world, this is because what happens depends on human choices, which themselves depend on human creativity. What people know and what knowledge they create. Things happen. Things happen. They don't probably happen. Knowledge is about good explanations of the world and can be instantiated in things other than human minds. It's not about beliefs and feelings. So Bayesianism is wrong and rationality cannot possibly be about considerations of things that probably happen. The idea that it is resembles a sort of mysticism, contemplation of imaginary worlds,

### 1h 6m

the worlds of the probable. But quantum theory tells us what can happen, what does happen. And constructive theory is revealing a science of the possible and impossible and therefore how we can transform the world. It's not that our decisions will probably happen, they will, or they won't. We'll either know how, or we won't. We'll either have the wealth to do what we want, or we won't. There's no probably about it. And that doesn't mean I'll likely end the podcast here. Instead, I will. See you next time.

