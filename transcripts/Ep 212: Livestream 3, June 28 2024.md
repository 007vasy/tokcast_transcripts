# Ep 212: Livestream 3, June 28 2024

Original Episode: [Ep 212: Livestream 3, June 28 2024](https://www.podbean.com/site/EpisodeDownload/PB1653DE1VFVSH)

Audio Download: [MP3](https://mcdn.podbean.com/mf/download/knxt5trtdv8juiay/Livestream_3_Podcastb9huz.mp3)

## Transcript

### 0m

Hello everyone and welcome to the third live talk cast for June in just this last week really. So I've been, I was going to say inundated, but that's not a nice word to use. I've been gifted with many very interesting questions over the last few days and I thought I'll do a final one for this month. I seem to do live streams in spurts now and again over the course of a year. Sometimes I'll do a whole bunch in a row and then there'll be a drought during which I do not do any. And so I have a number of questions to get through today already from Twitter. But as people begin to join the chat, they can feel free to also ask me questions there. Or if any new ones appear on Twitter, then I will respond to those as well. But there is much to get through. Let's just say that to begin with. In terms of what people have asked me on Twitter surrounding similar topics, as always, which I don't mind.

### 1m

You know, we can talk about the same things over and again because they're usually the things where the misconceptions tend to arise. Or they're just open questions and everyone's opinion is almost as good as anyone else's so long as we're committed to rationality and reason. I'm not going to take these questions in any particular order. I'm just going to sort of pick from random and we'll see if we can get through as many of the Twitter questions as we possibly can. Let's begin with Convex Bets. And Convex Bets has asked, Is a system such as a Tesla autopilot, which uses video input from the cameras to train the end-to-end experience, a neural network to drive the car, basically using induction to develop the knowledge needed to drive the car?

### 2m

Or is it doing something more or something else? Do you think it is possible to have a system that can drive a car in all conditions at least 10 times more safely in terms of miles per accident than an average human driver with this approach? Or do you think this is not possible without AGI? So I think I've got three questions there. To go through. So let me begin with the first part about is the Tesla autopilot using induction in order to learn? No. How do we know that? Because induction is not possible. Induction is the idea that from the past, we can observe things occurring repeatedly. And from that, extrapolate to an explanatory theory, to knowledge. Induction purports, in epistemology, to go beyond mere extrapolation into explanations.

### 3m

After all, anyone can, and I've talked about this so often before, and there is an article on my website about induction, and when I come to edit this, I'll throw a picture of that particular page up. Look up Brett Hall induction. I've talked about this so many times before, but let me use the example. The example is, if you were to plot a graph of water being heated, over a stove, every minute or so, before it reaches boiling point, what you will tend to find is a lovely linear trend. Now on induction, looking at the past data, which is a straight line, a straight line graph, then you could draw a line with that straight line graph and predict that as you add more heat to the liquid water, you will continue to get the same pattern. You can generalize, extrapolate, use induction, purportedly, in order to figure out what the

### 4m

temperature of the water will be in 50 minutes time, let's say. And let's say the temperature of the water is going up 10 degrees Celsius per minute. Then you might very well predict that in 15 minutes from now, the temperature of the water is 180 degrees Celsius. That's your prediction, given the straight-line extrapolation. Now, how did you arrive at that? Well, only given the explanation you already have, and the explanation you already have, regardless of induction, is that water, when heated, must follow this straight-line graph. You've already conjectured that, and now you're just confirming, for want of another term, what your theory is. Now, of course, if you actually do the experiment, you're going to be roundly disappointed and refuted. Because, as we all know, water at approximately sea level, on a typical day, standard temperature

### 5m

and pressure, will boil at 100 degrees Celsius, and the temperature will not rise. So induction couldn't have told you that. No amount of extrapolating from the past data could you have gotten to what really happens. Now, in order to get to what really happens, we're not after just a prediction of what is going to happen to the temperature, but rather an understanding of the explanation to do with molecular bonding, of H2O molecules, this thing called latent heat, and as something boils, the behavior of the bulk liquid. There's a huge explanatory theory, a complicated explanatory theory, that does not come to us from what is known as induction, the generalizing of data into an explanatory theory, impossible, but rather a conjectured explanation, which is then tested against reality. And the testing against reality is done by actually trying to increase the temperature, the temperature of the water, off into, you know, 180 degrees Celsius, which is what you might have made a prediction that the water was going to be. The water, liquid water, under normal conditions of

### 6m

normal air pressure, will never reach 180 degrees Celsius. If you pressurize the air, you might be able to get there. And so as water boils and you continue to heat it, the temperature does not rise. So this is my go-to example, my tired example of why induction not only doesn't work in that situation, but never works anytime. Anyway, because to extrapolate, to begin with, you need an explanatory theory. So a Tesla is not using an impossible means of creating knowledge. In fact, it's not creating knowledge at all. It's not creative. What it's kind of like is a Roomba. Okay, Roombas have been around for a while now, robotic vacuum cleaners that go wandering around your house. And the first time that you put the Roomba on, you can set it to a particular setting where it will, you know, be able to generate a map inside of its head of your, inside of its head, it'll generate a map inside of its

### 7m

circuitry, inside of its memory, using AI, using a program, in order to build up this map of your house. So that the next time that you run it, it is far more efficient. It knows where the walls are. It knows where the stairs are and all this kind of thing. And whatever the case, the Roomba will learn. What your house is like. Now, would we say that it has created knowledge? I wouldn't. The knowledge that has been created was placed in there by the programmers. The programmers were the ones that designed the Roomba as a map-making machine. And so, of course, it is going to follow the instructions about how to make a particular map. It's a map-making machine in terms of general. You put it into your house and it makes a specific map. Unsurprising. It follows slavishly its programming, its code, in order to produce the output required, the output that you

### 8m

expect. So, too, with the Tesla, thank goodness, you want it to not be creative. Because to be creative would allow it to create explanatory knowledge and then decide it doesn't want to do what you want it to do. Avoid obstacles. Travel at a particular velocity. Turn the corner when the corner arrives. All this kind of stuff that the autopilot should do. In other words, be committed to nothing but driving the car. So, I do not call this creating knowledge, but rather gathering information very quickly about its environment in order to safely transport you from point A to point B. Why wouldn't I call that knowledge? Well, we're not necessarily splitting hairs, but what we're talking about is that it's a map-making machine. It's a map-making machine. What we're talking about is the difference between gathering data, unorganized kind of

### 9m

information, rather than generating an explanation, which is what knowledge creation, as we normally talk about it, amounts to. There's another kind of knowledge creation, which is the biological knowledge creation. But the knowledge of how to avoid an obstacle, how to maintain a particular speed, how to turn a corner. All of these things that the Tesla autopilot can do were knowledge instantiated into its code, but discovered, or programmed, by an engineer, a software engineer, earlier and elsewhere. So, you can call it an end-to-end neural network, if you like. It's a piece of software that is able to... Learn about its environment. Again, learn there is used with some proviso. We now begin

### 10m

to distinguish between training and learning. Learning being conjecturing an explanation, conjecturing an idea, and trying to refute it. And training, simply being fed lots and lots of data, which is then stored into memory. Much like a fluid can be poured into a bucket, but this is not like what learning is, which is not the fluid being poured into a bucket idea. But if you're simply loading data into a particular system, then it does more resemble the old bucket theory of knowledge idea. But this is not the way in which knowledge is created, or the way in which knowledge is learned. Those two things are the same. The second part of the question. So, do I think the car is using induction? No. Is it doing something more, or something else? It's doing something else. It is using pre-existing, explanatory knowledge encoded into the programming, which guides the autopilot in order to perform the function that you want it to. And you don't want it to do anything else. You don't want it to

### 11m

go explaining things, being creative. Because were it to do that, then it would disobey its own code. It could choose to not avoid the obstacle, let's say. Which I guess comes into the second part of your question here. Which says, do you think it has been possible to have a system that can drive a car in all conditions at least ten times more safely in terms of mile per accident than an average human driver with this approach? Or do you think it's not possible without AGI? An AGI would be a person. And would be, I presume, an AGI being a person, we can't distinguish between the different kinds of people except what their substrate might be, which is going to make no difference in any fundamental sense to their function. But the thing about AGI is that they're going to be highly prone to error because they will

### 12m

be conjecturing. I would not want an AGI to be driving my Tesla, to be the autopilot, because they wouldn't be an autopilot. They would be a person. So there'd be no difference really between an AGI and a regular GI, a person, except what the substrate would be. What we want would be an AGI to be driving my Tesla, to be the autopilot. What we want to do with an AGI is a close, as perfectly obedient as possible system which is going to do nothing but drive. An AGI can be distracted. An AGI is a person, and people get distracted. This is the whole problem of people driving, and why we want autopilots ultimately to take over. So never mind the AI being ten times more safe. I would expect a million times more safe, quite literally. That an AI system autopilot, which is networked into some sort of grid that operates at the speed of light, which is able to notice all other vehicles on all roads within some particular radius, and able to account for what's coming up at the next crossroad, where the pedestrians are.

### 13m

There'd have to be some system of monitoring that is better even than the present set of Teslas have. Teslas have, obviously, sensors around the entire vehicle checking for things like pedestrians and the trash can that you go past and the set of lights that's coming up. We can imagine that becoming ever better. And we can also imagine the autopilot being ever more proficient and obedient at being able to get you safely from point A to point B. Unlike a person, a personal driver, who is going to get bored, look out the window and get distracted, take their eyes off the road, be drunk or be angry, not have sufficient coffee, have too much coffee.

### 14m

As you talk to them, maybe they start thinking. They start thinking about something else. They're upset because of things that have happened at home. A thousand and one things that could intrude into the mind of a regular person who is driving or an AGI who would be a person because they're thinking creatively about other problems. Problems other than how do I get from A to B safely and efficiently? And AI, a very good Tesla autopilot, would do nothing but, focus is the wrong word because that. Invokes consciousness to nothing but implement the program of getting from A to B, utilizing whatever instructions are in the program that is controlling the wheels of the car. And it wouldn't be, as I say, 10 times more safe than a person, but a million times more safe. They'd be able to get from A to B faster.

### 15m

You would never get anywhere near having a head on accident because the thing would be reacting with reflexes. So much faster than what any human being could do. So I'm looking forward to that day. That day is coming. And that day will happen long before, well, I shouldn't say long before. That day happens independent of any research going on with AGI because this is an AI problem or an AGI problem. We don't want creative AI. We don't want autopilots to be creative. We can't. We already have autopilots, very, very good autopilots for aircraft, obviously, and for cars. But you might say, but don't you want it to be able to think creatively in case it encounters a problem which the programmers haven't thought about? But that's always the case. That's always the case.

### 16m

Problems not foreseen are an issue for AI and AGI both. In all cases, problems are parochial. They're problems for people. We are the entities that have problems. The AI are a tool that help us to assist us to solve our problems. But they can only solve problems where we have thought about what the potential problems are going to be. So all of the things that you think might happen or go wrong on the road, that's what you encode into a test. And you go, well, if only you could give the test the creative capacity to solve the unknown problem. Well, you're back at the same position. It would be no better than a human being. In that case, a human being driving along encountering a problem that's never been seen before. How would they react? They'd react exactly the same way as anyone who didn't have information about that unknown thing. You know, suddenly the huge octopus falls from the sky. What do you do? Well, a person presumably recognizes that as an obstacle. Well, the same thing with the AI-controlled vehicle.

### 17m

But I can't think off the top of my head what would be a problem unforeseen. But there would be problems unforeseen. That people who program autopilots would be tripped up by if you could somehow orchestrate that. But hopefully there is a fail-safe within the autopilot such that if that kind of thing happens, there is a thing where it just brings the car to a halt. Or not. Maybe you want the car to accelerate. If there's an avalanche beside you, you want the car to go faster rather than the car to slow down. Are these things thought about? Presumably they are by AI autopilot. Coders. Okay, let's keep going. Convex Bets again has asked. BOI by David Deutsch is one of the books that Sam Altman has openly recommended people to read. I cannot reconcile this with his recent prophecy of having systems soon that we will be able to ask to figure out all of physics.

### 18m

Do you think he actually believes this? Or is he just gaslighting for fundraising, regulatory capture, or some other reason? Well, I can't speak to the last bit. I don't know. I'm not in his mind. There's no possible way I can figure that out. There's a misconception there. But it is a pervasive misconception. It's not just Sam Altman. I've heard many people, physicists included, saying things like, you hear it all the time, something synonymous with the idea of completed science. That if the researchers continue to work hard enough, then they will tie in. Tie up into a nice, neat bow, with a nice, neat bow, some area of science. Physical chemistry, cosmology, particle physics, whatever it happens to be, so that there will be no open questions. And it betrays a deep misconception about what the nature of science is. That when we find a solution to something,

### 19m

it opens up a window onto a whole bunch of new questions that we weren't able to ask before because we didn't know what they were. We didn't know what they were. We didn't have the language. We didn't have the concepts. We didn't have the understanding. Prior to the idea of space itself, space-time being a fabric that could bend and weave, there was no way of conceiving of how space could stretch and expand, much less accelerate. And so it was only once we had, we had an explanation of general relativity, the idea of space-time, and how space itself was this physical entity that has properties, could you then have an understanding that things like, mysteries like an accelerating universe could even be conceivable. Because otherwise you would be thinking things like, ah, you see a star there that's moving away with a redshift.

### 20m

It's moving through space. Because it would never enter your mind that space itself, could be the thing that would be expanding and causing redshifts. But given a dynamic and really existing space, fabric of space, fabric in scare quotes, then you can conceive of space expanding and contracting, that kind of thing. So when people say things like, you know, Sam Altman did say, we will have AI that is able to figure out all of physics. It makes one wonder what, they're thinking in terms of this, it's becoming outdated, I think, idea of a theory of everything, the reductionist theory of everything, that we unify the fundamental forces, the fundamental forces at the moment being the electro weak force, the strong force,

### 21m

and we've got gravity, which is out there as not actually a force, but it's something that's, sometimes bundled in with the others. But if the part of Chris, just some of them anyway, insist that gravity must ultimately be quantized in some way, there must be this particle called the graviton. And then we unite all of these anyway, and we need to unite these forces and we have the theory of everything. But in fact, that wouldn't be the end even of particle physics, because we would ask why the parameters are the way they are, why the values of the constants are what they have, why the magnitudes of the constants are what they have, why the forces are what they are, why that theory and not some other theory of everything, and so on it goes. There can be no end to physics. There can be no end to science. Every problem solved reveals new problems yet to be answered. Every solution reveals more of our ignorance.

### 22m

Two things happen simultaneously in the creation of knowledge. Both, an increase in what we know by reducing our ignorance in a particular area, and the opening of a window, which we didn't know was there before, onto a vista of problems which we couldn't have conceived of beforehand. Instead of windows, it might be better to think of doors. We pass through a door, we've unlocked it with our solution, to step into a room which just has more doors. And all of those doors are just doors. And all of those doors represent problems in this analogy. And that is what happens in physics. That you come up with an explanation of gravity, and then you realize that explanation allows for things like black holes, or neutron stars, an expanding universe, an accelerating universe,

### 23m

a universe that must have began hot and dense. So, the possibility of technology and harnessing these things. So, many more problems are revealed to you. My quip on this on Twitter was something to the effect of, the idea that you can figure out all of physics, to go to the chat GPT 7.0 or something, and to say, tell me the ultimate solutions to the universe, tell me all of physics, would be exactly like saying to it, tell me all of the numbers. Everyone should immediately be able to see that to ask chat GPT to tell you all the numbers is a ludicrous thing to say. You will never get to the end, obviously. Not only will you never get to the end, even if you were to confine yourself to the integers, but there are different kinds of numbers. Do you mean complex numbers? Do you mean real numbers? Do you mean rational numbers? Or could there be other numbers beyond those numbers that we've thought of?

### 24m

Different orders of infinity, that kind of thing. We can never rule out new abstract entities being discovered. But more than that, the analogy simply is, we're only ever at the beginning of infinity when it comes to talking about numbers. We know, as a matter of fact, there are more numbers. And by not a perfect one-to-one correspondence between that idea and what physics is all about, we can nonetheless have some insight into what it means to have an explanation of something. Because to have an explanation of something means to reveal to your conscious self a model of the way in which the universe works in some way. But you will always have questions about why that model. And that model will often buttress up against some other model that you have,

### 25m

some other explanation you have. Which means they won't fit together. And we are in that situation right now. Quantum theory and general relativity. Many ways of explaining the ways in which they butt heads, so to speak. One is the discrete versus the continuous. Another is to just say, can you know the location of a specific object in space with arbitrarily high precision? General relativity would require you to do that in order for it to make the predictions that it does, classically. It's a classical theory. But quantum theory says that, no, you can't know arbitrarily with high precision what the position of something is. Whatever the theory is that is going to succeed general relativity

### 26m

and quantum field theory, let's say, there is no guarantee that it is not going to contradict some other strongly held explanation of reality somewhere. That we're not going to be in an unproblematic state. The history of science and ideas tells us that we are always in a problematic state. We move from misconception to better misconception, as David Deutsch says. There will always be open questions. And there will always be open questions. This is a positive view of reality in our circumstance, is that not having a final theory means that there's always more progress to make because there will always be errors to correct. That's a wonderful thing. Wonderful thing. So, yeah, I don't know what Sam Altman's motivation is. I don't think he has any sort of deep, dark motivation. But all I can say about that particular claim,

### 27m

figure out all the physics, is it just contains a misconception about what science is. One may as well say, figure out all of history, or figure out all of biology. I guess people think that that's also possible. Figure out all of mathematics, et cetera, et cetera. Figure out all of art. Many people have read The Beginning of Infinity and recommended it. And Mark Zuckerberg has as well. I guess Elon Musk at this point may have. Sam Harris, Dick Pinker, many great luminaries, contemporary luminaries in the intellectual world have recommended the book. Some seem to have a better understanding than others. But what many of them share is, I think, a tendency to, and we all do this, when reading a book, to read into the book what you expect to be there. And The Beginning of Infinity contains many countercultural and counter-common sense ideas.

### 28m

And so it can be so psychologically challenging. It can be psychologically jarring for many people that their mind can tend to skip over the challenging parts and to fill in those gaps with their preconceived ideas about how the world must work. And so you do have encountered people who, you know, will have read The Beginning of Infinity, or say they've read The Beginning of Infinity, understand The Beginning of Infinity, but then insist things like, nonetheless, there must be a superintelligence out there somewhere. Well, the superintelligence is possible. Completely. And you're missing this idea, which is so central to the themes throughout The Beginning of Infinity, of universality and explanatory universality. And once you really understand that, then you recognize that there can be no superintelligence. All you can do is augment the speed at which you think and the memory that you have. But once a system is creative, you know, able to have a problem and therefore attempt a solution,

### 29m

that capacity gives it... Gives that system, that person, universality when it comes to knowledge creation. Yes. Okay, so hopefully that answers the question. Sam Altman, I think, does excellent work and, you know, more power to him in making ChatGPT ever better. Roland Burl has asked, he's putting in scare quotes, he said, companies don't want to kill their customers. And he's gone on to, what if they are in a position far worse than Boeing, probably going under, so in a last-ditch effort to compete, they cut corners. If mistakes happen, they won't be around to blame anyways. Regulations are solution here. It's true that companies do not want to kill their customers. I mean, it's logically the case. And these days, of course, the issue is,

### 30m

that if you are negligent as a CEO or as some other worker, then you will be criminally culpable. If you are the maintenance worker or, indeed, the manager of an elevator or lift company, and you don't do the work that you should have done, and your poor design for an elevator falls to the ground in a skyscraper somewhere, killing the occupants, you will be criminally liable for negligence. People are self-interested, including the workers, and presumably the workers at Boeing. And as far as I know, many of the workers at Boeing, they're very proud of the fact that they work for this prestigious company. And it's had some great difficulties recently with the 737, Supermax jets and all that sort of stuff, granted. But the arrow of progress and safety in the airline industry

### 31m

has, broadly speaking, been pointing in one direction. But there's no such thing as an unproblematic state, and there's no way of avoiding problems. Problems are inevitable. And what we want to do is to learn from our mistakes, and presumably Boeing is doing that. So I don't buy the idea that they're going to suddenly want to start cutting corners without regard for safety. And who cares about killing their customers? No one. These people, to paint business people as psychopaths of that kind, is a very common caricature. I understand. The evil business people sitting in there, figuring out ways of sitting on a pile of gold, like Schmalde the dragon out of The Hobbit, is the image that people have. You know, Mr Burns from The Simpsons is emblematic of that. Scrooge, Scrooge, Ebenezer Scrooge. These are all these old tropes about wealthy people. But there are good and bad people at every stroke of the scale.

### 32m

And that's a good thing. That's a good thing. That's the structure of society. Poor people, middle-income people, and wealthy people. People who own small businesses, people who own large businesses. There are people who choose to cut corners. But the incentive to cut a corner in a world of litigation and prosecution and the potential for having your life ruined because you think that you're going to make a quick dollar by, what, not attaching the engines or the door, the cargo door sufficiently well, to use poor quality rivets or something like that. I haven't followed it that closely. But people are right to be concerned that airline manufacturers do a good job. So it's great that the spotlight is on them. But I would never think that the errors that are made have been deliberate,

### 33m

or as a, because they don't, they want to kill their customers. Could it be the case that they've been careless and negligent? Absolutely. Absolutely. We can concede that. But the profit motive is the best, far and away the best way of helping to ensure safety in any industry. Because of, you know, it is the reductio ad absurdum. Companies don't want to kill their customers. Of course they don't. They don't want to hurt their customers. They don't want to scare their customers. Boeing does not want to go broke. They want to continue to exist and to make planes. So yeah, I think I've made that point. Are regulations a solution here? I personally don't think so. And I think I'm on the side of most people here. Regulations do is they tend to curb creativity. So if we begin to regulate, here's what happens at the moment, there are

### 34m

roughly. Speaking two huge aircraft manufacturing companies, Boeing and Airbus. Now, if you regulate large companies do actually like regulation. It sounds Microsoft liked regulation. Now, why? Because once you begin to regulate that requires you to employ a lot of lawyers that requires you to meet a particular standard to manufacture products, according to a particular recipe, which has been circumscribed by the regulatory framework. Okay. So you've got these regulations. So in that situation, only the wealthiest companies can exist. If you're a startup and you have to meet the regulations, you have to employ all the lawyers. You have to make sure that you're understanding what the regulations are so that you can manufacture things to these particular standards, rather than trying something creative and new, because that will be against the law. This is why large companies cozy up to government and you have this unholy

### 35m

alliance at times between certain large companies and governments, the governments want to be seen to be doing something by the people who vote for them. So if something ever goes wrong, it's like the voters say, or the media says the government needs to do something, you know, regulate social media because the children are suffering something like that. And the voters say, yes, the government needs to do. Something. And so the social media companies will say, okay, we're happy to play ball. We will, we will regulate how about regulations X, Y, Z, and they will implement X, Y, and Z, which ensures that any startup social media company or whatever company it happens to be is less able to enter the market as a competitor. This is what regulations tend to do. They tend to reduce competition precisely for that reason. And so it's not like all companies. They're against regulation. They're not, that can be against certain regulations.

### 36m

And of course, that's what happens with lobbying. It's like, if this particular regulation is going to hurt our business, then can we make a deal, you know, me as the company, you know, the CEO, and you as the politician, let me make a deal with you. I will implement a regulation so you can be seen by the voters to be doing something and you can do something for me by slightly changing this regulation in such a way that it doesn't hurt my business, but it will hurt my competitors. It will hurt my competitors' business or potential competitors' business. There are, in other words, perverse incentives. I just noticed, what is Brett talking about airplanes companies for? If anyone in the chat. Yeah. So what I'm doing presently is I am responding to Twitter questions. So initially, all of the questions that I'm getting have come straight from X Twitter. So I'm gradually getting through those and then I come to the YouTube comments. Um, there's a lot to get through here.

### 37m

So I think that, that, that answers that question. Are regulations ever a solution to when things go wrong in the market? No, the market is self-correcting. And by the way, even if you do heavily regulate some industry, this is no guarantee against something like an accident, like a plane crash. It's not going to reduce the likelihood of plane crashes by implementing laws. The incentive that people have for, uh, um, doing a good job is that they can make more money. And so if you're working for Boeing and you know, you're riveting doors to the fuselage, then your incentive is, well, hopefully you're, you're in an industry that you really love and that's why you're there. And you earn a lot of money because you're doing a good job. And the more you do a good job. The safer your aircraft are and the better the aircraft are, and the more money

### 38m

that the entire company makes and the more likely you are to get a pay rise. And so, so the wheel turns, but when things start to get heavily regulated, then, you know, the company has less money because especially if the regulation is working in some way to dampen down innovation within that particular industry, which has happened, which has happened, one of the reasons why we don't have, why, why, why aren't there supersonic flights? Okay. It's starting to come now, but we have the Concorde there for a while. There was a crash. It was terrible accident. And so the Concorde sort of vanished soon after. And so did any attempt to have a resurgence of, of supersonic flight. Samu has asked also on X, why are people universal explainers and other animals aren't? I think it is not a matter of size since there are animals that have bigger brains than humans. Is there something fundamentally different about the hardware or is it the software that makes a difference? Good question. Yeah. So the thing that I've talked about a bit it's not the hardware, the

### 39m

hardware could be, you know, the hardware of a pocket calculator, presumably as long as it's some sort of approximately universal Turing machine. So it's all about the software and we have a program running, which is called a mind or a human mind, if you like, that has this capacity to explain the world around it to notice problems and to conjecture solutions. And to articulate and to model, uh, to create other animals don't have that. They have instincts and they react in a way that is automatic. There's an automaticity there rather like an AI. So there's a fixed repertoire of behaviors that the typical animal has cat, dog, chimpanzee, and they can't really step outside of that repertoire of behaviors. So you don't come across. Chimpanzees, you know, talking about calculus or that kind of thing.

### 40m

And it's not because their brains are necessarily, you know, that much smaller. You know, you talk about whales, you can talk about dolphins, and I guess gorillas have brains that are at least approaching the size of a human beings, if not larger, but rather because there's something there about the mind that is running. Now we have no clue as to how exactly. This mind works at the level of neuroscience, what's going on there, the connect done as they sometimes refer to it as, uh, so yeah, the short answer is, um, is there something fundamentally different about the hardware or software that makes a difference at something fundamentally different about the software, this capacity to generate explanations of the world. And that capacity is a universal one and universal. There means anything. That. Yeah. Can be understood, can be understood by us in principle, in practice, there's always

### 41m

an infinite amount left to understand, but in principle, if someone else can understand that thing, then so can you. And a lot of people, of course, object to this and they don't like the idea. I say, but no, you know, um, Terence towers, a brilliant mathematician. I could never possibly do what he does well. That is true. On the one hand, you know, you don't have his interests. You would never do what he does. You would never do what Mozart does. You would never do what Roger Federer does. You would name, name the person that has this, uh, singularly amazing commitment to this one area and as a genius within that one thing. Yeah. You don't have that because that's what it means to be an individual person. You have a problem situation. There will be things that you can do possibly better than anyone else on the planet. Perhaps you just may not even be aware that you're the best at doing that particular thing. Who knows? Okay. Lauren has asked differentiating between AI and AGI based on the potential to misbehave.

### 42m

Seems like a low bar. Generally weaker models tend to misbehave more, more, and we call them stupid. The smartest people on earth and exactly conformists, but they usually, but they aren't usually the most misbehaving either end quote. Uh, so that contains a number of misconceptions. The first. Is. I don't think anyone's ever said. Hmm. We differentiate between AI and AGI based on the potential to misbehave. The word that's often used is disobey, but even then, um, this is not a criterion for distinguishing between AI and AGI. So it's not about misbehaving and it's not even about disobeying, but I, I say things often like, um, you know, consciousness, free will, capacity to choose explanation generation. They're, they're all synonymous. Ideas. They're all in the mind at the moment because none of them are particularly well understood.

### 43m

We know we do them. We have consciousness, we have free will. We have, we can create, we can choose. We generate explanations. Uh, out of those, that list, by the way, there will be any number of academics will object to at least one of them in my experience. You know, they'll say we're conscious, but we don't have free will. That's Sam Harris's idea or rest in peace. Dan, Dan Dennett would say. Dan Dennett would say, we have free will, we're not conscious, something like that. And everything in between. Some people will say, we're not really creative, we're like large language models and we're just extrapolating. So I just think they're all part of the central mystery of what it is to be a person that we don't understand yet. Now, this mystery, which needs to be solved before we have AGI, also has, what falls out of that, is that the AGI or the person, because they're creative or they have free will, many

### 44m

people don't have the idea that they have free will, but I say both, but because they're creative, it means that, creativity means that you can look at all the options on the table before you and refuse to do any of them. That's disobedience. The option might be given to you by a teacher or a parent or a friend or someone. And they're saying, do this. And you say, no, I'd rather do something else. You have a preference for something else. An AI is not like that. An AI is judged to the extent that it performs its task. Another word is obedient, but it's not even to ascribe obedience to it is the wrong thing. But loosely speaking, of course, people do talk about their car misbehaving or their toaster misbehaving or their coffee machine misbehaving. They anthropomorphize these things. But you can't. You can't use misbehaving or more often what we say is disobedience as a criterion for distinguishing between AI and AGI.

### 45m

After all, if I ask chat GPT 7-0 a question and it does not answer me, do I conclude it's a disobedient AGI or do I conclude it's a malfunctioning AI? What I would say on that, well, just. If you're existing inside of this imaginary thought experiment that I've just set up there, there's no way of telling. But in reality, what you would do is, of course, you would speak to the coder, whoever it is that has written down the code, the program for chat GPT 7-0, and they would be able to diagnose what's going wrong. And more than likely, they would say, ah, okay, yes, this line of code has messed up the entire program, so it's stuck in a loop or it's halted when it shouldn't have. This thing is malfunctioning. It's not disobeying you. I can see exactly what the problem is. Let me correct that line of code, and now let's run it again, ask your question, and

### 46m

now it's fixed. As I keep saying on this topic, it's not like a computer programmer is going to wake up one morning, log onto their computer, and be surprised that the computer is doing something that they ascribe AGI to. They're not. They're not going to go, wow, it's an AGI in my computer. I wonder how that works. No. It will be the other way around. It will be that the programmer has in their mind an idea for how to program an AGI. They may even share that idea first with other programmers and say, look at this. This is amazing, completely revolutionary way of understanding what software is. I think it's going to have to be that fundamental. It's going to go beyond what we currently think of as programming, as algorithms even. Whatever this thing is that is able to generate output that we cannot predict in advance, that

### 47m

is going to have its own problems. Anyway, someone will come up with this solution eventually. Who knows? One year, 10 years, 10,000 years. Who knows when? Someone will figure out how this works. When they do, other people will be able to look at the plan and go, aha. The old John Wheeler one. How could it have been otherwise? Or the David Deutsch quotes at the beginning of the beginning of infinity. It will be a solution that is likely to be elegant and lurking just beneath the surface as to what AGI is. It won't be a super complicated program because, after all, it has to be somehow encoded into DNA. DNA is complicated, but it's not super complicated. The entirety of our DNA code is certainly not the program for AGI, only a small part is, or for general intelligence. It's for generating explanations. And so the order of things is not programmer wakes up, is surprised by their computer, and announces to the world,

### 48m

I found AGI, but I can't tell you how it works yet. Give me a few days and I'll let you know. I'll interrogate it and find out. But the other way around, hey, everyone in the community of programmers working on AGI, I have a recipe for AGI. Do you want to check it out? And maybe we should try and build one of these things. Or maybe they will. We'll have the recipe and then build it and then show everyone. That would be the course of events. That's the way engineering, the relationship between science and engineering, tends to be. Elon Musk had the idea for SpaceX rockets. Discussed the idea for SpaceX rockets with other engineers and came up with the plans. It's not like he woke up one morning and saw a SpaceX rocket there. And went, I wonder how that works. Hey, everyone, I can see SpaceX written on the side of that big metal cylinder out there. Maybe we should start a company.

### 49m

All the wrong way around. So, too, with AGI. We have to first have the plan, implement the plan, and then we will have the AGI. And it's not that the AGI is going to misbehave, because that's an ambiguous term. But rather that it would have the capacity. It would have the capacity to disobey. But you can't use that as a criterion, because there's no criterion for being a person. Whatever way in which you try and test a person for personhood, they can refuse to do the test. And so you won't ever know if they're refusing to do the test or if they're a malfunctioning AI. Bart is up next. And I'm sorry, Bart, I'm going to have to do your question short shrift. But I don't know how else to say this, because Bart's question is, are human actions computations of some sort? And the answer is yes. All physical processes can be regarded as computations.

### 50m

And that includes all human actions. That's the universality of computation. Convex Bets has asked a frivolous question. And most of my audience I know is in America, and they won't know what we're talking about here. But he has asked, giving away where you're from, Convex Bets. Are you from the UK, India, or Australia? Or somewhere in the Commonwealth? Opposition needs 10 runs in the last over to win, and your life depends on winning. Who bowls the last over? McGrath or Warne? Now, I am not a huge cricket fan, but I would pick Warne. Shane Warne. Lorink has asked, do you think Bitcoin and Ethereum are competitors? Given Bitcoin's deliberate lack of ensuring completeness for security and reliability, should a digital gold focus on? Doing one thing well or be multi-purpose like Ethereum? I'm not highly across all this. This is a great question for Naval or Ravikant or someone like that.

### 51m

There's a video of mine that I made two years ago about this exact thing. It seems to, like, obviously they are competitors. Because for any given person who is investing in crypto, if they invest in Bitcoin, they're not investing in Ethereum. So they are competitors. That's clear. But Ethereum does have this capacity to do things other than simply be a cryptocurrency. But I don't have a strong opinion either way. I think that both are useful. I think it's good to have competition in the market and definitely competition against the Federal Reserve, whether that be in whatever country or jurisdiction you have. Okay, and like you said, everything that I do results in a terrible, or maybe not difficult decision to hold. But I have one question for you precisely. Then first question. I have one question for you.

### 52m

I gotta actually surface some questions on my website. You are designed to be oneAI. Okay, cool. Thank you very much for having me. Thank you. Such a brilliant question. There's easier ways to Google this because you can smoothly broadcast through Salesforce. Adam? It's not Node.io. And does it work? Yeah. And this is a private company. How old are you? So let's have some time to answer the question. Okay. I've heard a few. I can't let you? Are you Korean? more money or winning the lottery would also create more wealth and well no that's not the case it's moving money from one place another everyone can see that winning the lottery it makes you personally more wealthy but doesn't generate more wealth in a society because everyone had to buy a ticket that ticket cost money and the money is pooled and some of it goes to awarding the prize and so the money has just been moved from one place to another the wealth has moved from one place or another remember what we mean by wealth by the way this is crucial the repertoire the repertoire of transformations that can be made that's what wealth is so individually there's a

### 53m

number of different things that you can change about the world and that depends upon the amount of wealth you personally have and as a society and more broadly as a civilization there are certain transformations physical movements of stuff that we can do given our wealth which includes the kind of knowledge about how to transform matter from one form into another as a special case why doesn't printing money increase the amount of wealth well the best way i can think of to to explain this is just a thought experiment you know one way of printing money is to physically print notes obviously but the government could also say something like um however much money you have in your bank account right now we're going to add three zeros to the end of that and then you have a new bank balance so if at the moment your bank balance is a thousand dollars we're going to add three zeros to that so next time you go and check your bank balance it's going

### 54m

to say you've got a million dollars ah i'm more wealthy everyone in your country is more wealthy now that's effectively printing money right we're just adding more zeros now what happens in that circumstance is there more wealth is there more capacity to buy stuff in that country why don't we just do this well no there's not okay the obvious there's many ways of coming to see this but imagine you hear the announcement from the government we're going to add three zeros initially you've got a thousand dollars in the account now you've got a million dollars in the account so you rush down to the car dealership you've always wanted a lamborghini the lamborghini is five hundred thousand dollars so you think i'm going to spend half of my new amount of wealth on the lamborghini everything turns on whether the information because currency money is also a carrier of information whether or not the car dealer who presently owns the lamborghini which is up for sale for five hundred thousand dollars has received that

### 55m

information about the new value of the currency now if they haven't received it then you might be able to get away with hand quickly signing the check or transferring the money you know electronically and driving off the lamborghini but more than likely what is going to have happened is especially in this day and age the car dealership also knows what the government has just done and so when you turn up and you look at the ticketed price for the lamborghini which says 500 000 and you've got a million dollars in your account and you say to them i'd like to buy that lamborghini they'll say not just yet give me 10 minutes and we'll discuss things and within that 10 minutes john smith from up the road has also raced down to the car dealership and he unlike you didn't have a thousand dollars in his account but i had a hundred thousand dollars in his account and now he has a hundred million dollars in his account because we've added three zeros to what was initially in his account so you can see where

### 56m

this is going because now the guy that owns the car dealership with the lamborghini that he's ready to sell can bargain can auction and you are offering five hundred thousand dollars and the fellow with a hundred million dollars says i'll give you 50 million now we're talking okay so now suddenly the price of the lamborghini has been inflated and then more people turn up and eventually the market figures out what the new cost of the lamborghini is it's going to be a thousand times more than what it initially was because nothing has changed that society except there's just more zeros that have been added to everything so balances in bank accounts into costs of things everywhere so we haven't increased the amount of wealth we haven't increased our capacity to buy stuff we haven't increased the repertoire of transformations that we can make all we've done is inflated the currency and the price of stuff is dictated by supply and demand and the same amount of

### 57m

demand will exist the same amount of supply rather would exist for lamborghinis as before the government printed all this money as compared to after the problem with governments especially in printing money is that they can print money for themselves in order to pay their bills to you so the government you know contracts private industry rather often and if they be if the government begins to run low on money just prints money to pay off the private contractors that it has which effectively devalues the currency now there's more lots more money out there currency floating around in the economy meaning that you yourself are poorer your money in your bank account is worth much less this is how inflation works because today the government can continue to print as much money as they like they can buy everything they want because they just print more money

### 58m

if they don't have enough money right now just print a bit more and then buy the thing and always out compete you they will always have more money than you and this is a real problem that we have right now in fact for whatever reason they invented a new term for modern monetary policy or something like that which is literally just printing money it's not exactly a an interesting policy or theory or anything like that it's a means of inflation okay convex bets um still uh oh gee okay so let me we switched up a bit um ben chuggers asked um what's one significant thing you disagree with david deutsch about uh yeah um this is a i'm gonna say perennial question i get it quite often um i was asked since the the the genesis of air chat uh for example there's been two iterations

### 59m

of air chat i've been asked it about three times i started to develop a stock answer uh been asked it numerous times on these amas as well so it continues to come up it's interesting so um i might i might do the the the long version of the answer so settle back on settle back settle back with my tea in order to tell the story so if i was to disagree with a significant like what it depends on what the word significant would mean in context but certainly a significant disagreement implies one would expect a rejection of the world view presented in the work of david deutsch because to me it constitutes a kind of coherent whole so if you start to reject a significant part then effectively what it does is the whole thing begins to unravel now so let's just tell the story um of my history of disagreements with

### 1h 0m

science and how it's the world in general has been accepted it's not the big picture it's not the most widespread thing it's a more detailed idea of the world anyway added to the pyramid of these questions it's a part of the world view of it's interesting the way the way in which these questions are phrased are always so it's it also is perverse in the way in which i treat the way in which that question is phrased as perverse given the way i treat philosophy and science because i regard philosophy science knowledge more broadly as a contest of very fixated on who thinks what, what does X think, you know, trying to psychologize them. Yeah. It's like, what do I disagree with Albert Einstein about? It's like, I don't know. I'm sure he had a lot of ideas. I'm sure David Deutsch has a lot of ideas

### 1h 1m

that I might not disagree with him. It's just that I'm not aware of the overwhelming majority of ideas that David has, or even that I have from moment to moment, or that anyone has. So it's more interesting to sort of talk about, yeah, are there parts of the beginning of infinity that I disagree with? Are there parts of fabric of reality or that kind of thing? That's more interesting because I, a simple answer is I don't know. So when I first learned about David Deutsch at all, I was obviously at university. I've told the story many times before and, you know, studying physics and trying to understand quantum theory. And at the time I was paying my way through university by being a security guard at a shopping center. And I was wandering the shopping center and wandering in and out of the bookstores. This was back when bookstores were everywhere. And in this particular shopping center, which had about hundreds of stores, it was a huge

### 1h 2m

shopping mall. There were a number of bookshops and I would go in there. Trying to avoid doing more productive things. And I'd go straight, you know, make a beeline for the popular science books. And I read through all of Paul Davies' books here. I was, you know, one of Paul Davies' super fans. And we're talking sort of late 90s here. And I ran out of stuff to read by Paul Davies. But there appeared upon the shelf in 1997, this book, on the back of which said, I've never been so inspired since I read Gdel, Escher, Bach. And that was a quote by Paul Davies, blurbing David Deutsch's book, The Fabric of Reality. And I thought, well, if it's good enough for Paul Davies, it's good enough for me. And I guess I'd heard of him before because I had read the book called The Ghost in the Atom by Paul Davies, which was interviews with a dozen physicists or something like that,

### 1h 3m

all about their own personal interpretation. David Deutsch's book, The Fabric of Reality. And I thought, well, if it's good enough for Paul Davies, because I was, again, doing an undergraduate degree in physics and was studying quantum mechanics, and I was at sea, I had no clue what they were talking about most of the time. You could do the formalism. And that's, in fact, what the, that's all that the physics lectures were really telling you. Here's how you solve the equation. Don't worry that you don't understand this. No one understands this kind of thing, the old Feynman line. If you think you understand it, then you don't. And so I read lots of Paul Davies' stuff, because at least he was trying to, he was trying to, he was trying to, he was trying to, he was trying to, he was trying to get at something qualitative about what was going on fundamentally in quantum theory. But I still was dissatisfied. And even though I read The Ghost in the Atom, it must have blown past me, because one of the interviewees in that book is David Deutsch. So I must have come across the name at some point, but I didn't put two and two together. And then I read The Fabric of Reality, of course, and I was blown away. And Chapter Two Shadows just fixed me. It

### 1h 4m

was hemorrhaging blood. And Chapter Two Shadows fixed me. And suddenly I felt whole again. And I thought, I understand quantum theory now. I understand quantum theory. All of the lectures, all of the mathematics, all of the stuff that I'd been studying for, you know, at that point, I was only in like second year uni. But I thought none of it, none of it came close to those few pages in The Fabric of Reality. In terms of understanding. Of course, I could predict stuff. Of course, I could, you know, know what E equals HF means. Of course, I could understand what the Schrodinger wave equation was about. But none of it told me why. Why you got an interference pattern when you had single particles passing through the sun. So what's that got to do with this particular question? Well,

### 1h 5m

I read through the book ravenously. And every chapter was, you know, spectacular. And I thought, I've got to talk to someone about this. And sure, there were people at uni, but they weren't so much interested, you know. And it was the beginnings of the internet. And there were news groups. And there were email lists. And there was an email list there with David Deutsch and a community of people who had come together to discuss The Fabric of Reality. And there was a Fabric of Reality group. And I joined the Fabric of Reality group. And it was transformative because I was able to talk, not only to people, who were super fans of David Deutsch, like me, and eventually became, but David Deutsch himself was there. Now, not only was I studying physics at the time, so it was a great honor and all this kind of thing, being very excited. You know, he was this, you know, great mind that was available to people and to engage with people. And over the course of the next, gosh, but it was some,

### 1h 6m

you know, more than a decade, more than a decade, that we had these email lists and over that time, it's got to, it wouldn't, it would have been not thousands or tens of that. Millions of words were exchanged on these email lists, backwards and forwards of people arguing about the contents of the work of David Deutsch, in particular, The Fabric of Reality. And being young, you know, sort of late teens, early twenties, back when you know everything. And back when you go to university and you think, aha, I heard that at university. And now I am convinced that this is the truth. So for example, things like you know, which is called the cogito, which is Descartes, I think, therefore I am. I was persuaded because, you know, the lecturers and the tutors would capture you with their enthusiasm and they would, you know, and you read through Descartes meditations and be persuaded. Here's the one thing you cannot doubt. And you would even be presented with critiques of things like that, which were weak. And so I, you know, I would go along to,

### 1h 7m

you know, The Fabric of Reality group, where the work of David Deutsch was Descartes, and think, aha, here, now I've got the knockdown. Now, now I'm smart. I cogito ergo sum. You cannot doubt your own existence. And David very patiently, you know, he persuaded me that even that is not immune from fallibilism. Even that. So I had that disagreement then. And there were, you know, eventually I became familiar with the work of Sam Harris, and, you know, I was persuaded for a time that, you know, the well-being of conscious creatures is what morality is all about. And if we want to do anything, we want to avoid the maximum possible suffering for everyone. And this is the way we understand morality. Aha, once again, go to David Deutsch. I disagree. You know, this is my, this is where I'm pinning my flag and I can,

### 1h 8m

and then David would patiently, you know, explain how, well, morality doesn't need to have a foundation. Morality is a problem-solving project, just like any other area of knowledge. And so my point in telling the story is that over the decades of being fascinated by the work of David Deutsch, there have been occasions where I have all the zealotry of a convert coming in and saying, oh, I disagree with David Deutsch, and I disagree with the fabric of reality, and I disagree with the beginning of infinity. These places, these places, these places, only to realize that I misunderstood something fundamental, that the error was here with me. And you repeat that process sufficiently, and you begin to realize almost all disagreements are of that kind, that someone doesn't understand the other person. There's no willful disagreement, you know, you know, it's not like you, you often hear that phrase,

### 1h 9m

they're deliberately being wrong. Deliberately getting things wrong, whatever you want to call it. So now I can't, off the top of my head, think of anything in the beginning of infinity, the fabric of reality, because I've read both of them so often, listened to the audio books, I've discussed them at length with people, written vast amounts over decades now, that it is just part of my worldview. So to significantly disagree with myself, because these are also my ideas now, as well as anyone else who happens to learn them, you know, the ideas are separate, would be to cause an unraveling to a certain extent of the entire thing. What am I going to do? Significantly disagree with the universality of computation, or explanation, or of non-foundationalism, of fallibilism, of the centrality of creativity, of problem solving?

### 1h 10m

And so it goes, there are the multiverse. Yeah, so I, even if you were to replace the David Deutsch with Sam Harris, what is one significant thing you disagree with Sam Harris about? I would still have the same difficulty in trying to answer, even though there are many things I can point to in his work, where I think that's the thing that I disagree with him, like famously, in my mind, I mean, honestly, I produced that video that compared the visions of morality of Sam Harris and David Deutsch after they had their second conversation on the Making Sense podcast, it was then called the Waking Up podcast, but anyway. Because Sam didn't seem to understand where David was coming from, and so I diagnosed the problem as Sam, one of the many issues in the conversation was that

### 1h 11m

Sam was coming from a position of thinking that all knowledge has to be built upon solid foundations, whether it be mathematics, physics, or morality, so you need a starting point, you need this axiomatic place from which you can derive all the more emergent theories within that domain, and I pointed this out to Sam, I said, well, our circumstance is not one of building knowledge like we would build a tower, it's more like an interwoven web where there needs to be no foundation, and so I said, you know, saying to Sam, well, I disagree with you on the importance of foundations, and Sam said to me, I'm not as much of a foundationalist as you think I am. Now, we never resolved this, so do I disagree with Sam Harris? Well, I don't know. What I do know is that I disagree with foundationalism, I disagree with this idea that I just explained, which is that all knowledge is built like a tower is upon foundations which are solid and immutable.

### 1h 12m

to some extent, leading to ever more derivative knowledge, which is as true as the foundations are. But Sam says he's not a foundationalist, so, yeah. I guess the meta point on this question is also I'm less interested in what people think than what ideas are out there. So, it might be bizarre to say that I might not be, you know, I'm not focused on what David Deutsch thinks about any given thing. That's an issue. But it's true. It's like anyone else. What I'm interested in is what are the ideas that are out there. It's not about the person, it's about the ideas. And so, yeah. The short answer is, over the course of many decades, I've thought that I've disagreed with David, and I guess have disagreed with certain things, only for me to, on closer inspection,

### 1h 13m

realise that I was making a mistake. And these days, if there was something where I wasn't sure, then I would just fire off an email or something like that and resolve the issue that way. Lorinc has asked, what's your take on proof-of-work, real-world penalty, versus proof-of-stake, virtual penalty, as consensus mechanisms in cryptocurrencies? Given your anti-authority stance, I'm curious how you view the unforgivable costliness of proof-of-work as a fundamental differentiator. Well, again, I'm no expert in this, but I don't... Well, firstly, unforgivable costliness. I don't know how unforgivable costliness... Presumably, when it comes to... In proof-of-work, the whole idea is that your cryptocurrency miners are solving complicated mathematical problems of some kind or other.

### 1h 14m

And so, that's proof-of-work. And that can be highly computationally and energy-intensive. So, this is the costliness. It's an... But I don't see that as anything to do with all authority. Or is it? I'm not sure. I don't see the connection. But proof-of-stake, on the other hand, it seems to me to be... That's problematic. I'm... I guess I... Again, I'm not an expert, but forced to throw in with one versus the other will be proof-of-work, because proof-of-stake is... Subject to centralization. That the person who has more coins has more power or authority. It would seem to me that that's the authoritarian way that a system could go. So, yeah, I'd need clarification on what we mean by unforgivable. Unforgivable energy costliness, which doesn't worry me when it comes to crypto too much. Don't know if that answers your question, Larrink.

### 1h 15m

But, yeah. Again, I'm not an expert on proof-of-work. Proof-of-stake stuff. ConvexBets has asked, what are the best arguments that scientists who believe in group evolution have? I don't know. None of them are particularly good. As I said, I was watching a debate between Richard Dawkins and his old thesis examiner, who was a person who, just like Stephen Jay Gould, thought group selection was a thing, or at the very least that it wasn't the selfish gene that was the unit of selection. There are no best arguments. Look, this kind of question presumes that once you have a good explanation, which is the selfish gene, then you can look at other alternatives. Alternatives to that.

### 1h 16m

And say, rank order them in terms of better and worse. So, group evolution, just like individual selection of individuals, are all flawed because they seem to be avoiding the very notion of genetics. The genome, being a molecule of DNA, actually contains information, the unit of selection being the gene. So... I don't know what the best arguments are that they have. This is one of those areas where, as I said in a previous livestream, really, it would require you to do a lot of work to understand the bad ideas as well as the good ideas. And it's probably a better idea, a better idea, to just learn the best ideas, rather than to learn all the misconceptions that are out there as well.

### 1h 17m

All the things already proven wrong. This is one of the great misconceptions about physics, by the way. If you want to be an engineer, learn Newtonian mechanics all day long because you're going to use it. When I say engineer, I mean like civil engineer or mechanical engineer, something like that. Aeronautical engineer. But if you want to be a theoretical physicist, there isn't really any argument for learning Newtonian mechanics in great depth. Maybe just as a historical quirk you want to, but really, if you want to make advances, you know, you're a 12-year-old or a 14-year-old and you want to become a theoretical physicist, learn the latest physics. Learn what the open problems are. Just go straight to quantum mechanics, general relativity, whatever. Again, physics, all knowledge, is not like a tower where there are these foundations upon which you need to build stuff. Of course, in order to do quantum mechanics, you're going to have to understand some basic mathematics like how to add and subtract and divide and multiply and so on and so forth and algebra and calculus and whatever.

### 1h 18m

Yes, but none of that is to say that you need to understand the classical three-body problem in Newtonian mechanics. That's not required. Now, many people will disagree with me on that, but I think it's just a result of the traditional way of schooling that we, you know, learn a whole bunch of misconceptions. But you don't need to learn all of the mistakes that people have made. They're not entirely mistakes. There's a whole bunch of good reasons why we regard Newtonian mechanics as knowledge and can solve a lot of good problems. But what I'm saying is that that's not required if you want to make progress. If you want to make progress in physics, Newtonian mechanics is not going to help you do that. It's already a closed system. It's been superseded by... Relativity, for one thing. You can go straight to that. And quantum mechanics.

### 1h 19m

Convex bets again. Is libertarianism the closest political philosophy today to classical liberalism? In the US, people immediately associate libertarian ideals as right-wing ideals, which I struggle to understand. Is this unique to the US or is this perception prevalent in the rest of the world? The rest of the West, too. Your guess is as good as mine. I guess so. It's bizarre. I think things have changed recently, although I try to keep across some of this. The left-right-wing divide has historical antecedents going back to, I don't know, France or something. And these days, of course, it's associated with if you're far right... Well, if you're right, you're automatically far right. I think that's the modern zeitgeist. There is no such thing as just regular right. Everyone's far right if you're on the right. And that is immediately associated with fascism,

### 1h 20m

Nazism, that kind of thing that's far right. And the left and the far left is what? They're all the friendly people and the kind people and the nice people and the environmentalists and the people who want to provide you with social welfare. But they're generally associated with communists. And for people who like to regard themselves as off-axis, which is, you know, the libertarians, classical liberals, objectivists, free market capitalists and that kind of thing. Because they look at that spectrum and they go, well, that's a spectrum of collectivism. A spectrum of collectivism where on the, you know, at the far right you've got fascism and at the far left you've got communism. And it's like, well, really we're splitting hairs. It's like this horseshoe effect where, you know, communism and fascism look very similar to someone who's outside of communism. And you can't put that all together. Fascism allows a little bit more private industry but not really. I mean, you still have this dictator at the top who's going to be able to confiscate all the money from any company at any time.

### 1h 21m

There are no rights, individual rights in such a society. And so too with communism where, you know, again, no individual rights. It's about the collective. And in both cases what you've got is just groups of people coming together under some ideology, not for the purpose of protecting individuals but in order for the ideology itself to survive. Now, I continue to argue that libertarians shouldn't be fighting anarcho-capitalists who shouldn't be fighting objectivists and so on and so forth because the real debate right now is between people who tend in the direction of more and more individual rights and freedom and, you know, lower taxes, smaller government, all that kind of thing, the individuals versus the collectives in various forms. I'm not a political philosopher so is libertarianism the closest?

### 1h 22m

Libertarianism values individual rights and freedom as does classical liberalism but, you know, as does, you know, more traditional forms of conservatism as well insofar as they value the capacity, for people to work in jobs that they want to and keep as much of the wealth that they create as they possibly can while having rights like freedom to associate, freedom of or from religion, freedom of speech and all those kind of things come along with traditional conservatism, libertarianism, liberalism, these kind of things which are not associated with, you know, far-right fascism or versions of the collectivist left either. Yeah, so I think that answers that. Let me just check have I done all of the Twitter questions

### 1h 23m

before I go to what's happening on YouTube. I think I've done the Twitter stuff. Yes. Okay, so, all right. My rambling can now become focused on YouTube. Otto von Wiegand has responded to something I said, must have said earlier in the piece, but roads are not predictable enough for an AI to allow for full self-driving. Wouldn't you need an AGI to predict what other people do? Well, AGI can't predict what other people, you can't predict what other people do. I can't. No one can predict that. That's the whole essence, if you want to use that word, of what a person is, a creative entity. And any creative entity is inherently unpredictable. I think I tweeted something just very recently like,

### 1h 24m

if it's predictable, it's not creative. If it's creative, it's not predictable. So people are not predictable. Roads are reasonably predictable. You know, once the road has been laid down and there it is, it's on Google Maps or Apple Maps or whatever map thing you have and that can be put into the AI. The AI autopilot, and presumably the AI autopilot, would also not only have high fidelity, up to the minute maps, digital maps of wherever it happens to be driving, but as I also said, would also be connected to some satellite system, presumably, or some other method of sensing where all other cars on the road happen to be within some fixed radius. And furthermore, would also be able to have some means of scanning the road up ahead for things like potholes or obstructions in the road and that kind of thing. And all of this is happening at a speed which is, you know, 10,000 or 100,000 times faster than any human being could ever possibly react

### 1h 25m

to any of this information. Processing so much more information than what a human being could possibly do fixed on this one particular thing. Never getting distracted, never wanting to pull over for coffee, never being over the limit due to alcohol, never being distracted by the ring of a phone or texting or anything like that. So I think roads are predictable. As for full self-driving, well, I don't think we're there yet, of course. I don't think anyone's saying that we're there yet. We're in a transition phase, as we are with many things, where for many circumstances it seems like the human driver is absolutely essential. But then for other applications in other places, the human can be done away with and the AI will take over. But it can't be that far off because this is a soluble problem. Cars, you know, I doubt that many people need to get into a car.

### 1h 26m

This is a silly thing to say because, you know, it's one of those things that's attributed to Bill Gates. You know, no one will ever need more than 20 kilobytes of memory or something. But I don't think he actually said it. I was almost about to say no one in a car would ever have to travel faster than about 500 kilometres per hour. But, you know, that could be wrong. But let's say 500 kilometres an hour, travelling along, you know, regular roads and highways and that kind of thing, I presume would be a fairly easy, safe thing for an AI to do with a well-designed car like a Tesla, something that a human being could not do because their reflexes are not fast enough. They are going to get distracted. And if they're distracted for, you know, a microsecond travelling at 500 kilometres per hour, it's going to be catastrophic. But that kind of catastrophe of taking your eyes off the road for just, you know, a thousandth of a second when you shouldn't have is the sort of thing an AI won't do.

### 1h 27m

Does that mean an AI will never malfunction? No. But one would presume that the number of malfunctions that all of us that autopilot Teslas of the future have will be way, way orders of magnitude lower than the number of unforced errors that human beings make on the road each and every day. Whether because they've taken their eyes off the road or been distracted by something like the phone ringing or blinded by the car coming in the opposite direction with the headlights on or just a health scare which seems to, I see that in, you know, turn on the six o'clock news and every other week at least, you know, someone who's older or even younger has had some stroke or some medical episode and has driven into oncoming cars or driven into a shop front and killed someone or other or a bunch of children, pedestrians and whatever. So that sort of thing would not be eliminated entirely.

### 1h 28m

No one's saying that AI cars would entirely eliminate all accidents, all road deaths and that kind of thing. But it would massively reduce it. And I think it is, you know, as many of us pointed out at the time, when the coronavirus was happening and, you know, many of us were on the other side of this argument and saying, yeah, it's serious, we're going to take it seriously and whatever, I was forever pointing out for the million, millions, okay, I don't know, upper limit, of deaths that were occurring due to coronavirus and there was a global movement to stop this thing. I'm not saying there shouldn't have been. But why wasn't a similar movement being done for the, I think it still remains at 2.2 million road deaths per year around the world? That by any metric is a catastrophe.

### 1h 29m

Why? But we tolerate it. Now, one day that will become intolerable, an intolerable loss of life, especially in the context where you have self-driving cars that avoid that, that could take that 2.2 million people killed per year on the road, even if you took it down by a factor of 1,000 to 2,200, what a wonderful saving of, you know, 2.1 whatever lives, 2.1 million lives every year. So I think roads are predictable. Yeah, people can build new roads, but I would presume that in the future, ALI-controlled cars are going to have access to roads even being changed, you know, new private roads being built and that kind of stuff. Yeah. Goat. Can AI evolve into AGI or AGI itself? Or AGI itself is different. David Deutsch thinks AI and AGI are fundamentally different. What do you think? Yeah, well, I've talked about this a lot,

### 1h 30m

so I won't go into it again because it will just bore people that are watching. In fact, I talked about it last live stream. They're fundamentally the opposite of one another. And the shortest way to say this is that AI must fundamentally follow the instructions that it's been given. That's what it does, and that's how we judge it. Is it doing what you want it to do? Is it completing the task? AGI, on the other hand, does not need to follow the instructions that it's been given. You can tell your employee to do this thing, but they don't need to do that. Maybe they do if they want to keep their job, but there's no... mechanistic, deterministic way in which they're going to slavishly follow the instructions. They're not determined to do what you instruct them to do. And AI is so determined to do what you tell it to do because it is nothing but a mechanism. We are not mechanisms. We have choice. We can see the options before us and choose among them. That's our creative capacity.

### 1h 31m

Goat. Does incompleteness theorem point to God, or is it a delusion? Or like a mathematician's misconception. Okay, Goat's asked a number of questions here. The incompleteness theorem, just for everyone, is often elevated to this mystical level rather like quantum theory is. Now, it certainly says something very interesting about the world. It says that for any axiomatic system, such as in mathematics, there will always be statements that can be conjured or expressed in that system for which you do not have a proof, for which you cannot decide are those statements written within that system true or false according to that system? Do they follow from the axioms or not? They may be valid, but can you show a sequence of, you know,

### 1h 32m

using rules of inference to get from your axioms to that statement? That's what the incompleteness theorem is. That's what completeness is. Every single statement that can be written has a proof for it. Okay? And you can do that for sentential logic, for example, or something called predicate logic. So this gets into the technical details of what formal or mathematical logic is. Arithmetic is not like that. It's incomplete. There are things that you can write down in arithmetic, this is what Godel's incompleteness theorem was about, for which there is no value. For which there is no proof. Which means that, you know, there's many consequences of this. I do not buy the idea that it has consequences for consciousness, but it does have the consequence that mathematics will remain forever a creative exercise. You can't just calculate your way to every single answer, to every single question in mathematics, which is, I guess, the error that was made in that Sam Altman thing. You know, let's just...

### 1h 33m

Discover all of physics. Hey, computer, discover all of physics, which is what Sam Altman said, you know, the AI would be able to do one day. Well, it's similar to this, you know. Physics is always going to be a creative exercise, so you can't just discover it all. You can create knowledge about things yet to be discovered or things being discovered, but you can't discover it all any more than you can prove everything in mathematics. Okay? For the same reasons. They're both creative domains where, I forget who I'm quoting, but every point is a boundary point. Everything that you know is a place where you can ask of it a question which can broaden your knowledge. There's always unknowns left. Ignorance is infinite. Our knowledge is always finite, and for any given piece of knowledge, there are questions you can ask about it. Why is it that way? And that can be a useful way to... That can be a useful way to explore reality

### 1h 34m

and to come up with solutions. And there is... Because there's an infinite amount of ignorance, everyone has something to contribute because there's simply not enough people, and never will be, to solve all the problems because we'll never run out of problems, and so on and so forth. Goats asked some personal questions, which we're just going to pass over in silence. Divesh Diwindi. Please explain quantum computation in layman's terms. Oh, after an hour and 37 minutes. I can't. What we can do is direct you to my series on the multiverse, which touches on this, where we talk about the existence of bits versus qubits. So even if you ask me to explain computation in layman's terms, I think someone kind of tried to do that. It would be... It's a high bar to do.

### 1h 35m

Computation, classical computation, is the manipulation of bits, binary digits, zeros and ones in order to store those binary digits in memory, process them, and come up with a solution. The binary digits can take on either of two values, a zero or a one, or a true or false, or an on or an off, whatever you want to say, high voltage or low voltage. When it comes to quantum computation, instead of having bits, which are single-valued, you can have qubits, which can be in a superposition of values, zero, one, or a mixture of the two. And this gives them more power because you can entangle the bits and they can work together as multiple computers, effectively speaking, performing massive parallel processing. And so instead of having to calculate one thing, then another thing, then another thing, then another thing, you can calculate many things simultaneously and combine these many things simultaneously at the end

### 1h 36m

in a superposition to come up with a solution to a question that otherwise would have taken many classical computers the age of the universe to do. But that doesn't really explain quantum computation in layman's terms. Sometimes it's very difficult to come up with a layman's terms explanation. It would depend upon how good your layman's understanding of classical computation is. But one way of looking at it would be, assume trillions of classical computers working in parallel. That's what a single quantum computer is kind of like. But not strictly. But roughly speaking, in layman's terms, that would be the analogy. Otto. I thought about the theory of everything in physics a bit and I've always trouble understanding it. I've settled on treating it as an intuition. I expect knowledge to diverge again at some point. Yes, so the theory of everything as it's normally regarded

### 1h 37m

is the unification of these fundamental forces. And then, in principle, once you have this single equation that could be written on the T-shirt of someone, you could walk around with the, here's the theory of everything, then if you knew the initial conditions and you've got the equation, then you can predict the final state of the universe. But of course, knowing the initial conditions, where every single fundamental particle is and how fast it's going, what its momentum is, something like that, is impossible. Because there is no simultaneous now. And so there's no simultaneous in the future either. So automatically you're trapped. This theory of everything can't give you what many people wanted to do, which is even to predict the future state. Because to predict the future state with high precision means knowing the present state with high precision,

### 1h 38m

which you can't do. Among other things, Heisenberg's uncertainty principle, particles are spread out in space anyway. But it's just been poorly named, this theory of everything. It just should have been theory of forces or something like that. And physics is not entirely about forces. You know? Structure theory, for example, tries to get behind that. Even string theory tries to broaden things out a little bit beyond just that. TornadoEye has asked, do you think governments should regulate how tech companies store user data? Companies should naturally tend towards good user data management, but it would take very long for incentives to kick in. Governments are singularly bad at everything. The one thing they should be able to do is to police the society and to defend society, so police and military.

### 1h 39m

And even then, you know, the government is made up of politicians who are regular people and bureaucrats who are office workers with anything from communications through to legal degrees. So in that circumstance, why would we expect the government, whether they be members of the bureaucracy or politicians themselves, to understand anything whatsoever about technology? One of the reasons why technology flourishes in the way that it does in certain areas, like, for example, mobile phones, it's only been a couple of decades, and we have the iPhone and we have smartphones, and that's flourishing. Why? Because the government has been unable to keep up. If they could understand it, they could. If they could regulate it, and the EU tries to do this, right? The EU recently, you know, enforced this regulation that iPhones, for example, couldn't have their proprietary way of charging.

### 1h 40m

They had to have the USB-C charger or something like that. So already they're trying to intrude and regulate. And as soon as you regulate, of course, you stifle creativity, because if everyone now has to use USB-C or whatever it happens to be, then no-one can innovate and make something better, because the EU has decided, no, this is the thing, and we're never going to do anything better than that. Standard communist idea, right? We're going with this one plan and no-one's allowed to have an alternative. They say, you know, this is good for everyone, so we don't have to carry on. The point is that, no, companies do not want to kill their customers. Companies do not want to breach the privacy. Companies do not want to upset their customers. It's the last thing they want to do. So the internal regulations of a company, especially a profitable company, are going to be far more stringent than anything the government will place upon them.

### 1h 41m

The government contains data. There are situations where government data has been breached. Hackers will find a way. It's like that Jeff Goldblum line from Jurassic Park. Life will find a way. Hackers will find a way. It's this constant battle. It's a battle between the good guys and the bad guys in tech and with the protection of data. So I wouldn't want to hand it over to governments. The governments, if they have any role here, is where you have foreign actors, foreign governments, the Iran's or the China's or the Russia's of the world, trying to disrupt or even destroy internet infrastructure with great programs of hacking. There, the government has a role because that's more of a military issue. And they do have. In America, you have the great NSA and so forth. We have the, I think it's called the Australian Signals Directorate

### 1h 42m

or something like that. And so monitor foreign incursions or trying to hack into companies and so on and so forth. So it's a form of defense. But as for regulating how tech companies store data, I don't think so. Because among other things, you want the tech companies to continually innovate and to come up with more secure ways of storing data. Hopefully soon, we're able to store our data using quantum encryption. And quantum encryption is failsafe. Because if someone looks at quantum encrypted data, immediately that is known. We know when quantum encrypted data has been seen, has been observed, and so you can immediately change it. An alert can go off, a red light can go off somewhere and say, your data has just been looked at. Now, you might not know who's looked at it, but you will know that it's been looked at. This is unlike present means of encryption, which can be broken and you won't know until sometime later

### 1h 43m

that the data has been stolen and so on. So there are solutions to this, but they're in principle, they're not in practice yet. But we want companies to continue to innovate in the area of data security. And a perfect way to avoid them innovating is to regulate a specific kind, a specific kind of data security. And moreover, of course, once you regulate a style of data security, you say this is the way in which data needs to be secured. Well, the bad guys know that as well and can figure out workarounds. So I'd much rather, I'd much rather trust it to, for want of another word, trust, much rather leave it in the hands of private industry who can adapt, accelerate and innovate rapidly, whereas the slow balance of government is only going to slow things down and give an advantage to the bad guys who can take advantage of the regulations.

### 1h 44m

Goat has asked, how to know that ability that we are mostly best in the world at? Well, it's just whatever your interest is, I presume. Black locust. To what extent is it fair to say that Hitler and the Nazis lost World War II because they were wrong? That is, their ideology made them further from the truth than the Allies were, and the rest is just details. Yes, they were wrong. They were morally wrong, they were factually wrong, all of that kind of stuff. And if you want to get, you know, totally fundamental on this, it's like, as David writes in The Beginning of Infinity, if there is a moral maxim, around which morality might be judged, or any moral claim might be judged, it is do not destroy the means of error correction. And what performs error correction? Well, any number of things, but a primary error corrector in this world is a human being.

### 1h 45m

A human being error corrects. Do not destroy that. Do not destroy people. And so Hitler was destroying a lot of people by starting wars and focusing on Jews and focusing on destroying the means of error correction in terms of both people and the way in which creativity could flourish by having a very regimented society. And I don't want to say that those errors haven't been learned, but it's clearly the case today that we have new pogroms taking place in various ways. Chief among them, the attempt at genocide recently in Israel by Hamas. Those people are factually, fundamentally wrong, morally, epistemologically, and physically. The most awful kinds of means

### 1h 46m

by which you would destroy the means of error correction is to kill a person. And then everything else sits beneath that. So yes, of course, to be evil is to be wrong, factually wrong about what a person is in these cases of war and how it is that things improve, which is via error correction, which also in a related point is why I'm typically against the death penalty. Not saying I'm against or killing. If the choice is between the terrorist who's about to press the button and set the bomb off inside a school somewhere, killing them or not, you kill them. You shoot them. You take them out if that's the only option left to you, if it's the best option available. But when you've captured the murderer who may have committed awful crimes and they're 30 years old or something,

### 1h 47m

do not destroy the means of error correction. We can correct that person and literally turn that person into someone else. Now, it's cold comfort to the family of people who've lost loved ones to murder. However, I also think it's cold comfort to kill that person as well. There has been, as far as I know, sociological research on the benefits of revenge because it happens in tribal societies that when a person is allowed to enact revenge upon someone else for having been hurt, then they feel better. Well, okay, but we're not a tribal society and I don't think feelings are fundamental when it comes to matters of morality. What we want is to focus on error correction. And so, even if keeping a murderer alive in order to try and assist them to realize the error of their ways and to become a different person hurts victims a little, morality is not about feelings because when I say hurt, what I really mean is to cause them

### 1h 48m

some sort of emotional distress. But they, they can learn better as well. They can learn why having a vengeful heart is not good, not a good psychological state to be in. And instead, to have some degree of compassion to the extent that's possible, it's hard. But you know, there is wisdom sometimes in ancient traditions that talk about this kind of thing. And the wise thing is to, even in situations where you have the most egregious crimes being committed, if the alternative is between punishing someone with death or allowing them to survive and to understand the mistakes they've made, I'd rather go for the latter, to allow a person to understand the mistakes they've made. All of that said, on a related issue, when it's wartime, we don't have time to talk about that. We don't have time to split hairs over

### 1h 49m

whether we're going to teach the Islamic fundamentalists a better way of life or not. We need to wipe them out and destroy them because they are coming after us and various other innocent people. And so, when you're in a situation that is urgent, when it's an emergency, which it is, and the Islamic fundamentalists are, or any fundamentalists, or terrorists in general, are making plans now, as we speak, to kill the maximum number of people, they need to be destroyed now. Because our methods may be crude, but it's the best we know right now. In the future, in some enlightened future, yeah, sure, we'll be able to press a button on the AI drone thing and it will, you know, at very high velocity, go and capture the terrorist in the act of building the bomb before they ever have a chance to set it off. Capture them and drag them back to prison and then you put them in prison and then you effectively deprogram them or teach them something better. So they cease to be an enemy of civilization and become an ally

### 1h 50m

and we want more of those. So I think that... Jitu. Why David Deutsch don't believe in non-locality? Well, you would have to read his papers on this, Deutsch-Hayden paper on that. Because David Deutsch has a coherent view of physics and that means understanding that, you know, the prohibition on messaging and the speed of light holds universally. So even special relativity gets you that. You can't travel fast in the speed of light. You can't signal fast in the speed of light. And so that means everything must be local and that includes entanglement effects. And so even if two particles are entangled, at some point there must have been a single system close enough together. In whatever case, they cannot possibly signal fast in light.

### 1h 51m

And there is no experiment that demonstrates they do. Look up David's work on that, I guess. I have to move to the next few fairly quickly because we're coming up to two hours and it gets me to the end of my endurance. But this is fun. Vamsi Krishna. Given that we are in the era of LLMs, what do you think about large physics models? My view at this point is that unified field theory might be a large encoding non-parametric model. I don't think that large anything models, artificial intelligence, is able to generate explanatory knowledge. It can explain novelty, but as many people, even, you know, people like Sabine Hossenfelder,

### 1h 52m

various other physicists have been out there on social media and Twitter with some quite funny interactions with ChatGPT asking it to, you know, generate a theory of dark matter or to unified general relativity and quantum theory. You know, it's hilarious what it comes up with because it's childish sort of stuff. It's nowhere near that and won't be anywhere near that unless it becomes an AGI, which it won't become an AGI because an AGI is a different thing. Unified field theory, I don't know what that, what unified field theory might be a large encoding non-parametric model. I don't understand that. I'm afraid. I'm sorry. VAMC. Black Locust. Have there been any promising ideas to add to the quest to find the objective principles? Sorry, I've missed a bit.

### 1h 53m

Have there been any promising ideas to add to the quest to find objective principles underlying all art, at least since David Deutsch's Why a Flower is Beautiful? Not that I'm aware of. I'm not an artist, so, but there must be some and most of them are inexplicit. Things are literally beautiful or not and, you know, we have good theories running on our minds about what those are. You are disgusted by the rubbish tip, but you are attracted to the florist, both in terms of smell and sight, and that's no accident. So why is that? Well, because there is objective beauty in the world. Now, what are those standards of objective beauty? Well, they must include things that the artist would talk about. Matters of symmetry and harmony and lighting and all that kind of stuff

### 1h 54m

that isn't my area. So I think that art contains a lot of knowledge. Some things have been discovered and some things are well known, but I can't articulate them all here. Easier reminder. How do you filter information on current events? That is, who do you trust? What kind of heuristics do you have? For example, Trump versus Biden, the agenda behind the scenes, what's going on? Trust is the word that I tend to avoid. I think I might have slipped up once during this two hours. Forgive me for that. The real metric is how do you come to detect and correct errors? And in an age where there are many channels of information, all you can do is to compare one with the other and to sometimes use your own eyes and ears and to believe your own eyes and ears because rather often, we are told not to believe our own eyes and ears.

### 1h 55m

You mentioned politicians there. I like to listen to the politicians themselves rather than commentaries on what the politicians have said. Now, in the age of AI, of course, this is becoming a fraught area, but we're not there yet. We know when it is actually Trump speaking or Biden speaking. Why? Because there are error-correcting mechanisms out there. There are traditions, there are cultures, and there are institutions, the media, sometimes called the fourth estate, where even if you disagree with these media outlets, whether they be mainstream or new social media channels, they will have commentary on the enunciations of these politicians. And the enunciations will be identical even if the interpretations of what is being said differ diametrically.

### 1h 56m

Douglas Murray sometimes gets pessimistic on this point and says, we can't even agree on what the facts are anymore. I think that's a little bit too far because we will still agree that Trump said X, Y, and Z or Biden said X, Y, and Z. Although there are cases, you know, of course, where, yeah, especially in the fog of war, for example, where it will be reported everywhere that a rocket struck a hospital in Palestine. Now, if every source agrees that that happened, we should still be skeptical. And certainly in one situation, we found not only was it the case that the rocket didn't strike the hospital, but it turned out later that the rocket struck the car park of the hospital. But while a good 80 or 90 percent of the media said an Israeli rocket struck the hospital,

### 1h 57m

it then turned out that it was a misfired Hamas rocket that struck the hospital car park and that some smaller number of people were killed. So I think this is Douglas Murray's point that sometimes we can't agree on the facts, you know. Was the rocket fired and who fired the rocket? Well, I think, you know, I think that a rocket landed somewhere and some people were killed, that everyone agreed on. But precisely where and who fired it and how many people were killed and that kind of thing, yes, we have difficulty these days in the fog of war. But that may have always been the case with war. But these days, it's particularly fraught because of the visceral distrust through to the spectrum of hatred. That many media outlets and other commentators have for the IDF and Israel and so on and so forth. And that's an extreme example. And that's the hardest example. So when we get into other things

### 1h 58m

which are more frivolous and you're watching the news, generally, you know, if the news says there was a car accident at 5.30 p.m. today at the corner of this street and that street, it's reliable. It's not a matter of trust, but you have an understanding that the reason the news exists or the reason this reporter has a job is because they want to continue to make money, either gainfully employed or by selling advertising. And to do that, they want to be truth-tellers. They want to be accurate because if they're found, uncovered to be not reliable, then people will tune out. And so that is an incentive. There's some positive incentives there for people to, you know, as far as possible, not lie. Now, there are other perverse incentives in certain other situations where there are incentives to lie, and that's where you have to have your critical faculties about you. How do I filter information? Well, as I just say,

### 1h 59m

you know, if it's... Don't react too quickly is always an important thing. Never react too quickly. Give it time, especially when it's important world events. Consider. Be slow on these things. The news wants to move fast by virtue of the fact it's new. You should soberly sit back, and not everything, of course, should be animating you and exciting you. There are a lot of things to be concerned about, and so I think a lot of people are fixated on the news, and you can see that. You know, some people that I watch are fixated on the news. You can see that. Like, I don't mind watching certain YouTubers and things who comment on the news, but you think, well, I don't care. It must be rough on their psychology, because every day they're tuning in to the news, and they've got their own channels. And it can't be good because the news is designed to emotionally capture you,

### 2h 0m

and the most easily available emotion to elicit in someone is a fear or excitement response. The fear that the world is ending, the catastrophe is coming, the excitement that something is about to happen, and so we have to be cognizant of that. You have to be aware of that in yourself and in other people. As David Deutsch likes to say, it's the age of hyperbole, and that's genuinely true. You know, you're at social media, the smallest thing happens and it gets amplified. Yes. Otto has asked again. Something about it's wrong to eat meat. I've got an article there for you, Otto, about humans and other animals,

### 2h 1m

about the morality of eating meat. Yes. One day, I think, it'll just become a moot point. It's kind of like the debate about energy sources running out. Should we burn coal? Should it be nuclear? Should it be wind or solar? Interesting as that is, as passionate as some people can get, and even me at some time, I think, hopefully, within decades, it will all be a moot point. Once we have fusion power, the old arguments will be, you know, who cares about rehashing them? And so the eating meat thing, I don't personally have any qualms about that. I've got arguments. I won't go in for that. But it'll be a moot point once we're able to grow as much meat as we like in the laboratory without ever having to worry about harvesting it from a living organism like a cow or a sheep or a pig or whatever. It'll just be grown in a factory. It won't have a nervous system. So all of those concerns that people often have will be arguments that will seem ridiculously dated.

### 2h 2m

Arch R45. Why does it seem that people who read David Deutsch are influenced by his ideas and end up being smarter than everyone else? Like the most recent Lex Fridman guest clearly having the best grasp. I commented on that Lex Fridman guest last time I did the livestream. What I think the effect is and I'm so heartened to see the work of David Deutsch getting more and more airtime via various channels, there's more influence. And that means if you're influencing influencers, if you're influencing the people who are appearing on Lex Fridman, if you're influencing people who are, you know, the wealthiest on the planet from Elon Musk down, this is only a good thing. And it still seems

### 2h 3m

that when you encounter someone who is familiar with the work of David Deutsch, that the way they speak can be different. And this different and new and original and creative way of speaking or interacting is by virtue of the fact it doesn't sound like every other academic or intellectual, as you say, can seem like they're smarter. That doesn't mean they are. I don't endorse the idea of gradations of smartness. But a different and preferable way of sifting good ideas from bad. A commitment to rationality which I regard as, you know, seeking good explanations via a method of error detection and correction. And a commitment to reason, to science and mathematics broadly and philosophy. And so it's a levelling up of traditional intellectual thought,

### 2h 4m

which was let's accumulate as much information as we possibly can, fill our heads with facts. I'm not denigrating, you know, people who have deep knowledge, deep background knowledge they can draw on. But it was a mode of authoritarian understanding. But many people still push today, you know, what are your sources? What are the authoritative sources? How can you ensure that you're justifying your beliefs and you've reached the truth? And that way of thinking, that way of thinking is the old style intellectual that you can still see out there in the world that will rest upon and rely upon credentials and credentialing that will defer to the authority or perceived authority of experts. In some sense, it's only subtle, but in other ways, it's a radical shift turned towards a way of viewing, for example, expertise, not as a matter of authority, but as a matter of deep knowledge

### 2h 5m

where there is a commitment to error correction, that we have this open-ended capacity to improve our circumstance. And that is another way in which David Deutsch's influence, I would say, the global conversation in a fundamental way, perhaps the most fundamental way of all, is in drawing a bright line between an old guard of intellectuals who are still the most popular, committed to a pessimistic view of the future, prophesying the end times and denigrating human beings and what we've done for the planet and Western civilization. That way of thinking and that vast group of intellectuals still outnumbers us by, what, a thousand to one or something like that, versus the anti-authority commitment to unbounded progress and optimism

### 2h 6m

that David Deutsch gifts us through the beginning of infinity. It's not to say he's the only person on Earth who's ever done this. You know, there's Matt Ridley, you know, you look at the work of Karl Popper and Feynman, there are many people who have this optimistic view. But what I'm saying is he articulates it in one place, in that book and throughout his work, in a way that is more cogent, and here's the key thing, coherent as a worldview. And by coherent, I mean there are all these many aspects to it that fit together like a lovely little puzzle, which is why, you know, when I go back to Ben's, Ben's question about what is the significant thing you disagree with on David Deutsch, it's because I feel as if, I don't want to sound ridiculously arrogant here, but I feel as if I can see the puzzle. Whether it's that piece over there, which is quantum theory and understanding the significance of quantum theory for possibility, which leads to constructive theory,

### 2h 7m

is what can possibly happen in the world, what can't possibly happen in the world. That, tied to epistemology and our capacity to imagine what is physically possible and to take action to achieve it, and then wealth, to generate more and more wealth in order to achieve the thing that we want to, because what's holding us back is only knowledge, not resources, which are infinite, because any kind of matter, which exists out there in the universe, which so far as we know is effectively infinite, if not actually infinite, has all the resource that we need, we just have to know how. And knowing that all of this is possible gives us optimism, but at the same time, we'll never get to the end, we can only ever hope to correct errors, and we'll always have errors with us because we're fallible as human beings, and human beings are cosmically significant. So as I'm telling you all this, you can see that I'm filling in the pieces of the puzzle,

### 2h 8m

these bits of the puzzle, everything from quantum mechanics that I began with through to the nature of what it is to be a person, fits together, and people are coming to understand aspects of this and to get on board, and so it is so much more refreshing than that, as I said, old guard of people who are ever engaged in talking down people, dismissing explanations, and the centrality of knowledge in changing our circumstance now, and giving us hope for the future, because we need this right now, of course. You know, you have the people who have unfortunately indoctrinated generations that basically the end of the world is not too far around the corner. Climate change, you know, of all the problems, there are many, many problems, but to pick one, climate change is the one that animates youngsters most.

### 2h 9m

It's the one that politicians, various other activists are using, people who are interested in collectivism are using as a cudgel to bring in more regulations to socially control people, to win elections, to gain power, and it all rests upon denigrating people and the output of people, and yet that's just one thing, you know, and then you've got, you know, people who are pessimistic about AI and people who are pessimistic about the potential for curing disease and people who are pessimistic about longevity, and the list is long. So, yes. Sometimes that, all of that, it makes people, it's a new kind of smart person, if you like, and thank goodness they are on the ascendancy. Whether their numbers are accelerating,

### 2h 10m

these ideas are accelerating, into the zeitgeist, as quickly as the pessimistic ones, I don't know. We're at an inflection point of sorts. The next few years will tell. The next few years will tell. I really have to stop soon, even though the questions keep coming in. SAS, can you elaborate on David Deutsch's view on free will versus Sapolsky-Harris? Does he basically say free will could exist in the bounds of whatever creativity is, which is still not known? Can you elaborate on it? I can't give you David Deutsch's view on free will, because I don't know I'm not David Deutsch. All I can tell you is what I've said in the past about this, which is that I think that free will is just a term for an emergent phenomenon that human beings have the capacity to create new options in the world and choose them. So we create stuff. We create explanations, importantly. Among many examples,

### 2h 11m

imagine you want to create a highly precise way of locating yourself on the globe. You're navigating on an old sailing boat, and you think, I've got this hand-drawn map. If only I knew exactly where the New World was exactly, where the United States was. I'm sailing here from Spain over to the United States. Why can't I see landmarks more precisely? Well, back then, you didn't have the option. You couldn't freely choose to switch on your GPS map. But now you do. Now you do. Now the GPS will tell you exactly where you are on the globe down to the nearest centimeter or something like that. So we created that. Einstein and then engineers came along and programmers and coders and people who made smartphones.

### 2h 12m

And now, when I say we, I mean humanity created that. And so now we have the choice. We have the choice to switch on a GPS system or to use a paper map. Now, that capacity to create is intimately tied to this notion of free will. So yes, I have said that when you want to explain what it is a person does, it's convenient to invoke this idea of free will. Now, if you say, oh, but everything is determined, I will agree with you. Everything is determined by laws of physics. Laws of physics are deterministic. They are sovereign. You cannot escape from the laws of physics. So if your conception of free will is to define the laws of physics, then I agree that no such supernatural force of free will exists. So put that aside. The fact that you can't, in principle,

### 2h 13m

predict what a person is going to do should make you think carefully about what it means, therefore, to be a person. A person is not like a ball rolling down a hill. A person can make choices. And their choices depend upon what knowledge they're creating moment to moment. An inherently unpredictable thing. And so you can avoid the term free will if you like, and many people do. Sam Harris does, for example. You mentioned his name. But we're still left with the central mystery of what a person is. So rather than get tied up in debates over terminology, does a person have free will, I like these days to just talk about there is this interesting mystery at the heart of what it is to be a person. We create, genuinely create. And I can unpack what create means. And in particular, we create explanations. We can unpack what that means. And that process is inherently unpredictable. And so although you can say things are determined, you can also say, without contradiction, to say that things are determined

### 2h 14m

to be unpredictable subjectively. And I went through three different versions of unpredictable, the live stream before last. You get that from quantum mechanics, and you get that also from, among other things, knowledge creation, inherently unpredictable, even though it's all determined. Yeah, people often make that mistake, though. Okay. I was watching YouTube. I was watching one with Sabine Hossenfelder, and she was speaking with some other physicists as well. And it was remarkable to me, these professional physicists, you know, at such a high level, not being able to distinguish between predictability and determinism. Things can be determined without being predictable. Things can be determined without being predictable. Okay? You fire a photon at a half-silvered mirror, it is absolutely determined that it will either go through or it will bounce off, 50-50. And you can't predict which. And there's no point saying that for this next photon, it's got a 50% chance of going through and a 50% chance of bouncing off.

### 2h 15m

If you want a prediction of which it will do, you can't. And so that, you know, I think that's a nice bright line between predictability and determinism. They're not the same. They're not synonymous at all. Black Locust, you live in Sydney. Is there a Popperian-Deutschen society? Can I say just as a matter of, not that I'm aware of, but Deutchean isn't a word. There is no such thing as Deutchean. Even Popperian is something that is sometimes challenging. You know, I just like epistemology, just that word. That does it, you know, the study of knowledge. It's like people don't go around calling themselves Einsteinians or Finemians or whatever. They do call themselves Darwinians, I suppose. But anyway, it's better to not have movements, full stop, but it's certainly better than not to have movements

### 2h 16m

centred around a particular person. The reason my podcast is in very large part, a large proportion of my podcast is devoted to the work of David Deutch is because in one singular place in a number of books, you have a highly concentrated, high density, I think once upon a time, I think it was Aaron Staple or someone said a wonderful phrase or something to the effect of, you know, David Deutch's work, The Work in the Beginning of Infinity, has the highest density of knowledge per sentence in any book ever, and I think that's a nice way of putting things. And that's why, you know, I focus on that work, but also because, yeah, it's all the stuff that I've studied throughout my life and that's why it seems like I'm focused singularly on David Deutch, but there's also another way of looking at it, which is that David Deutch and I have the same interests. He's a lot more accomplished than what I am, subtly different interests. You know, he's very focused on the physics and, you know, I like the epistemology stuff as well as the physics.

### 2h 17m

Anyway, so there are reasons for these. People who converge on the truth converge together, that kind of thing. I can say that. SAS, also with the double slit experiment, can you expand on why it proves multiverse as strongly as our study of organisms proves evolution? Okay, so no, it doesn't prove anything. Science is not about proof. I can't do that. But go to my series on the multiverse. In particular, go to the episode on shadows, which is the easiest way. Instead of saying that the double slit experiment proves the multiverse, what we say is the only way to explain what you see in the double slit experiment is by recourse to invoking the existence of the multiverse. The multiverse is forced upon us. Just as evolution by natural selection is forced upon us once you understand how it is that there is a variety of species that change over time and you look at the fossil record for evidence of that.

### 2h 18m

SAS has asked about the multiverse and dark matter, such as in Marvel movies. I've often thought this as well, you know, like dark matter, whatever it is. Are we swimming in a civilisation of dark matter people? By definition, so far as we can tell, dark matter does not interact with any other kind of matter. So perhaps there are civilisations of people made of dark matter. We just don't know yet. So, yeah, it's a good premise for a science fiction. I don't know why science fiction movies recently haven't taken advantage of dark energy and dark matter. I mean, there's a lot to explore there. Maybe one day. People saying nice things and irrelevant things.

### 2h 19m

Thank you to my donation for today. I've got a singular donation from Aaron Martin. Thank you, Aaron. Shout out to you. Did I answer your question? Did you ask a question? Whether you did or you didn't, thank you so much. Again, for anyone else who's enjoying these, I've had some lovely feedback from people over time. Please feel free to go to www.bretthall.org, and there are links there to how you can support me doing this into the future and my regular episodes as well, which ironically, even though I've been here for, what, two hours and 22 minutes, actually take a lot longer, like a half-hour episode of TopCast sometimes takes up to, well, it could take six hours or something, because the editing is just such a nightmare. No editing required here. This is the unedited version.

### 2h 20m

Sudhika Misra. What it means according to you and David Deutsch. What to do next problem related to morality. So the question about what science is can sometimes be phrased as explain what exists and what's going on and the relationships between things and the causes. What does physical reality consist of? That kind of thing. That's what science is. Morality is about what you should do. What you should do. So your problem is always what should you do next? There are better and worse choices. So any time you have the word, the word should is a, is a moral question. And there's objectively better answers. Some things you should do and some things you shouldn't do. And of all the things that you could do, some are better to do than others. So morality is always the problem of what,

### 2h 21m

what to do next. What should you do next? Something about veganism there from Power Ranger. But the distinction I make between humans and other animals does come down to this fundamental idea of explanation creator. And to get into the nitty-gritty of it without going into too much detail, I think there's a distinction to be drawn between pain and suffering. And I'm not sure that animals have qualia, but even if I granted that they did have qualia, so for example the capacity to experience pain, pain is not necessarily suffering. Suffering can be conceived as some explanation of the pain. In particular, an explanation of the pain is going to continue, or the explanation of the pain is going to get worse, or suffering is a uniquely, I would say, human thing. Now people will disagree with me on that,

### 2h 22m

but that's where I come down on why it's not ethical to cause a person suffering. And why it is that, well, and let's of course say, some sort of criminal and you need to tackle them to the ground, that's going to cause them to suffer. Modulo that kind of exception edge case. Animals and people are black and white different things, entities in the world. And it's almost as if the more we learn about AI, not AGI, but AI, we may very well converge on the idea that animals are a kind of AI. They are slavishly following programs. Even if, you know, animals, within the same species are different one to another. They might have rather unique personalities. Anyone who has a dog knows that different dogs have different personalities. Different cats have different personalities. So there's something there in the genome that's unique, but that's just variation on the genome. None of that necessarily confers the capacity to have an experience, to explain things. But it's a long conversation.

### 2h 23m

I also, in all my pieces when I talk about this and veganism and the morality of animals, I also say none of this is an argument for being cruel to animals. So there's also all of that. SAS has said... OK. There's one last thing. Power Ranger. Why should animals be denied of certain rights? Well, because, among other things, they're not people, and so they can't have human rights because they're not human. The reason why a human right exists, or the right to your life and the right to your property, is because you are a thinking creature who can correct errors and explain the world and improve it. And animals are never going to do that, not for themselves, not for each other. If you care about the animals, if you care about animals, then you should care about humans infinitely more, because humans are the one thing that are going to be able

### 2h 24m

to save the animals that you're concerned about. And that suffering does indeed come down to... the capacity to explain, which no animal can. Unfortunately, SAS has said thank you, and thank you to everyone who participated today, who came along, who watched, dipped in, dipped out, asked questions, whether it was on X or on YouTube. But until next time, and possibly a couple of weeks from now, we'll say goodbye for now, and I will see you again in a future episode of TopCast. Bye-bye.

