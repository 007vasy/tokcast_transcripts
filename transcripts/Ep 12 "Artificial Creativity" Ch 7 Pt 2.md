# Ep 12 "Artificial Creativity" Ch 7 Pt 2

Original Episode: [Ep 12 "Artificial Creativity" Ch 7 Pt 2](https://www.podbean.com/site/EpisodeDownload/PBA67FE2VXSPV)

Audio Download: [MP3](https://mcdn.podbean.com/mf/download/mrti3u/Chapter_7_Part_2.mp3)

## Transcript

### 0m

Hello again, and this time welcome to Chapter 7, Part 2. This is Artificial Creativity. The first part is very much about Artificial General Intelligence. So we've got creativity, which is from our minds, and that is the creativity that allows us to create explanations, as well as create all the things that appear to be rather uniquely human. So, for example, art and poetry and music. But importantly, explanatory knowledge, like science and philosophy and mathematics, the things that allow us to really make progress into the future. And of course, that does include the products of our creativity, like art. Art requires explanations. In order to improve towards some better standard, objectively better standard, we're going

### 1m

to get there as well in a later chapter. So that first form of Artificial Creativity is very much about trying to replicate artificially the creativity of our minds, what our minds can do. It's always surprising to me how people think that there is a genetic propensity for things like mathematics, let's say. Your mathematical ability, it is often said, is genetic in some way. This is what psychology at the moment, the prevailing view is that IQ, intelligence, somehow has a genetic component. And this flows through to things like capacity to do mathematics. There's some inherent thing about brains that allows them to either be good at mathematics or not so good at mathematics. Which would mean, if that's true, if there truly is a genetic component to intelligence or to math in particular, that would mean there would have to be genes for that capacity.

### 2m

This can't be true. Although there are genes for brains, there are not genes for minds, or what minds turn out to be. Minds, of course, are universal explainers. There's unfortunately an entire field of academia devoted to a misconception. It's called evolutionary psychology. Evolutionary psychology purports to be about how we have a general idea about how we can inherited certain mental characteristics. If we've inherited certain mental characteristics, then this means that those mental characteristics must somehow be in the genes. To me, this seems like a category error. It's saying that abstract mental capacities are somehow coded in the DNA. This is extremely unlikely, because vast as the DNA molecule is, it's not vast enough to contain all of the information that is inside a mind as the mind begins to learn. And so, in the same way that we cannot expect that there would be a gene for the capacity

### 3m

to say, speak English, there cannot be a gene for the capacity to do mathematics. More or less, all English speakers have the same proficiency. Yes, there are differences. Some people write books. Some people are great orators. Other people kind of mumble. Some people mumble a little. But overall, we understand each other. We're about the same level. I don't think there are vast differences. There's probably like a 5% difference in vocabulary between the people who have the greatest linguistic dexterity and between the people who struggle to form a sentence. But generally, adults can understand one another, no matter the language that they're using, unless it's a specialization. But again, if it's a specialization such that you understand a lot of medical or legal terminology, that's not in your genes. You have to learn that. In the same way that it cannot be the case that the capacity to speak English is in the

### 4m

genes, because it doesn't matter what culture, nation you come from, if you come to an English-speaking country and you stay there for long enough, you will learn the language. Similarly, if a person born in an English-speaking country moves to China, they will eventually learn Mandarin. In neither case can the language be encoded in the DNA. The capacity to speak English is in the genes. The capacity to speak either language be coded in the DNA. What is coded in the DNA is a capacity for language generally. And so it is with mathematics or for any other activity of the mind. That particular activity of the mind, mathematics, doing poetry, understanding science, the list is very long, none of these individual things can be coded in the DNA. Only the general, the most general capacity can be coded. Namely, the code for a brain which can run a mind which is universal. That's it. That's it. Once you're universal, then you have a capacity to do everything else.

### 5m

So why are some people better at maths than others? Or better at speaking English than others? Because they show a greater interest in doing those things than others. Is that interest coded in the DNA? No, I don't think so. It's a combination of the way in which people are brought up, what grabs their attention as they grow into maturity. Change over time as well. So artificial creativity has to be about trying to find the algorithm for whatever a universal explainer is. This very, very special capacity that only, so far as we know, human beings possess in the entire universe. Okay. So that's artificial creativity in terms of mental intelligence or something like that. The second part that I'm going to talk about here and now. Is artificial evolution. Okay. So artificial evolution. There's two sorts of knowledge, remember, that David has distinguished here in the beginning of infinity. There's the explanatory type knowledge.

### 6m

And that's the knowledge that we are able to create as human beings. And there's knowledge in the DNA. The knowledge that codes for organisms. We are not able to, at this moment, because of our own lack of knowledge, artificially create either. And the reason we can't artificially create either is because we don't understand either, sufficiently well. And I mentioned in part one that there were parts of this chapter that I didn't fully understand the first time I read the book or the second time or the 10th time I read the book. It really took me until last year, many, many years after the book had been published for me to really grasp what was being said here. And it really was exciting once I did figure it out. I didn't figure it out. I had to speak to someone else about it. I totally understood that we didn't understand consciousness. We didn't understand how explanations were generated. And I knew that because if you can't program it, you haven't understood it.

### 7m

I knew that. But I just couldn't figure out why we couldn't understand evolution. I understood we had evolutionary algorithms. And David even talks about evolutionary algorithms in the beginning of infinity. So I was missing something. I was missing something big. I myself played games with simulating evolution by natural selection. And I'll put it on the screen. I'll put it on the screen. I'll put a link in the bottom all about this. You can play games where you set like, for example, the number of rabbits in a particular environment and how often they breed and how much food they have. And you allow them to produce random mutations now and again, such that their fur color changes. Then you can introduce wolves into the environment and the wolves will eat the rabbits or not eat the rabbits, depending upon what color their fur is. And so you can simulate this kind of evolution by natural selection in a computer. So I thought, isn't that programming evolution? And aren't the people who design evolutionary algorithms, aren't they programming evolution? No, not really. So I really thought that not only we, I thought that I had a good handle on this evolution

### 8m

by natural selection thing. I even remember in second year maths, I did a subject called continuous dynamical systems, which was basically about something called differential equations. That aside, there was maths applied to biology and it involves something called the logistic equation. And more commonly, it's called the logistic equation. The more complex versions thereof. And the logistic equation allows you to determine the growth of a population, given the amount of food in an environment. If there's too much, if there's just the right amount, or if it's been restricted. So you can make predictions using mathematics and graphs. And I thought we understood all that, how populations grow and decline. Again, I thought, here's biology being predicted by mathematics. I thought we understood Darwinism because didn't Dawkins himself figure out the rest of the genetic details? Indeed. Didn't Richard Dawkins himself write a little program that simulated evolution? Now this is going to be terribly self-indulgent for a moment, but I just wanted to labor the point and be terribly self-referential for the moment.

### 9m

I certainly didn't major in biology, but I was always really keen at university when I had the opportunity to take biology subjects, or at least subjects related to biology. I took a brilliant subject called astrobiology. Astrobiology was great. I took a subject about astrobiology twice. It was once in undergraduate. And then later on in postgraduate, when I used a book like this, an introduction to astrobiology, which was a great book. One time I took a subject with a great astrophysicist who now lives in Australia. He began in America. He's called Charlie Leinweaver. And if you're interested in astrophysics or astrobiology, look up Charlie Leinweaver on Google and have a read through some of his papers. He's a great polymath. He first did a degree in history. Which is unusual for a physicist. And the subjects he's written about professionally in astrophysics cover dark energy and dark matter. Why planets are the size that they are. That one's called the potato radius.

### 10m

You can look that up. Why did life appear as soon as it possibly could on Earth? It appeared much faster than might otherwise have been expected. He created something called the nasalization quotient and analyzed the length of animal trunks. And he did that to make a point about how brain size isn't a convergent feature of evolution. Anyways. Charlie taught me astrobiology and evolution and I got confident that I knew it. And then I did biophysics with another guy called Joe Wolfe at the University of New South Wales. And if you're interested in learning physics, well look up Joe Wolfe, University of New South Wales because he's got some brilliant pages, web pages on the basics of physics all the way up to modern physics including quantum theory and relativity. And. What Joe said of the subject of astrobiology was basically that astrobiology was the science closest to theology because after all, they're both yet to demonstrate the existence of their own subject matter.

### 11m

So in biophysics, I learned even more biology and really thought I was getting across this biology stuff. And I was excited to learn more about biology and I finally took a philosophy subject called the philosophy of biology with Professor Michaelis Michael, again at the University of New South Wales. He had a degree in zoology. But. I was excited to take lots of subjects in logic and classical philosophy, which is how I got diverted off into philosophy. And so in the philosophy of biology course, I read lots of Dawkins and I read lots of Stephen Jay Gould and about their debates. And so I thought this is this this theory. I mean, there's a few unknowns around the edges, but surely, surely we know it as well as we know Newtonian mechanics or general relativity or quantum theory. It is the biological equivalent of that, surely, but despite reading The Selfish Gene and The Extended Phenotype, I didn't know what I didn't know. And this was the wonderful thing. It's possibly a problem with taking formal courses of this sort and you gaining some small amount of so-called expertise in an area.

### 12m

You overestimate yourself, especially if you've never challenged yourself. And this is where the beginning of infinity came in. It challenged me about what I thought I knew. I didn't know. And to be fair, no one does. But at least David Deutsch knew what others didn't. Or at least he had a way of diagnosing. How to know that no one else understands either. As a bit of a footnote for what it's worth, my lecturer, Michaelis Markle, that I mentioned who did the philosophy of biology subject, he must have known that we didn't know much about evolution by natural selection. He must have known that what was known about evolution by natural selection contained huge gaps because he published a book just a couple of years ago. I'll put it on the screen now. And in it, he states clearly the big gaps we have in our understanding. The big gaps in our understanding of evolution by natural selection that comport with what is said in the beginning of infinity. So I guess I should have known. I didn't listen well enough during the lectures apparently. I might mention something else here in terms of not learning the right lesson.

### 13m

It's kind of like, I suppose, how people can go through an entire physics degree and learn as much as possible about quantum mechanics and how to do all the calculations and never quite accept or appreciate that it does imply the many worlds interpretation. It implies that there are... parallel universes, that there is a multiverse. The parallel to that situation is me studying what's called the Miller-Urey experiment. I apologize. This is clearly a very long introduction, but bear with me just for one more moment while I mention again why I didn't realize what I didn't realize. If you study astrobiology, so astrobiology is about the conditions required in order for there to be life out there in the universe somewhere. And so where might be best to look for life out there in the universe somewhere? It'd be a good idea to have a place to start. Okay. We're probably going to start on Mars, but beyond that, where might be a good place? Would it be a warm pond? Would it be beneath the surface, et cetera?

### 14m

One of the first things in any astrobiology course is usually something about the Miller-Urey experiment. The Miller-Urey experiment was done back in the fifties, and the idea is pretty simple. You take a flask and you fill it with chemicals. Inorganic chemicals. Chemicals that you think were present in the early earth. So things like oxygen, nitrogen, carbon dioxide, perhaps some methane, perhaps sulfur, et cetera. You can make up your own list of chemicals and this experiment has been repeated again and again. So I think they're just generally called Miller-Urey type experiments now. And what Miller and Urey did, these were the first guys that did it, was to take this flask, seal it, heat it up a little and pass electricity through it. Just to simulate lightening. And to leave it for some time. And then after a certain amount of time has passed, you open up the flask and you investigate what's inside. Now at first, what was found inside of this flask offered great hope. It was quite exciting.

### 15m

What they had managed to create out of the nitrogen and oxygen, methane, et cetera, were amino acids. People got very excited about the fact that amino acids had been produced inside of this flask. They're excited about producing amino acids. Because amino acids are the very building blocks of proteins. And proteins are what living organisms are made out of. They're the things that DNA actually produces. DNA or genes code for proteins. So if you're creating amino acids, surely leaving it for even longer, perhaps changing or fiddling with the conditions a little bit inside of your Miller-Urey flask, you might get proteins. So you get proteins, then you might get nucleic acids. You might get something that's self-replicating. You might get DNA. You might get something crawl out of the flask eventually. This is what the Miller-Urey type experiments are all about. Taking something that is definitely not alive, not living, inorganic, leaving it for some time in a warm environment, with energy in other words, perhaps with electricity, and then at the end having something alive, something organic.

### 16m

Surely the production of amino acids indicates that we're on the way to producing life. Well, no. As many other people have pointed out. I might just mention Paul Davies. Paul Davies wrote an excellent book called The Goldilocks Enigma, all about how the conditions in the universe seem to be just right for life. But he will admit, as many other people will, that these Miller-Urey type experiments that produce amino acids aren't showing very much. We find amino acids with our powerful telescopes looking at interstellar gas clouds. There's amino acids out there in interstellar space. So amino acids seem to arise. Pretty often. Pretty spontaneously. Given the right elements with a little bit of energy. Other people have described finding amino acids as to finding a pile of bricks. If you walk around the corner and find a pile of bricks, you don't expect that the next pile of bricks that you're going to find is going to self-assemble itself into something

### 17m

like the Opera House, which would be the equivalent of thinking that just because you've found amino acids, you're on the way to finding a living organism. So just because Miller-Urey? Were able to create amino acids inside their flask tells us absolutely nothing about whether or not, left for a certain amount of time, you will get life. So the remarkable thing is that Miller-Urey experiments have been repeated again and again since the 1950s with basically the same results. I think proteins might have been created at some point. We do not know how inorganic material becomes organic material. Now, by organic material. By organic material, I mean material that's self-replicating, that's alive. Many popularizers of science today talk about how we do not know how geochemistry becomes biochemistry. There's a massive gap in our understanding, and this comes to bear on this whole question of why we do not understand how the knowledge that's in DNA got there at all.

### 18m

How it gets there. How the universality of DNA, which means that the DNA can actually create any living organism that's out there. How that came to be in the first place, we don't know. We can't create DNA from inorganic materials. It must have happened. It must have been a spontaneous thing. We just don't know how. And I'll just mention in passing one final thing. The Miller-Urey experiment seems to suggest that life is very, very hard to create because our smartest biologists working for decades at a time on these kinds of experiments have not produced artificial life in the lab. They don't know how. It must be really hard. We've repeated what we think are the conditions in the early Earth over and over again. I think it must be thousands of times, thousands of different experiments by now, and nothing has crawled out of that flask.

### 19m

So that's an argument that life is very hard to spontaneously arise. That the universe is such that it's very difficult for life to spontaneously arise. If smart people working in labs can't do it, then is it going to happen by chance? If people with knowledge can't seem to do it, then how on earth could an environment without any knowledge cause it to happen spontaneously? We don't know. There's a great mystery there. So on the one hand, we have this argument that life must be very difficult and therefore be very rare in the universe as well. That one of the reasons, one of the answers to the Fermi Paradox might be it's just too difficult. It's highly unlikely that however many planets there are out there in the universe, there simply are not enough planets out there in the universe. Even if you were to cover them all in inorganic material and to warm them, just like in the Miller-Urey experiment, and to make them perfectly bio-friendly, nonetheless, it might

### 20m

be the case that it is exceedingly unlikely for inorganic material to become alive. And so that might be an answer to the Fermi Paradox. And the reason for? Books like this one, which I would also recommend, Rare Earth, Why Complex Life is Uncommon in the Universe by Ward and Brownlee. That's a great book. Now standing in stark contrast to that, I might just mention a paper by the great Charlie Lineweaver who I mentioned earlier. And he wrote a paper looking at how quickly life arose here on the planet, here on earth. There was a period called the late heavy bombardment here on earth. There was a period of time in the universe where there was a lot of material from the very far reaches of space, I think out in the Oort cloud, or maybe it's the Kuiper belt. One of those places where there's lots and lots of asteroids in the far reaches of the solar system. This material was kicked in towards the earth and it bombarded the earth.

### 21m

And so this is called the late heavy bombardment. And it caused the temperature of the surface of the earth to rise very, very high. I think to molten rock temperatures. So thousands of degrees Celsius. Sterilizing the earth. So if there was any life there, it was certainly wiped out at the late heavy bombardment. Probably there was no life there to begin with because prior to that the conditions weren't any more friendly. They became exceedingly hostile during the late heavy bombardment is the point, however. But then what happened? Well, then the earth cooled, and if we look through the fossil record, if we dig down deep, we find dinosaurs. And if we dig even deeper so that the strata become older and the organisms are more ancient, then we've found dinosaurs. And then we find dinosaurs. And then we find dinosaurs. find fish. And if we keep going down further, then we'd find nothing but bacteria. And if we keep going down further, we find nothing. We find no living organisms. We find the period at which the late heavy bombardment happened, and there's geological evidence for the late heavy bombardment. But as soon as the late heavy bombardment was over, almost as soon as it was over in geological

### 22m

time, life appeared. Life appeared straight away, it seems, on a geological time scale. So that is an argument that life will arise as quickly as it can, given favourable conditions. Because here on Earth, as soon as the conditions were favourable, life arose. That's remarkable. But now we have a contradiction. The Miller-Urey type experiments seem to be suggesting that life is very, very difficult to create, no matter what the conditions, because the scientists keep trying to create friendly conditions and nothing's crawling out of the flask. On the other hand, the actual experience of Earth was, life is very, very difficult to create, no matter what the conditions, because the scientists keep trying to create friendly conditions and nothing's crawling out of the flask. Life arose as soon as it possibly could, as soon as the conditions were just right. What on Earth is going on? This is really exciting. There must be an answer to this. But we don't understand how life arose. We do not understand these processes of life. I suppose this is kind of only tangentially related precisely to what the beginning of infinity is about, which is more about once you've got life, once you've actually got life,

### 23m

how can you artificially simulate the process of evolution by natural selection? Although the process of evolution by natural selection probably predates any of the simple living organisms that we have. It probably goes all the way back to when we had an RNA world, so there was probably evolution by natural selection going on then. We don't even know how to get RNA out of this inorganic material. That's enough from me for the moment. Let's go to, let's go to the book. So David writes, when discussing Lamarckism in chapter four, I pointed out the fundamental difference between a muscle becoming stronger in an individual's lifetime and muscles evolving to become stronger. For the former, the knowledge to achieve all the available muscle strengths must already be present in the individual's genes before the sequence of changes begins. And so must the knowledge of how to recognize the circumstances under which to make the changes. This is exactly the analog of a trick that a programmer has built into a chatbot. The chatbot responds as though it had created some of the knowledge while composing its response. But in fact, all the knowledge was

### 24m

created earlier and elsewhere. I'm just going to flag that. This is me. We will come back to that later. That is the key fact in this chapter that I think I missed. I'll say it again. When it comes to a chatbot, when it comes to knowledge and the chatbot appearing to say something original or something creative, or to give you a piece of knowledge that it has produced itself, David says, in fact, all that knowledge was created earlier and elsewhere. Okay, I'll continue reading. The analog of evolutionary change in a species is creative thought in a person. The analog of the idea that AI could be achieved by an accumulation of chatbot tricks is Lamarckism. The theory that new adaptations could be explained by changes that are in reality just a manifestation of existing knowledge.

### 25m

There are several current areas of research in which that same misconception is common. In chatbot-based AI research, it sent the whole field down a blind alley. But in other fields, it has merely caused researchers to attach overambitious levels to genuine, albeit relatively modest, achievements. One such area is artificial evolution. Recall Edison's idea that progress requires alternating inspiration and perspiration phases, and that, because of computers and other technology, it is increasingly becoming possible to automate the perspiration phase. This welcome development has misled those who are overconfident about achieving artificial evolution and AI. For example, suppose you are a graduate student in robotics, hoping to build a robot that walks on legs better than previous robots did. The first phase of the solution must involve inspiration, that is to say, creative thought, attempting to improve upon previous researchers' attempts to solve the same problem. You will start

### 26m

from that, and from existing ideas about how to solve the same problem, you will start from that, and other problems that you conjecture may be related. And from the designs of walking animals in nature, all of that constitutes existing knowledge, which you will vary and combine in new ways, and then subject to criticism and further variation. Eventually, you will have created a design for the hardware of your new robot, its legs with their levers, joints, tendons, and motors, its body which will hold the power supply, its sense organs, through which it will receive the feedback that will allow it to control those limbs effectively, and the computer. You will have adapted everything in that design as best you can to the purpose of walking, except the program in the computer. We're already getting a hint of where this argument is going. The knowledge was created earlier and elsewhere. Okay. With evolution by natural selection, organisms don't come into being

### 27m

just with language. The knowledge is created by natural selection. We use the language for the purpose of learning. We use the language for the purpose of learning. We use the language for the purpose of learning. We use the language for the purpose of learning. We use the language for the purpose of learning. Those legs have evolved over time from things that weren't legs, maybe like fins or flippers, something like that. And then legs evolve. In fact, in the case of flippers, of course, they evolve from legs, but you get my point. Here, the graduate student has already built a thing, a robot, with the limbs. So already, we don't have anything resembling artificial evolution. We have something that we can use to build a robot. a creature that already has the required hardware. So let's go back to the book where he's I'll just re-read that last section. Last sentence. You will have adapted everything in that design as best you can to the purpose of walking except the program in the computer. The function of that program will be to recognize situations such as the robot beginning to topple over or obstacles in its path and to calculate the appropriate action

### 28m

and to take it. This is the hardest part of your research program. How does one recognize when it is best to avoid an obstacle to the left or to the right or to jump over it or to kick it aside or ignore it or lengthen one's stride to avoid stepping on it or judge it impassable and turn back? In all those cases, how does one specifically do those things in terms of sending countless signals to the motors and the gears as modified by feedback from the sensors? You will break the problem down into sub-problems. Veering by a given angle is similar to veering by a different angle. That allows you to write a sub-routine for veering that takes care of the whole continuum of possible cases. Once you have written it, all other parts of the program need only call it whenever they decide that veering is required and so they do not have to contain any knowledge about the messy details of what it takes to veer. When you have identified and solved as many of those sub-problems as you can you will have created a code or language that is highly adapted to making statements about how your robot should walk. Each call

### 29m

of one of its sub-routines is a statement or command in that language. So far, most of what you have done comes under the heading of inspiration. It required creative thought, but now perspiration looms. Once you have automated everything that you know how to automate, you have no choice but to resort to some sort of trial and error to achieve any additional functionality. However, you do now have the advantage of a language that you have adapted for the purpose of instructing the robot how to walk. So you can now start with a program that is simple in that language despite being very complex in terms of elementary instructions of the computer and which means, for instance, walk forwards and stop if you hit an obstacle. Then you can run the robot with that program and see what happens. Or you can run a computer simulation of the robot. When it falls over or anything else undesirable happens, you can modify your program still using the high-level language you have created to eliminate the deficiencies as they arise. That method will require ever less inspiration and ever more perspiration. But,

### 30m

an alternative approach is also open to you. You can delegate the perspiration to a computer by using a so-called evolutionary algorithm. Using the same computer simulation, you run many trials, each with a slight random variation of that first program. The evolutionary algorithm subjects each simulated robot automatically to a battery of tests that you have provided. How far it can walk without falling over. How well it copes with obstacles and rough terrain and so on. At the end of each run, the program that performed best is retained and the rest are discarded. Then many variants of that program are created and the process is repeated. After thousands of iterations of this evolutionary process, you may find that your robot walks quite well according to the criteria you have set. You can now write your thesis. Not only can you claim to have achieved a robot that walks with a required degree of skill, you can claim to have implemented evolution on a computer. This sort of thing has been done successfully

### 31m

many times. It is a useful technique. It certainly constitutes evolution in the sense of alternating variation and selection. But is it evolution in the more important sense of the creation of knowledge by variation and selection? Okay, so I'll just repeat that. This is David Deutsch's emphasis on what Darwin and Dawkins have said about evolution by natural selection. David Deutsch emphasizes how DNA contains knowledge. Knowledge of how to create organisms. And so therefore evolution by natural selection is really a theory about how knowledge has evolved in DNA. Okay, how the knowledge got into that DNA. So I'll just repeat that. But is it evolution in the more important sense of the creation of knowledge by variation and selection? This will be achieved one day, but I doubt that it has been yet. For the same reason that I doubt chatbots are intelligent, even slightly. The reason is that there is much more obvious explanation of their abilities.

### 32m

Namely, the creativity of the programmer. The task of ruling out the possibility that the knowledge was created by the programmer, in the case of artificial evolution, has the same logic. That checking a program is an AI, but harder because the amount of knowledge that the evolution purportedly creates is vastly less. Even if you yourself are the programmer, you are in no position to judge whether you created that relatively small amount of knowledge or not. For one thing, some of the knowledge that you packed into the language during those many months of design will have reach, because it encoded some general truths about the laws of geometry, mechanics and so on. For another, when designing the language, you had constantly in mind what sort of abilities would eventually be used to express. Okay, me talking. So the programmer who says they've successfully simulated evolution by natural selection in a computer, well, they can't have because evolution is blind. Evolution is blind. We know

### 33m

this. We know this from the theory of evolution by natural selection. It's not directed towards a particular goal. This is a huge misconception, by the way. Okay, yes, yes, I admit lots of people do have this misconception. Lots of people think there is an arrow of evolution, that organisms move towards ever greater complexity. Not true. Bacteria have been around since the beginning of life on Earth for billions of years. They have remained there. They're just as evolved as we are. I think Ricky Gervais is fond of saying things like that. Which is true, in a sense. They've been evolving and they've found their niche and they have been perfectly suited to their niche. As have moths and other insects. As have fish. They've all evolved to fill their niche. There is no arrow of evolution leading towards a particular form of complexity. Evolution wasn't always directed towards us, so far as we can tell. At least that's what the theory says. Because evolution is blind, it doesn't know what the next best organism

### 34m

would be for a given environment. So if evolution is blind, fact, it cannot be the case that this is an evolutionary algorithm, in the Darwinian sense. Because the programmer, when designing the language, had constantly in mind what sort of abilities it would eventually be used to express. Which is completely unlike what evolution does. Evolution does not have in mind what sort of abilities it's going to be expressing. It's going to be expressing in the organisms of the future. I'll continue reading. Next paragraph. I'm just going to skip the next paragraph and then David writes, One thing that always seems to happen with such projects, evolutionary algorithms, is that after they achieve their intended aim, if the evolutionary program is allowed to run further, it produces no further improvements. This is exactly what would happen if all the knowledge in this successful robot had actually come from the programmer. But it is not a conclusive critique.

### 35m

Biological evolution often reaches local maxima of fitness. So again, I'll just pause there. So what's David saying there is that in real life evolution, uh, one wouldn't expect the organism that's evolving to simply stop there. If it was true evolution, especially if you're doing it in a computer and you can simulate things such that they get better and better very, very quickly. So you can do, you know, billions of cycles of evolution, um, you know, in a few seconds or a few minutes or whatever it happens to be because you're just simulating it. Why doesn't the organism, organism, I say organism, why doesn't the simulated robot let's say, inside of the computer, that you've taught to, you haven't taught, you've allowed to evolve the capacity to walk, why doesn't it then start jumping? Or better yet, why don't the legs evolve into wings and it fly away? That's kind of what evolution does. You have improvements beyond the thing that it becomes good at. But that doesn't happen. All that it evolves towards is precisely the thing you expect it to evolve

### 36m

towards. You expect it to evolve towards walking. Because that's what you've programmed it to do. The only thing that you've added in is this so-called evolutionary algorithm where instead of just solving the problem yourself, you allow the computer to determine, to judge for itself whether or not it's slightly improving or slightly getting worse and to make a judgement on that. And you're calling that evolution. Now, as David says there, um, that is not a conclusive critique. Biological evolution often reaches local maxima of fitness. Also, after attaining its mysterious form of universality. DNA, he's talking about here, seemed to pause for about a billion years before creating any significant new knowledge. But still, achieving results that might well be due to something else is not evidence of evolution. That is why I doubt that any artificial evolution has ever created knowledge. I have the same view for the same reasons about the slightly different kind of artificial evolution that tries to evolve simulated

### 37m

organisms in a virtual environment and the kind that pits different virtual species against each other. Which is the one that I'm going to put down in a link below. And you play around with those. It's a good way to learn about evolution by natural selection. But yes, there's lots of those things out there on the internet and there's lots of ways of simulating evolution. But as David says there, they're not real artificial evolution. They're toys. They might be good pedagogical tools to use, but these are not proper simulations of evolution by natural selection. The next part is the real kicker. So let's read the next couple of paragraphs. So he wants to, he's just asserted that no genuine artificial evolution has ever been simulated. And he writes To test this proposition, I would like to see an experiment of a slightly different kind. Eliminate the graduate student from the project.

### 38m

Then, instead of using a robot designed to evolve better ways of walking, use a robot that is already in use in some real life application and happens to be capable of walking. And then, instead of creating a special language of subroutines in which to express conjectures about how to walk, just replace its existing program in its existing microprocessor by random numbers. For mutations, use errors of the type that happen anyway in such processes, though in the simulation you are allowed to make them happen as often as you like. The purpose of all that is to eliminate the possibility that human knowledge is being fed into the design of the system, and that its reach is being mistaken for the product of evolution. Then, run simulations of that mutating system in the usual way, as many as you like. If the robot ever walks better than it did originally, then I am mistaken. If it continues to improve after that, then I am very much mistaken. One of the main features of the above experiment, which is lacking in the usual way of doing artificial evolution, is that for it to work, the language of subroutines would have to evolve along with the adaptations

### 39m

that it was expressing. This is what was happening in the biosphere before that jump to universality that finally settled in the DNA genetic code. As I said, it may be that all those previous genetic codes were only capable of coding for a small number of organisms that were all rather similar, and that the overwhelmingly rich biosphere that we see around us created by randomly varying genes while leaving the language unchanged, is something that became possible only after that jump. We do not even know what kind of universality was created there. So why should we expect our artificial evolution to work without it? And David concludes by speaking about how we need to be a little bit more humble and modest and face the fact there are huge unknowns here. Huge unknowns with human intelligence, human creativity, and trying to create artificial creativity inside artificial general intelligence. And there are huge unknowns similarly with evolution by natural selection. We've never

### 40m

simulated evolution. If we can't program it, we haven't understood it. And so I'll just emphasize that again, just to put a cap on this, about what I didn't understand. It's really the part where he talks about taking away the graduate student. Removing the goal. Removing the goal. Okay, I didn't get that. Evolution doesn't have a goal. It's just survival of the fittest. But it can't possibly – evolution doesn't know what the fittest is. It has to test out what works. And what survives is what survives. It becomes a little bit of a truism. The survival of the fittest. Darwin had never actually talked about survival of the fittest, and I think for a very good reason. He knew that it was sort of a tautology, because who are the fittest? Well, the fittest are the ones who survive, right? So anyway, taking away the graduate student from the experiment, where you've got this robot that can't yet walk, removes the goal. Removes the knowledge that could be put into that robot by the graduate student,

### 41m

by the programmer. If you give the robot legs, and let the software take over, then what happens? Well, if it's just a random lot of numbers in there, then you're letting the microprocessor just churn through these numbers. Then that will be a true simulation of evolution by natural selection. This random sequence of numbers. If the robot starts to walk, if the robot starts to walk a little bit better, well then okay. Knowledge is somehow being created by that robot in order to improve its walking. So if the robot was to start to walk better, David admits he would be wrong. And if it continues to improve, he would be very wrong. But wrong about what? Well, that evolution – he would be wrong that evolution doesn't have a goal. Because the robot, if it starts to walk, must have had a goal. Must have had the goal of walking. Now, of course, it's not just David who would be wrong. It's not just David who would be wrong. He just happened to explain this thought experiment.

### 42m

Darwin and Dawkins would be wrong, and it's what they were in fact getting at, and I didn't understand. There is literally no goal. There's no thing, walking or otherwise, to strive towards. So why, nevertheless, is there improvement of the kind we actually see in nature? We do see things walking that couldn't walk before, kind of. You know, the fish evolved into land creatures and the land creatures walked, but the individual fish didn't. That would be, again, Lamarckism. We do see increased complexity. Life evolving to fill niches. And this sometimes leads to greater complexity, but why? How does life fit so well in its niche? How does it adapt? We don't know, except to say, well, the fittest survive. And the fittest are just those who survive, and those who survive are the fittest. In high school biology, students now learn all sorts of fancy details about genetics, about replication and transcription, how genes on DNA code for proteins. The DNA is a

### 43m

kind of software, and it constructs proteins. Different parts of the DNA code for different proteins. Indeed, it's all very computer-like. There's a seed head that moves along the DNA, copying sections to RNA, which then gathers up the required materials for protein synthesis. We know many details, but we cannot replicate the evolution of this in the lab. We simply do not know enough details to simulate the evolution of this process. This is where it's not like general relativity. If there's a true evolutionary algorithm out there, let's see an actual ecosystem evolve online. So there's so much we don't know, and as I began this with the Miller-Urey experiment, we don't know why all these Miller-Urey experiments continue to fail. There are big gaps here in our understanding about how complexity increases. In other words, how the knowledge comes to be instantiated within the DNA, within the self-replicating molecules. This is really exciting for me, this chapter. This was a brilliant one. It's the one, as I fully admit, I

### 44m

didn't appreciate until last year. But now I think I do. I have a better idea. And it was all about the fact that evolution doesn't have a goal, but evolutionary algorithms most certainly do. And so therefore they're misnamed. They're not true evolution by natural selection algorithms. Call them evolutionary algorithms if you like, but don't think that in any way it resembles the kind of evolution we have in biology. Looking forward to doing the very next chapter. The next chapter is Window on Infinity, so moving away from biology and into the philosophy of mathematics. Can't wait to do that one. I'll see you then. Bye bye.

### 45m

Captions by GetTranscribed.com

