# Ep 130: Steven Pinker’s ”Rationality” Ch 6 ”Risk and Reward” (Rational Choice & Expected Utility). Analysis.

Original Episode: [Ep 130: Steven Pinker’s ”Rationality” Ch 6 ”Risk and Reward” (Rational Choice & Expected Utility). Analysis.](https://www.podbean.com/site/EpisodeDownload/PB1299317U74MS)

Audio Download: [MP3](https://mcdn.podbean.com/mf/download/v5ir43/Pinker_Ch_6_podcast8i9v8.mp3)

## Transcript

### 0m

The almost ubiquitous view remains that knowledge is not actually created, but instead is somehow derived, whether from our observations of the physical world, or the input of our senses, or perhaps from axioms that are themselves self-evident. We have this idea that is still regarded by members of the intelligentsia, what is taught in academia, that knowledge in some way is derived, that all knowledge aspires to be what a mathematical proof is. We begin with solid foundations, and from those solid foundations we can derive everything else which is as equally certain as our solid foundations are. And of course, part of our project in any area of knowledge, whether it be science, mathematics, philosophy, logic, morality, is to find those firm foundations. And on finding those firm foundations, we can then derive the equivalent of theorems, the incontrovertible truth. And so

### 1m

long as we can fulfill this process, we are being rational. We are using our reason in order to come to a deeper understanding of reality. All we need are those starting points. And then we mechanically follow a process of logical proof in finding what is true about reality. This entire conception of knowledge, not only is it a process of understanding, but it is also a process of not only as a problem for trying to overcome errors in our knowledge, our errors in understanding exactly how knowledge is created, but it is also at the core of people's mistaken beliefs about what people are, and hence how people can be rational. We want to be rational. We should want to be rational. We should want to be logical. We should want to use our reason. But if our conception of what reason and logic and rationality is, in some way, misconceived, because our understanding of how knowledge is generated

### 2m

begins with misconception, then there will be certain misconceptions that, using that particular scheme of rationality, we will never improve upon. We will never correct those errors. Hence, we need a new theory of knowledge, a new epistemology, a new way of understanding rationality. Welcome to TalkCast and to my latest episode in my discussion of the book called Rationality by Steven Pinker. And as I have been saying throughout my discussion of this book, what Pinker does very well throughout this volume is to provide us with a deep and useful overview of what we might call the conventional model of rationality, the conventional way of understanding what rationality amounts to, what critical thinking is, how logic works, the role of probability and Bayes' theorem in coming to understand the world and being rational about it, how to use our reason, and today, how to make decisions,

### 3m

how to be a rational decision-maker. And today's episode really will be a comparison of worldviews, a comparison of mainstream academic thinking on what rational decision-making is, what a theory of rationality might be that would help us to make ever better decisions, and the worldview that I tend to try and explain here at TalkCast. There is a chapter in The Beginning of Infinity, chapter 13, called Choices, which is about decision-making. It's about how we can be rational decision-makers and the problems with the conventional view of decision-making. I'll come back to precisely what the conventional view is, and as we go through this particular chapter by Pinker today, we'll be slowly unpacking what this conventional view of decision-making is. Essentially, what Pinker will discuss is what David Deutsch in chapter 13, namely that if you want to be a rational decision-maker, then you should rely

### 4m

upon something called rational choice theory. Rational choice theory can trace its roots all the way back to Adam Smith and the beginnings of our understanding of how free trade and capitalism works, how people can be rational in their interactions with each other and to decide what might be a better purchase, whether or not one should actually buy this particular thing or not buy this particular thing, depending upon how much money they have, that kind of thing. That's the sort of rational decision-making that economists are interested in, whether you have rational self-interest. If you do have rational self-interest, then you should make rational decisions. One way of going about doing this is to actually employ the mathematics of or the logic of rational decision theory, rational choice theory. It goes by many, many names. You can look up Wikipedia articles on what rational choice theory is. The key thing is that there are a number of controversial axioms that are involved in rational choice theory. And if you go to chapter 13 of

### 5m

The Beginning of Infinity, David discusses those axioms there, some of those axioms. Now, depending upon which flavor of rational choice theory that you happen to subscribe to, you might begin with subtly different axioms. But the key thing that is often not discussed, but which David does discuss in chapter 13, is that although these axioms that underlie rational choice theory are uncontroversial, people would want to subscribe to these nonetheless. Although they are all logical, reasonable, and rational, it also happens to be the case they are inconsistent. It is impossible to satisfy all of them simultaneously. This is a problem. It is a problem not unlike the way in which Gödel's incompleteness theorem treats Pino's axioms of simple arithmetic. The idea there being that even with a system like simple arithmetic, you are going to have statements that cannot be proved as true or proved as false given the axioms. In the case of rational choice theory,

### 6m

what we have are no-go theorems. There are various no-go theorems which show that rational choice theory cannot be the basis of rationally choosing things. After all, if you can't satisfy all of the axioms simultaneously, then in what way can this system, this so-called system of rationality, this system of mathematically backed rationality, actually be able to satisfy all of the axioms? Be the way in which people make rational decisions. As David says in chapter 13, and I'm going to read a few paragraphs here. I'm quoting from towards the end of the chapter. And he says, quote, there is something very wrong with that entire conventional model of decision-making, both within single minds and for groups as assumed in social choice theory. It conceives of decision-making as a process of selecting from existing options according to a fixed form of decision-making. It is a process of selecting from existing options according to a formula, such as an apportionment rule or an electoral system. But in fact, that is what

### 7m

happens only at the end of decision-making, the phase that does not require creative thought. In terms of Edison's metaphor, the model refers only to the perspiration phase without realizing that decision-making is problem-solving, and that without the inspiration phase, nothing is ever solved, and there is nothing to choose between. At the heart of decision-making is the creation of new options, and the abandonment or modification of existing ones. To choose an option, rationally, is to choose the associated explanation. Therefore, rational decision-making consists not of weighing evidence, but of explaining it. In the course of explaining the world, one judges arguments as explanations, not justifications, and one does this creatively, using conjecture, tempered by every kind of criticism. So, this quote I will be coming back to, this underlies the aspect of the worldview provided

### 8m

in The Beginning of Infinity as applied to this idea of making choices, making decisions. As David goes on to say, quote, The key thing here is, just because you call a set of axioms social choice theory, or decision theory, or game theory, or anything like that, does not mean that you are making a decision. The key thing here is, just because you call a set of axioms social choice theory, or decision theory, or game theory, or game theory, or game theory, or anything like that, does not mean that what you are labelling in the physical real world, by that abstract process, actually

### 9m

applies to the physical real world. You can call these two things the same thing, but it does not make them the same thing. In much the same way as, saying something will probably happen, although it seems reasonable because it's part of our vernacular, does not mean that that something will probably happen. After all, something happens or does not happen. Nothing ever probably happens. It happens. But our language is saturated with these kinds of misleading terms, and introducing new ones, like decision theory, calling this set of axioms decision theory, does not mean that it is the theory of how decisions are actually made by people. I have a final quote that I'm going to read from The Beginning of Infinity, quote, A logical contradiction is nonsense. The truth is simpler. If your conception of justice conflicts with the demands of logic or rationality, then it is unjust. If your conception of rationality conflicts with a mathematical theorem, or in this

### 10m

case with many theorems, then your conception of rationality is irrational. End quote. And this, unfortunately, really is the acid that dissolves the supposed foundations of rationality as explained in the book from which I'll be reading today. There can be no solid foundations. There can be no inherent way of producing inerrant and perfectly rational decisions. What we have are competing explanations, if we're lucky. But typically, we have no explanation. We need to create one. And so if we have a decision before us, either we have a good explanation about what is the best course of action to take, in which case we take it, or we do not, in which case we need to understand our problem situation. And when we understand our problem situation, only then, can we properly create a solution to that problem situation, an explanation of what

### 11m

to do. And once we do that, then we know what to do. We make a choice. We make that decision. This modelling idea, this very abstract, divorced from actually what goes on with decision making, perspective on how people make decisions as a process of choosing between various options and perhaps assigning weights to them, perhaps assigning probabilities to them. And then, choosing which one is going to increase the utility, increase the win, simply isn't the way we do things. Unless, of course, we happen to be gambling. And it is no accident that throughout this chapter, as in the last chapter that I read from this book, Rationality, the go-to examples are drawn straight from the casino. They are drawn from games of chance, where the probability calculus is, for most people, uncontroversially applicable. In real life, of course, we know, following the work of David Deutsch, that even there, these things are physical systems. Roulette wheels are physical, dice are physical, cards

### 12m

are physical. And so, therefore, they obey the laws of physics, not the laws of probability. The laws of physics are not probabilistic. They are quantum laws of physics. They are the laws of general relativity. That is how we understand the behaviour of all physical systems, including roulette wheels and dice. And so, in this case, even in the ideal situation of the physical construction, we just need to know in which way to do things. We have casino, we don't have a situation where, technically speaking, precisely, do the objects there obey the probability calculus? The only way we can have an object obey the probability calculus is to have a computer simulation of something like a dice or a roulette wheel and so on and so forth, where we can model an ideal abstraction. But that's not the real world. That's an alternative universe obeying alternative physical laws, which are the probability calculus. In our real physical world, even things like casinos do not obey the

### 13m

probability calculus, only approximately. And as for moving outside of the casino, well, in that case, you're far removed from anything that is probabilistic. Things happen or they don't happen. There is no way of assigning probability to the likelihood of a particular decision turning out to be good or not, because people make decisions. Make choices and create knowledge, bringing new options into the world. Now, it is useful to know that rational choice theory goes under a number of names. Social choice theory is another name it goes by, or decision theory. That's yet another. Now, technically, if one gets into the weeds on this, we can tease out differences between these subtly different versions of the same kind of thing. It can also be said, perhaps, that rational choice theory is not the only thing that is possible. It can also be said, perhaps, that social choice theory is an umbrella term, and that social choice theory is a species of rational choice theory, which itself is a species of game theory. But never mind all that. The conclusions

### 14m

I will draw and claims I make are independent of the particular version of the theory. It is important to keep in mind, though, what David says in The Beginning of Infinity, and which I've already quoted. I'll quote it again. Quote, it is mistaking an abstract process that it has named, decision. making, for the real life process of the same name. End quote. But call these things what you like. Rational decision theory, rational choice theory, social choice theory. They are systems of axioms from which we aim to derive certain conclusions. Now, whether those axioms actually, in truth, represent decision theory, or social choice theory, or rational choice theory, or any of a number of other things, we are called, we are not mindless calculators. We can change our minds, and models, to come to understand more

### 15m

deeply the world around us, and the inner world, indeed, of our subjective preferences. We can come to understand those with increasing fidelity over time. Our feelings can simply change. To ignore the constant state of flux, we can change our minds, and models, to come to understand more deeply the world around us, and the inner world, indeed, of our subjective preferences. We can change our minds, and constant creative capacity of people to transform their own selves, their own ideas, and indeed, the world around them, is to ignore the most fundamental feature of what people are, not as calculators, but as explainers. In any case, what this whole decision-making theory is about, is about a statement of axioms that, uncontroversially, one would want to agree with each of these axioms, if one is going to be rational. And Pinker will outline a large number of these axioms, as it turns out. I think about seven of them. We'll get to those in the readings. David also provides some in his book, in the chapter on choices. Here are two of the

### 16m

axioms. The first axiom is called commensurability, according to Pinker. For any options A and B, the decider either prefers A, or they prefer B, or they're indifferent between them. That's an axiom. Now, that seems like so obvious as to not be worth stating, simple statement of basic logic. This is what happens when it comes to outlining systems of logic. When you come up with axioms for anything, whether it's simple arithmetic or basic logic, you begin with axioms that are so obvious, no one could possibly disagree with them. Let's pick another axiom, transitivity. This one's a little more interesting. When you compare two options at a time, if you prefer A to B and B to C, then logically, you must prefer A to C. This is yet another axiom. Again, uncontroversial. Or is it? Pinker will come back to this as well. And there are many more, each of them as uncontroversial as the last.

### 17m

These axioms apply both to groups of people making decisions, hence social choice theory, as well as to individuals, rational choice theory. A person can be like a committee trying to reach a decision because we have, at times, competing impulses or preferences. We sometimes don't know what to do. Here's a classic example. You don't want to put on weight. You have heard that certain foods are more or less healthy for you, and you are trying to keep healthy, be fit, and eat well, according to whatever the prevailing view, whatever the best explanation is at the time, of health and nutrition, fraught as that entire area is. But against all of that, you have a real love of pizza. Meat lovers pizza. Pizza with melted cheese of three kinds, minced meat and barbecue chicken, and slices of marinated fatty pork belly. So there you are, on the couch at night after a day of, say, working out at the gym in a 10-kilometer run, and you have before you a number of options. Don't you now deserve the

### 18m

meat lover's pizza? Or perhaps you do not want to effectively waste the calories burned today, all the effort you've gone to, to try and lose some weight and stay fit and healthy, and instead go for the sashimi salad option. Very low in fat, low in calories, highly nutritious. Do you weigh the options up in your head? Well, no, you don't. You make a decision based upon your preferences themselves arising from what is, by your light, your best explanation. In any case, what you do not do is ever calculate. You don't pull out your pocket calculator and weigh probabilities. Now, just as we will see, Pinker in this chapter concedes that, in fact, well, we might not be calculating after all. We might just be feeling our way to the answer. But then, in what sense are we really taking into account these axioms of decision theory? Are we not coming up with the best explanation and ruling out all of the others? The fundamental point here is, once you begin adding uncontroversial

### 19m

axioms to a system, just as one does with simple arithmetic, then one ends up with theorems about those axioms. In particular, the consistency of those axioms, the possibility of satisfying them all simultaneously. Can they be satisfied simultaneously? Well, it turns out they cannot. As David says, after listing just five axioms from social choice theory that he wrote about in chapter 13 from the beginning of infinity, he said, quote, arrow proved that the axioms that I have just listed are, despite their reasonable appearance, logically inconsistent with each other. No way of conceiving of the will of the people can satisfy all five of them. This strikes at the assumptions behind social choice theory at an arguably even deeper level. In the theorems of Belinsky and Young, first, arrow's axioms are not about the apparently parochial issue of apportionment, but about any situation in which we want to conceive of a group

### 20m

having preferences. End quote. And just my note here, any group having preferences or even an individual having preferences, but competing preferences. I'll continue. Quoting from the beginning of infinity, quote, second, all five of these axioms are intuitively not just desirable to be considered, but are not necessarily desirable to be considered. And so, if you make a system fair, but essential for it to be rational, yet they are inconsistent. It seems to follow that a group of people jointly making decisions is necessarily irrational in one way or the other. It may be a dictatorship or under some sort of arbitrary rule, or if it meets all three representativeness conditions, then it must sometimes change its mind in a direction opposite to that which criticism and persuasion have been effective. So it will make a system fair, but make perverse choices, no matter how wise and benevolent the people who interpret and enforce its preferences may be, unless possibly one of them is a dictator. So there is no such thing as

### 21m

the will of the people. There is no way to regard society as a decision maker with self-consistent preferences. This is hardly the conclusion that social choice theory was supposed to report back to the world. End quote. And then later on in chapter 13, just to underline the point, David goes on to say, quote, And then David goes, And then David goes on to criticize the common sense mainstream view, that mainstream view being that one weighs one's options up. And instead, he goes into providing the correct answer. One

### 22m

chooses the best explanation, refuting all the others. We have an explanation for our decision that decisively rules out the alternatives. We cannot weight our options or determine the probability of success of our options because rather often we are making decisions about situations that are unprecedented. And therefore, we need to create explanations on the run and try them out. The world simply is not predictable in the way rational choice theory would have it be. Let's consider an actual real life example, rather than something abstracted away from reality, which so often throughout this book and throughout this chapter, we resort to talking about casinos and lotteries and games of chance and situations in which we are not able to predict the future. And so we need to create an actual real life example. We've completely denuded all the details out of the reality. And so we're left with nothing but a very stark, abstract, pristine idealization of what a mathematician might

### 23m

be concerned about. You know, first assume a spherical cow kind of thing. Anyway, here's the real life example. Now, you may or may not have seen the movie Sully about the real life situation where Captain Sullenberger in 2009 lost both of his engines on his air class when they flew through a flock of birds after taking off out of New York. And he was faced with the decision. This was unprecedented. What happened to him was unprecedented. He could have chosen to try to return to the airport from which he had taken off from, or in fact, tried to land at another nearby airport. But having not encountered this problem ever before, nor had anyone else encountered this particular problem ever before, he needed to make up his mind. And in order to do that, he needed to think about the future. And he needed to think about the future. And he needed to think. He needed to come up with potential explanations for what was best to do. He needed to make a decision based upon the best known explanation that he could create in that

### 24m

moment. Now, in order to think, to conjecture these different explanations, according to the movie, and I think according to his own book on this, it took him 35 seconds to figure out what to do. And in that time, the aircraft continued to lose altitude. And so Sully, the captain, determined, after the 35 seconds, that the only viable option was to land the plane in the Hudson River in New York, which he did. And no lives were lost. All 155 people on board survived. Now that is a real life creative decision. Was he weighing the options? Was he calculating anything in the sense that, was he resorting to numbers in order to calculate these particular probabilities of success? It doesn't seem so. The curious thing about the movie is that it's not just the movie. And the real life scenario was that the NTSB, the National Transport Safety Board, they ran simulations of the bird strike after the controlled descent into the water had occurred.

### 25m

The computer simulator was able to run through countless scenarios in mere seconds and determined, well, it was indeed possible to return to the airport, thus saving not only all the people on board, but also the aircraft itself. The computer is able to simulate reality, but, and this is key, the computer itself has to be asked the question, can the aircraft make it back to the airport from this particular place? It has to be programmed with all of the relevant variables that come to play when a situation like this arises. Presumably, in some future, there will be such systems aboard aircraft routinely that can quickly calculate if an aircraft can make it back to the airport simply by gliding without any thrust, and the autopilot could then actually do that, take over. But the simulation, it must be kept in the mind, is only ever as good as the data fed into it, the conditions, as well as the extent to which the simulated world is a close analog of the real world. The simulated world does not tend to

### 26m

throw up the unexpected, but the real world will. Can we get serious now? Captain? We've all heard about the computer simulations, and now we are watching actual sims, but I can't quite believe you still have not taken into account the human factor. Human? Human piloted simulations showed that you could make it back to the airport. No, they don't. These pilots were not behaving like human beings, like people who are experiencing this for the first time. Well, they may not be reacting like you did. Immediately after the bird strike, they are turning back for the airport, just as in the computer sims, correct? That is correct. They obviously knew the turn and exactly what heading to fly. They did not run a check. They did not switch on the APU. They had all the same parameters that you faced. No one warned us. No one said you were going to lose both engines at a lower altitude than any jet in history. But be cool. Just make a left turn for LaGuardia like you're going back to pick up the milk.

### 27m

This was dual engine loss at 2,800 feet followed by an immediate water landing with 155 souls on board. No one has ever trained for an incident like that. No one. Okay, so now I'm about to begin the reading. And I must add, in this chapter, Pinker is curiously non-committal about this whole decision theory thing. Namely, it's difficult to tell if he actually endorses this model of decision making that he's explaining to us or not. So whether it is a part of rationality or not, we're kind of left in the dark about. And if it's not part of rationality, I don't know why it's part of a book on rationality. At times, he speaks of it as being a kind of heuristic of sorts. Certainly useful for, well, whether or not one should bet on a lottery, let's say, considering nothing but the chance of winning, never mind having fun with these things. But at other times,

### 28m

he says, well, it might not be a model of rationality. So anyway, it's difficult to tell what the author's own take is on rational choice theory. My guess is that he has read widely enough about the topic to understand that there do exist criticisms out there in the world and criticisms from people. He respects. So he's not willing to go all in, so to speak, to bet on rational choice theory, but he does see some usefulness with it. We will get there as time goes on. So let's begin. And I'm going to be skipping a vast amount of this chapter. There's, as is Pinker's style, he uses many, many examples where perhaps sometimes I think that maybe one or two examples might suffice. Nonetheless, we'll see that. And I think as we go along that I can skip rather a large number of paragraphs. Chapter six, risk and reward, rational choice and expected utility.

### 29m

Quote, everyone complains about his memory and no one complains about his judgment. La rochefoucauld. And then Pinker goes on to write himself. Quote, some theories are unlovable. No one has much affection for the laws of thermodynamics and generations of hopeful crackpots have sensed that. And patent offices that doomed the designs for a perpetual motion machine. Ever since Darwin proposed the theory of natural selection, creationists have choked on the implication that humans descended from apes and communitarians have looked for loopholes in its tenant that evolution is driven by competition. End quote. Okay. So firstly, some theories are unlovable as Pinker begins there. Well, I guess that's quite right. They shouldn't be lovable, or at least people shouldn't love their own theories. People shouldn't believe their own theories. It is only by criticizing them that we can improve our particular circumstance, solve our problems. Now, on the one hand, you might say, well,

### 30m

we should love our theories because they're the very things that allow us to go around routinely solving problems anyway. So the laws of general relativity, the laws of gravity enable us to have things like the GPS system. So shouldn't we love that theory? Well, on the one hand, perhaps yes. And on the other hand, perhaps if you think that criticism is the opposite to love, then we shouldn't love the theory because we want to eventually improve on the theory. And only by criticizing it can we find flaws in it and therefore improve on it. And then on yet another hand, you might say, well, in fact, criticism properly applied is indeed a sign of deep love. People don't tend to criticize things they don't care about at all. So it's only things that people can be bothered with that they criticize. I know this is true of myself. If there's certain things that people don't care about, there's a lot of bad ideas out there, but you can't go around trying to criticize all of them. That takes far too long. There's just too many bad ideas. So you pick the best of the bad ideas.

### 31m

You pick the best of the ideas and you criticize those perhaps because you care about those ideas and you want to improve upon them, whatever the case. Yes, in one sense, theories are unlovable. So I can agree with Pinker there. Let's continue. Pinker writes, quote, One of the most hated theories of our time is, This past Christmas season, CBS This Morning ran a heartwarming segment on a study that dropped thousands of money-filled wallets in cities across the world and found that most were returned, especially when they contained more money, reminding us that human beings are generous and honest after all. The Grinch in the story? Rationalist approaches to economics, which suppose that the truth is, that the truth is, that the truth is, that the truth is, that the truth is, that people live by the credo, finders keepers, losers weepers. What exactly is this mean-spirited theory? It says that when faced with a risky decision,

### 32m

rational actors ought to choose the option that maximizes their expected utility, namely, the sum of its possible rewards weighted by their probabilities. Outside of economics and a few corners of political science, the theory is about as lovable as Ebenezer Scrooge, people interpret it as claiming that humans are or should be selfish psychopaths, or that they are uber-rational brainiacs who calculate probabilities and utilities before deciding whether to fall in love. Discoveries from the psychology lab showing that people seem to violate the theory have been touted as undermining the foundations of classical economics and with it the rationale for market economics, end quote. And, you know, my reflection on this, is if people violate the theory of rationality as laid out here, it wouldn't undermine the rationale for market economics, by the way. The free market is not to be argued for on the basis

### 33m

of anything other than it's the moral thing to do. The free market is simply the market with coercion removed. So that is prior to any other consideration, even if there was some sense in which wealth was to be generated faster by someone else. If there was some other mechanism, some other magical mechanism, it still wouldn't be right to coerce people. Coercion is fundamentally the wrong way of going about things. So even if there was some result out of a psychology lab that showed that people flouted the rules of market economies, that doesn't mean that therefore there is something dubious about the market. In fact, there's probably something dubious about the psychological experiments. But the more central point is no result from psychology can change the fundamental moral principle that coercion is wrong. And therefore, a free market is the only moral way in which people should engage in trade with one another. But let's get going. Pinker writes, quote, In its original form, though, rational choice theory is a theorem of mathematics,

### 34m

considered quite beautiful by aficionados, with no direct implications for how members of our species think and choose. Many consider it to have provided the most rigorous characterization of rationality. Rationality itself, a benchmark against which to measure human judgment. As we shall see, this can be contested. Sometimes when people depart from the theory, it's not clear whether people are being irrational, or the supposed standards of rationality are irrational. Either way, the theory shines a light on perplexing conundrums of rationality, and despite its provenance in pure maths, it can be a source of profound life lessons, end quote. So there we have the first indication that, Pinker himself, as the author of this chapter, with a chapter on rational choice theory in a book called Rationality, is saying that the very theory he's explaining here might itself be

### 35m

irrational. But he's not coming down on one side or the other. He's just saying that this is a possibility, that the supposed standards of rationality are irrational. Supposed standards, he should concentrate on that perhaps a little bit more. These are the supposed standards. And as David points out in the beginning of Infinity, these can't be the standards of rationality. This can't be the standards of rationality. These can't be the standards of rationality. These can't be a model for the way in which people go about making decisions. What people do is to create new options that weren't there in the world prior to trying to make the decision. And upon making the decision, they choose one thing, ruling out all of the others, never mind weighting and probabilities and everything that Pinker has so far said here. So Pinker is quite right in highlighting the fact that sometimes people depart from this theory. And no wonder, you know, taken seriously, people always depart from this theory because this theory is so important to them. And this theory is not a model for decision making. It's a model of something, an abstract process named decision theory. But it's that abstract process does not in any way model the real life

### 36m

process of the same name, as David points out. And this is key. Now, Pinker then goes on in this section here to talk at length about the history of decision theory and how it came out of game theory. So it's a version of game theory and mentions all the usual luminaries from Blaze, Pascal to John von Neumann and various economists and so on and so forth. So we don't need to go through that. We don't need to talk about the whole history of this decision making thing. But I do want to highlight what Pinker then goes on to say. Again, it's very curious for me that he includes this chapter and lengthy discussions about how rational choice theory can be deployed to actually make real life decisions in the real world. So it seems to be claimed throughout the chapter. But he does say here in this section, quote, rational choice is not a psychological theory of how human beings choose or a normative theory of what they ought to choose, but a theory

### 37m

of what makes choices consistent with the chooser's values and each other. That ties it intimately to the concept of rationality, which is about making choices that are consistent with our goals, end quote. Okay, so there we have it. So it's not a theory about how human beings choose, but it's a theory about how human beings choose. So it's not a theory about how human beings choose, but rather, once you've made a choice, to see whether or not your choice is consistent with your values. Well, I don't know how much that is different to what rational choice theory aims to be in the first place. I'm skipping a little more. And then Pinker goes on to say, quote, the beauty of the theory is that it takes off from a few easy to swallow axioms, broad requirements that apply to any decision maker we'd be willing to call rational. It then deduces how the decider would have to make decisions in order to stay true to those requirements. The axioms have been lumped and split in various ways. The version I'll present here was formulated by the mathematician Leonard Savage and codified by the psychologists Reed Hastie and Robin Dawes. And Pinker goes on

### 38m

to write, quote, a theory of rational choice. The first axiom may be called commensurability. For any options A and B, the decider prefers A or prefers B or is indifferent, between them. This may sound vacuous. Aren't those just the logical possibilities? But it requires the decider to commit to one of those three, even if it's indifference. The decider, that is, never falls back on the excuse, you can't compare apples and oranges. We can interpret it as the requirement that a rational agent must care about things and prefer some to others. The same cannot be said for non-rational entities like rocks and vegetables. The second axiom, transitivity, is more interesting. When you compare two options at a time, if you prefer A to B and B to C, then you must prefer A to C. It's easy to see why this is a non-negotiable requirement. Anyone who violates it can be turned into a money pump, end quote. And then Pinker goes on to provide some

### 39m

examples, which are really trivial, of the way in which, obviously, if you prefer A to B and B to C, then you must prefer A to C. We won't go through the examples. There are seven axioms he goes through all together. Let me mention just a couple more, okay? I don't think we need to go through all of them. Quote, the third is called closure. With God playing dice and all that, choices are not always among certainties, like picking an ice cream flavor, but may include a collection of possibilities with different odds, like picking a lottery ticket. The axiom states that as long as the decider can consider A and B, the decider can also consider a lottery ticket that offers A with a certain probability, P, and B with the complement probability, 1 minus P. Within rational choice theory, although the outcome of a chancy option cannot be predicted, the probabilities are fixed, like in a casino.

### 40m

This is called risk, and may be distinguished from uncertainty, where the decider doesn't even know the probability and all bets are off, end quote. Okay, so in this case, Pinker is distinguishing between what he says is risk, which is where you know what the probabilities are, and that is to be distinguished from uncertainty, where the decider doesn't even know the probabilities and all bets are off. The curious thing is, within a page of having said this, between distinguishing risk, where you know the probabilities, and uncertainty, where you don't know the probabilities, he says the following. In fact, it comes up in the very next axiom that he discusses, and it's, well, quote, I'll call the fourth axiom consolidation, Life doesn't just present us with lotteries, it presents us with lotteries whose prizes may themselves be lotteries. A chancy first date, if it goes well, can lead to a second date,

### 41m

which brings a whole new set of risks. This axiom simply says that a decider, faced with a series of risky choices, works out the overall risk according to the laws of probability explained in chapter four, end quote. I won't go on, but if we're talking about a going on a date with another human being, if you go on a date with someone, this is not in the realm of risk. You do not know the probability of success on the date. It's an area of uncertainty, where there is no knowable probability. So this doesn't make any sense. It's almost within the same breath that Pinker has distinguished between risk and uncertainty, and then goes straight into, launches straight into, talking about how a, date with another person, a creative entity, can be judged in terms of risk. In other words, known probabilities. So I'm not understanding precisely what Pinker is saying. I'm not sure

### 42m

whether there was a sub-editor here who might've wanted to say, instead of using the word risk there, don't you mean uncertainty? In other words, he should have said, quote, a chancy first date, if it goes well, can lead to a second date, which brings a whole new set of uncertainties. The axiom simply says, that a decider faced with a series of uncertain choices works out the overall uncertainty according to laws of uncertainty. As you can see, this is a very confused way of thinking about real life outside of the casino, where we don't know what the probabilities are, where there is an open-ended range of different things that could happen, an infinite number of things that could happen, especially when you're dealing with other people, other people who create, create, create, create, create, create, create, create, create, create, create, and can behave in completely, inherently unexpected ways. Okay, I'm skipping a fair bit. He goes on to the fifth axiom and he says, quote, the fifth axiom independence is also interesting. If you

### 43m

prefer A to B, then you also prefer a lottery with A and C as the payouts to a lottery with B and C as the payouts, holding the odds constant. That is, adding a chance at getting C to both options should not change whether one of them is going to win or not. That is, adding a chance at getting one is more desirable than the other. Another way of putting this is that how you frame the choices, how you present them in context should not matter. And that's quite right as well. But again, we're focused on gambling again. We're again concentrating on things like lotteries, gaming machines, where asymptotically, we can imagine a situation where a computer is programmed to as closely model the probability calculus as one might like. And it's very difficult to have genuine random number generators, of course, which is what you would need for a proper probability calculus. Nevertheless, okay, we can approach it reasonably well. But the real world, the real world is not like this. It is not going to obey the

### 44m

probability calculus. Pinker goes through, you know, axioms six and seven. And again, many more examples are almost always going back to gambling, coming up with games of chance about how to understand the probability calculus. And again, many more examples are almost always going back to gambling, coming up with games of chance about how to understand how these axioms might work in abstract terms. Although the way it's written is, well, this is applicable to real life, even though we're talking about chances of winning lotteries and that kind of thing. So skipping across all of that, Pinker gets to the point where he says, quote, now here is the theorem's payoff to meet these criteria for rationality. In other words, the axioms he's just discussed. The decider must assess the value of each outcome on a continuous scale of desirability. Multiply by its probability and add them up, yielding the expected utility of that option. In this context, expected means on average, in the long run, not anticipated. And utility means

### 45m

preferable by the light of the decider, not useful or practical. The calculations need not be conscious or with numbers. They can be sensed and combined as analog feelings. Then the decider should pick the option with the highest expected utility, that is guaranteed to make the decider rational by the seven criteria. A rational chooser is a utility maximizer and vice versa, end quote, pausing there. So there we have the admission that this rational person can be perfectly rational by falling back on their emotions and their feelings and not ever actually being concerned about performing real life calculations or even considering the axioms at all. Except in this sort of intuitive way. Now I have no problem with that, with people intuiting their way to the best explanation and therefore to the preferred decision. But again,

### 46m

all of that would just to say it makes this model of decision theory utterly irrelevant to real life. If you're falling back on your internal preferences, which you arrive at by consulting your own feelings on the matter, this one feels more preferable to that one. In what sense are you really weighing up the options? You're just saying this one feels worse, therefore you're ruling it out. And this one feels better. There's no weighing going on. There's no you adding a particular weight to a thing. You can't add emotion to something. You just are the emotion at that particular time. You're conscious of a particular feeling. And so therefore you choose the thing that seems to you most preferable. That's the best explanation. But Pinker goes on to say, after having just said, quote, a rational chooser is a utility maximizer and vice versa. And goes on, to be concrete, consider a choice between games and a casino. In craps, the probability of rolling a seven is one in six, in which case you would win $4. Otherwise,

### 47m

you forfeit the $1 cost of playing, end quote. So you can see, I guess, why I'm pausing here. To be concrete, he says, consider a choice between games and a casino. So to be concrete, and this happens again and again throughout the chapter, to be concrete, let's consider what's going on in a casino. How many of us go to casinos? How good is a casino, a model of real life? A casino has fixed odds. And always in the favor of the house, by the way. The casino always wins. They've fixed the odds. They know that they're going to win. But this coming back to games of chance, coming back to the casino, as if the world is one big casino. Pinker doubles down on this. And he says, he goes, to say later on, I'm skipping a little, but he says, quote, games of chance make it easy to explain the theory of rational choice because they provide exact numbers. We can multiply and add. But everyday life presents us with countless choices that we intuitively evaluate in terms

### 48m

of their expected utilities. I'm in a convenience store and I don't remember whether there's milk in the fridge. Should I buy a quart? I suspect if I'm out and if that's the case and I forgo the purchase, I'll be really annoyed at having to eat my cereal dry tomorrow. Warning. On the other hand, if there is milk at home and I do buy more, the worst that can happen is that it will spoil. But that's unlikely. And even if it does, I'll only be out a couple of bucks. So all in all, I'm better off buying it. The theory of rational choice simply spells out the rationale behind this kind of reasoning, end quote. So there we have it. Like there we have an example of where Pinker admits a couple of things. One, he seems to be saying there that rational choice theory really is behind these common day-to-day decisions that people make. But on the other hand, he's also saying that, well, it doesn't involve numbers. It doesn't involve actually knowing probabilities or calculating anything with probabilities at all. In other words, the real life scenario is not like a casino.

### 49m

The real life scenario is where we are guessing. Now he uses the word intuit, whether we intuitively evaluate in terms of expected utilities. A fancy way, I would say, of simply saying, guessing what the best explanation is. Not having a best explanation, not knowing whether there's milk in the fridge or not, one picks the best alternative. Well, there's very little to lose by buying more milk. Milk these days happens to last, what, a week or more? You're easily going to be able to consume that milk before the time that it goes off, before it passes the expiry date. We aren't making calculations. We are coming up with good explanations. And if we don't have a good explanation, or if we have a bad explanation, we fall back on that explanation. And that's where we fall back onto the best available explanation, the best guess that we happen to have, ruling out all of the others. So although he begins with the claim that games of chance make it easy to explain the theory of rational choice, he then goes on to use, and he tries to use an example, tries

### 50m

to summon up an example from real life that is completely divorced from the casino, that has nothing to do with providing probabilities. There is no probability of milk in the fridge. He doesn't know it, and no one can know it. It either is there, or it isn't there. There is no probability of milk in the fridge. That's the key thing. Either it is there or it isn't there. And if you don't know, then the best option is to assume it isn't there if you think that it's really going to be annoying tomorrow morning not to have any milk. You're there at the shop right now. And if you buy extra milk, it's not like the milk is going to spoil, because milk lasts a long time. These are the real life, actual explanations that people conjure in their mind, never mind probabilities, never mind decision theory, never mind consulting axioms, never mind trying to be perfectly rational. You are conjecturing explanations and ruling out the worst ones, and making the decision based upon your best explanation.

### 51m

Now again, I'm skipping a rather lot of the chapter. The next section is titled, How Useful is Utility? Again, we go more into games of chance. I'll pick up just one part where he talks about, he said that, well, you know, expected utility. He writes, quote, which would you rather have? $1,000 for sure or a 50-50 chance of winning $2,000? Their expected value is the same, but most people opt for the sure thing. This doesn't mean they are flouting rational choice theory. It just means that utility is not the same as value in dollars. Utility of $2,000 is less than twice the utility of $1,000. Fortunately, for our understanding, people's ratings of their satisfaction and their choice of gambles point to the same bent over curve relating money and utility, end quote. Yes, so surely different people will have different ways in which to

### 52m

assess a situation like this. Again, we're falling back onto kind of games of chance, these abstract, non-real situations which don't actually have any... analog with a real-life decision that people make. A person who is starving and is poor or is unemployed should take the $1,000. That's the rational thing to do. A person like Elon Musk, who is given the same choice, he's probably earning more money than it takes to make that decision. But why not go for the $2,000? The $1,000 doesn't make any difference, nor would the $2,000. But maybe just for the fun of it, he would go with the 50-50 chance. Having fun is rational. And this is something rational. Rational choice theory, or rational choice theories, don't seem to account for. And this is the whole idea with casinos. Yes, rationally, the thing to do is not to bet your money if your only consideration is money. If that's your only consideration is that, well, I'm going to definitely lose. Well, not definitely, but the probability of my losing my money walking into

### 53m

this casino and betting on the various games and machines and things is higher than me walking out and winning. If the only consideration is money, then yeah, it's irrational to partake in that kind of activity. But that's not the only consideration. People actually have fun. And Pinker goes on to concede this, that even when it comes to casinos, well, people value other things at the casino as well. They might be very well plowing their money into the game machines, but at the same time, they're entertained by, well, various things that go on at casinos. Pinker actually says, quote, so I'll pick it up when he talks about this, unfortunately for the theory, by the same logic, people should never gamble, buy a lottery ticket, start a company, or aspire to stardom rather than become a dentist. But of course, some people do, a paradox that tied classical economists in knots. The human utility curve can't both be concave, explaining why we avert risk with insurance, and convex, explaining why we seek risk by gambling.

### 54m

Perhaps we gamble for the thrill, just as we buy insurance for the peace of mind. But this appeal to emotions, just pushes the paradox up a level. Why did we evolve with the contradictory motives to jack ourselves up and calm ourselves down, paying for both privileges? Perhaps we're irrational, and that's all there is to it. Perhaps the showgirls, spinning cherries, and other accoutrements of gambling are a form of entertainment that high rollers are willing to spend for, end quote. Yes. Yes. Precisely. Precisely. People are going to get entertained. They're not technically losing money. They're paying for something. Now, of course, they could sit there and not partake in the gambling, and just watch the, quote, showgirls, spinning cherries, and other accoutrements. Okay, they could do that, and then they come out on top, I suppose, in some way, shape, or form. But the gambling has this fun element to it, and that fun doesn't count for nothing. It counts for something.

### 55m

And might I just say, as well, Pinker began that section by saying, unfortunately for the theory, by the same logic, people should never gamble. Buy a lottery ticket, which is the same thing. Start a company, or aspire to stardom. But hold on. Starting a company is not the same sort of thing as buying a lottery ticket. Now, of course, people talk about this as if they're the same kind of thing, but they're not. Gambling and buying lottery tickets have known odds. You can know the chance of success ahead of time. And typically, it is very, very low, especially with lottery tickets. The one in the 200 million kind of category of winning the lottery ticket is very, very low. And if you buy a lottery ticket, the jackpot, a considerably higher probability of winning at least some prize. But it's nothing like starting a company. Starting a company depends upon the explanations. It depends upon whether or not the service or good being produced by the company fits the market. Whether or not the people working in the company work well together, have themselves good explanations about

### 56m

how to make a successful company work. This is completely unlike the other situation where people aren't involved. People can't do anything. They can't do anything. They can't do anything. It doesn't matter how much effort you put into gambling and to trying to win the lottery, that doesn't change the odds. But with a company, it makes all the difference in the world. The more effort people put in, the more creativity they bring to bear, the more they try and problem solve and overcome difficulties, and indeed, change tack when it comes to building a company, error correcting, incrementally trying different versions of the company, different versions of the service of the product, the more, the opportunity for success. It's not a chancy thing. It's not probabilistic. It's not a flip of the coin. This is people being motivated to try to succeed, which makes a difference, unlike with trying to succeed at the lottery. The more and more that you try and be successful at

### 57m

the lottery, in other words, putting more and more money into the lottery, the more likely you are to lose it all. This is the opposite to a company. If you're really trying hard and if everyone's pulling together and there's a good idea, well then, you should expect success more than if you were doing the opposite, namely not caring, not really trying hard, not really all working together. So that's the difference. That's the difference between a casino and the rest of reality. Again, skipping a lot. Skipping a lot of this chapter. And I'll just mention again, there's one part here which I'm basically skipping over, but it's titled, Violating the Axioms, How Irrational. And Pinker writes, quote, you might think that the axioms of rational choice are so obvious that any normal person would respect them. In fact, people frequently cock a snook at them, end quote. And then he goes on and explains all the ways in which people reasonably seem to give up on the axioms of

### 58m

rational choice theory. Quite rightly, too, they can violate some of the axioms for quite reasonable reasons. Let me pick up on one of these that Pinker mentions. He writes, quote, a different family of violations involve a concept introduced by the psychologist Herbert Simon called bounded rationality. Theories of rational choice assume an angelic knower with perfect information and unlimited time and memory. For mortal deciders, uncertainty in the odds and payoffs and the costs of obtaining the axioms of rational choice are the same as the costs of obtaining and processing the information have to be factored into the decision. It makes no sense to spend 20 minutes figuring out a shortcut that will save you 10 minutes in travel time, end quote. Just pausing there. Yes, yes, this whole idea of theories of rational choice assume an angelic knower with perfect information, unlimited time and memory. Perfect. So Pinker admits right there that that can't possibly apply, this whole thing can't possibly apply to human beings, as we mentioned

### 59m

with Captain Sully right at the beginning. If he had unlimited time, then, of course, he would have could also figure out whether or not he could make it to the airport or not. And these simulations kind of do have that effectively unlimited time anyway, you know, because they can do their calculations so much more swiftly. But a human being, a creative person operating in the real world where one second per second is passing, has to do something different, has to create explanations and refute them very, very quickly. And time is going on. So they're not the angelic knower, obeying rational choice theory. Pinker goes on to say, quote, The costs are by no means trifling. The world is a garden of forking paths, with every decision taking us into a situation in which new decisions confront us, exploding into a profusion of possibilities that could not possibly be tamed by the consolidation axiom. Simon suggested that a flesh and blood decider really has the luxury of optimizing, but instead must satisfy us.

### 1h 0m

A portmanteau of satisfy and suffice. Namely, settle for the first, alternative that exceeds some standard that's good enough. Given the costs of information, the perfect can be the enemy of the good. End quote. Yes, perfect. Again, we can't always know what the optimal, the optimal decision will be in any given situation, especially when time's a factor. And only in retrospect, when someone decides to do a simulation, in retrospect, can you then determine what the optimal decision might be. Again, the optimal decision for Captain Sully trying to land his aeroplane was to, yes, immediately turn back for the airport, but he didn't have the opportunity to act immediately. Why? Because he didn't know what to do. He didn't know that was the right thing. And insofar as the simulation does know that's the right thing, it's only because it has tried various other things and found out that, well, this one happens to have worked. Now, let's say that it didn't. Let's say that the simulation figured out that you couldn't have made it back

### 1h 1m

to the airport. If you were to go back to the airport. If you were to go back to the airport. If you were to go back to the airport. If you were to go back to the airport. If you were to go back to the airport. If you were to go back to the airport. If you were to go back to the airport. You would have run out of, you would have crashed into the ground. Well, then that's a different scenario. Then what would the simulator do? Well, there's just so many questions here. You know, in a real life situation, the simulation is unable to predict what's really going on in the real world. Is there yet another flock of birds out there somewhere? Is a gust of wind going to cause the aircraft to change trajectory? Are other aircraft in the area going to have an effect on the way in which you're going to move? There's so many questions. going to be boats on the river where you decide to land. Things the simulation can't account for in a real life situation until they actually encounter it for the first time. Now this is the thing about human decision making that I come back to. Many of these decisions are things that people will be encountering for the first time. Situations people are encountering for the first time. And because they're encountering it for the first time, that's why the creativity is required.

### 1h 2m

And skipping a little, and Pinker goes on to say, quote, we don't do all the multiplications and additions necessary to melt down the attributes of an item into a glob of utility. Instead, we may consider its attributes one by one, whittling down the choices by a process of elimination. In choosing a college, we might first rule out the ones without a lacrosse team, then the ones without a medical school, then the ones too far from home, and so on. End quote. Indeed, a process of elimination. We have these colleges before us, we have a decision to make, and we rule out the ones we don't like. In my case, I kind of had an explanation of the one I wanted to go to, and I chose that one. None of the others were able to meet the standards I'd set for myself about which college to go to, which university to go to. All the others were ruled out because they didn't offer this particular course that I wanted to do. That was an easy decision to make, but it came down to

### 1h 3m

not a weighting of the options. In no way, shape, or form did it come down to weighting of options. So, skipping a little, and Pinker does try and bring it back to a real-life example. But again, this fails. Although it is an example that is from outside of the casino, it's no longer about games of chance. It's about, ostensibly, hiring someone for a role. And he draws on the work of Zversky and Kahneman. And, well, you know, the way I see it, it's not about hiring someone for a role. These guys won the Nobel Prize for this kind of thing in economics, trying to figure out how people are or are not rational decision-makers when it comes to rationality. Well, let's see what Pinker has to say about this particular example that they concoct. Quote, Zversky imagines three job candidates differing in their scores on an aptitude test and years of experience. So, the first candidate is Archer, and he scores 200, and he's got six years of

### 1h 4m

experience. Baker is the second one. He scores 300, and he's got six years of experience. He scores 400, with only four years of experience. And last of all is Connor, who scores 400 on his aptitude test, but he only has two years of experience. Pinker goes on to explain, quote, a human resources manager compares them two at a time with this policy. If one scores more than 100 points higher in aptitude, choose that candidate. Otherwise, pick the one with more experience. The manager prefers Archer to Baker, more experience. Baker to Connor, more experience, and Connor to Archer. Higher aptitude. When experimental participants are put in the manager's shoes, many of them make intransitive sets of choices without realizing it. End quote. Okay, so when someone is put in this artificial position of trying to decide between these candidates, based on no other information, sometimes they make the illogical choice. But once more, this is a terribly abstract example, utterly denuded, of the real-life

### 1h 5m

process of, hiring people for a position. The reality is that people go into these kind of interviews with a spectrum of candidates and have to fill the position. And perhaps they rely on aptitude tests. Perhaps they rely on things like number of years of experience. But it's pretty rare that it only comes down to those things, that effectively mechanical process of, you know, turning the handle of a calculator so that you can spit out the end of it, the ideal candidate. But that might not be the ideal candidate. People tend to fill positions at companies, you know, fill vacancies, by interviewing people and getting a feel for who they are and whether or not they're going to be suited, whether or not they're going to fit in with the other workers, whether or not they're going to be competent at a particular job. Never mind how many years of experience they have. Can they answer questions about how you can solve this particular problem in this particular job? Don't worry about the aptitude test. Again, do you have relevant knowledge for this particular position? So once more, even when trying to take,

### 1h 6m

the examples out of the realm of the casino, we're still left with this abstract spherical cow, so to speak, of an example. It's not real. It doesn't correspond to anything in the real world. But again, we go through once more, many, many pages worth of analysing different ways in which one might choose the best ticket for competing lotteries. Pinker says, you know, for example, here, here's his first example. You choose the super cash option where you have 100% chance of winning $1 million or the Powerball option where you have a 10% chance of winning $2.5 million and an 89% chance of winning $1 million. And he says on this, quote, though the expected value of the Powerball ticket is larger, $1.14 million, most people will go for the sure thing, avoiding the 1% chance of ending up with absolutely nothing. That doesn't violate the axioms. Presumably,

### 1h 7m

the utility curve is going to be higher. But if you choose the super cash option, you bend over, making them risk averse, end quote. So he goes through this example and wonders, you know, whether or not it's rational to pick one over the other, even if, you know, the expected value, the expected value is higher for the other, you know, should you choose certainty over, you know, uncertainty? Again, not real life doesn't, there has no analogue in real life. No one's really making this decision. There's no such thing as a 100% chance of winning $1 million. I don't know how much people are betting on this particular thing anyway. What does a ticket cost? You know, $199,000? I don't know. We're not told, actually. And he goes through many, many more examples with different percentage chances of winning different amounts of money. What would you choose in these different situations? And, you know, if you're not picking the one with the highest utility, then on some account, you're being irrational. But again, I'm overemphasizing it, I suppose. This has no analogue in real life decision making. It applies specifically to this

### 1h 8m

situation, which itself doesn't arise in real life. There isn't a situation where you're forced to choose between these different lotteries. So I'm skipping almost all of that. It's many pages worth, and I'll pick it up where Pinker says, quote, I once asked a family member who bought a lottery ticket every week why he was throwing his money away. He explained to me, as if I were a slow child, you can't win if you don't play. His answer was not necessarily irrational. There may be a psychological advantage to holding a portfolio that has limited safept случай aspects, which includes the possibility of a windfall rather than single dominantly maximizing expected utility, which guarantees it can't happen. End quote. This shocks me, that is a psychologist would ignore the role of emotion and the role of fun, which again, aren't worth nothing. Pinker says there I once asked a family member who bought a lottery ticket why he was throwing his money a way. But how is he throwing his money away? If he's having fun, if each time the

### 1h 9m

lottery will be moving, he could throw his money away for fun. Despite the windfall without a numbers are drawn he's sitting there in front of the television or wherever it happens to be and he is looking at those lottery numbers and his ticket and comparing and he's getting a thrill that's excitement he's paid for that it's rather like a roller coaster you know you you you're having fun doing this thing it's just a sensation that you're willing to pay for i don't understand how that's throwing your money away you're paying for that specific feeling the the the thrill of perhaps winning that's not worth nothing and you know that this kind of this this haughty way of saying his answer was not necessarily irrational no his answer was not irrational at all he's exactly right you can't win if you don't play that's perfectly rational it's exactly right now considering the economics the finances and nothing but of course the person you know in a typical lottery you know with a draw whatever it is six numbers correctly out of 38 that are available or whatever it happens to be yeah your chances are like one in 200 million or

### 1h 10m

something like that so it isn't rational if we're only considering just the economics of the matter but once more it's like would pinker think would people analyzing situations like that this say that going to a fun park is irrational after all you're giving away money for what apparently getting nothing back but riding on roller coasters but why should that be worth your money you're not getting a return on the roller coaster are you well of course you are you're having fun in the same way that a lottery participating in a lottery and gambling can be fun now pinker then goes on to talk at length about the framing of these particular questions and these psychology slash economics thought experiments that that people engage in i'm going to skip the part where again he goes through games of chance and go to again what purports to be a realist life situation but when looked at closely isn't okay here we go quote once again it's not just in

### 1h 11m

contrived gambles so it's useful to notice that their pinker admits that these are contrived gambles so the gambling examples he admits are contrived but that should be a big red flag for him for the remainder of his examples because they too are contrived so let me continue quote suppose you have been diagnosed with a life situation but when looked at closely isn't okay here we go quote once again it's not just in contrived gambling but when looked at closely isn't okay here we go quote once again it's not just in life threatening cancer and can have it treated either with surgery which incurs some risk of dying on the operating table or with radiation experimental participants are told that out of every 100 patients who choose surgery 90 survived the operation 68 were alive after a year and 34 were alive after five years in contrast out of every 100 who chose radiation 100 survived the treatment 77 were alive after a year and 22 were alive after five years fewer than a fifth of the subjects were alive after a year and 32 were alive after five years in contrast out of every 100 patients who choose surgery 90 survived the operation 68 were alive after five years in contrast out of every expected utility over the long term end quote now notice in this example it's the use of experimental

### 1h 12m

participants in other words once more this is abstracted away from real life so to what extent is it informative for real cancer patients these are not real cancer patients these are people who are presumably brought into the psychology faculty of some university sat around a table and given a survey that's what's going on here and so it's like a maths problem pinker goes on to say quote but now suppose the options are described differently out of every 100 patients who chose surgery 10 died on the operating table 32 died after a year and 66 were dead within five years out of every 100 who chose radiation none died during the treatment 23 died after a year and 78 died within five years now almost half chose radiation they accept a greater overall chance of dying with the guarantee they won't be killed by the treatment right away but the two pairs of options pose the same odds all that changed was whether they were framed as the number who lived perceived as a gain or the number who died perceived

### 1h 13m

as a loss end quote i hate to say this is this is what passes for psychology this is psychological research but it's not real life so can it be applied to the real life situation of someone being diagnosed with cancer is it important which way the odds are put to them well i would put it to you the listener that a doctor a caring doctor an oncologist a a a doctor who deals with cancer surgery removal of tumors and that kind of thing is going to pose the odds in both ways and in multiple ways over many consultations and the patient is going to not just be sitting in a room dealing with this survey they're going to talk to a number of different experts family members and other people who will be advising them and they will consider all the ways in which to assess the risks for themselves and to come up with the best explanation for their particular circumstances this example is to use pinker's own word contrived it is contrived it

### 1h 14m

is abstracted away from the real life situation where you have been diagnosed with a life threatening cancer when you have been diagnosed with a life threatening cancer you are not simply presented with the odds in one direction you're going to be provided with the odds from every direction possible and often it won't be the odds because for you the situation will be different to the typical person you might not be the typical person you might be more susceptible to dying in the operating theater or less depending upon your age and all sorts of things like that there may actually be no statistics available for you and your particular life-threatening cancer the medical fraternity is not typically out to try and trick you into choosing one option over the other which is what's going on here with the example it's like oh look how irrational people are just depends upon the way in which they're presented the odds yes they make mistakes people make errors

### 1h 15m

but i tell you what if people are shown the error of their ways it only takes a few times for them to make the right choice the correct choice given this kind of puzzle now i'm again i'm skipping a vast amount of this chapter um and i'll just pick it up where um pinker has a personal anecdote to some extent um he writes quote the asymmetry between gains and losses too becomes more explicable when we descend from mathematics to real life our existence depends on a precarious bubble of improbabilities with pain and death just a misstep away as versky once asked me when we were colleagues how many things could happen to you today that could make you much better off how many things could happen to you today that could make you much worse off the second list is bottomless it stands to reason that we are more vigilant about what we have to lose and take chances to avoid precipitous plunges in well-being and at the negative pole death is not just something that

### 1h 16m

really really sucks it's game over with no chance to play again a singularity that makes all calculations of utility moot end quote quite right of course the first list of all the ways in which you could be better off at the end of the day is also limitless but i suppose he's right in saying that well the worst thing that could happen is death which leads to death and death is leaves no more options open but that's not quite the same as in the alternative of a way in which things could become better of course you could find the ultimately good thing the way in which to become effectively immortal that could be a good thing that could happen but there's no real equality on the scales of death versus anything else death is as he says there game over skipping over a little more and pink goes on to begin a section titled rational choices after all question mark and behavioral economics showing all the ways in which people flout the axioms of rational choice has become something of a sport and not just a sport five nobel prizes have gone to discoverers

### 1h 17m

of the violations part of the fun comes from showing how irrational humans are the rest from showing what bad psychologists the classical economists and decision theorists are gigarenza loves to tell a true story about a conversation between two decision theorists one of whom was agonizing over whether or not they were right or wrong and the other was agonizing over whether or not to take an enticing job offer at another university his colleague said why don't you write down the utilities of staying where you are versus taking the job multiply them by their probabilities and choose the higher of the two after all that's what you advise in your professional work the first one snapped come on this is serious end quote quite right so when pushed to make a genuine decision one of the decision theorists basically points out that this is serious we're not we're in the within we're in the realm of real life decision making not in the concocted abstract realm of decision theory so

### 1h 18m

called decision theory he knew he seems to have known that it's a serious situation where we need to use our creativity and our ability to refute bad explanations and not weighing options and writing down probabilities he knew he couldn't write down the probabilities of success okay he's deciding whether or not to take a job how does he know what the probability of that being successful a successful decision is going to be he doesn't know so he knows that is a refutation of this whole call it something else don't call it decision theory i don't know what but it's not decision theory because it's not really about how human beings make decisions skipping over a little more and pinker picks it up by talking once more about a medical situation he says quote weighing risks and rewards can with far greater consequences also inform medical choices doctors and patients alike are apt to think and do things that are not in terms of propensities cancer screening is good because it can detect cancers and cancer surgery is good because it can remove them but thinking about costs and benefits weighted by their

### 1h 19m

probabilities can flip good to bad for every thousand women who undergo annual ultrasound exams for ovarian cancer six are correctly diagnosed with the disease compared with five in a thousand unscreened women and the number of deaths in the two groups is the same three so much more than the number of deaths in the two groups is the same three so much more than the for the benefits what about the costs out of the thousand who are screened another 94 get terrifying false alarms 31 of whom suffer unnecessary removal of their ovaries of whom five have serious complications to boot the number of false alarms and unnecessary surgeries among women who are not screened of course is zero it doesn't take a lot of math to show that the expected utility of ovarian cancer screening is negative the same is true for men when they when it comes to screening for prostate cancer with the prostate specific antigen test i opt out end quote wonderful so that there is an important use of statistics knowledge good explanations of

### 1h 20m

these tests which produce all of these terrifying false alarms so is it worth undergoing these scans for ovarian cancer or in the case of the prostate cancer for prostate specific antigen testing when you're screening for prostate cancer you're screening for prostate cancer you're screening for you get false positives and then people have unnecessary procedures which put them at a risk which may be as great as actually having the disease in the first place this is why simply considering the numbers is on its own an insufficient basis for making a decision you need to sit down with your doctor a number of doctors and come to a decision based upon your best understanding of what the heck is going on it's not about betting on things it's about understanding what's happening which of course can include the statistics statistics like that are very very important to know that these scans often result in false positives it says you have cancer but you don't

### 1h 21m

and then people go off and have these operations which turn out to be useless operations in fact damaging they never needed to have had unnecessary surgeries but this is why you would go for a second opinion perhaps a third opinion with various people various doctors and you needed to find a doctor who you have a good explanation you have a good explanation and you have a good explanation that the doctor is a knowledgeable expert in the area they're not some quack and there's bad doctors out there let's just face it which would be the lesson here because these statistics would be an average over all the scans that are being done by all the doctors and all the different places i don't know around the world or around america or something some doctors would probably have very different statistics to other doctors that would be worth looking into let me just go to the end of the chapter now because this is a long episode and let me pick it up in the final paragraph where pinker says quote even when exact numbers

### 1h 22m

are unavailable there is wisdom to be had in mentally multiplying probabilities by outcomes how many people have ruined their lives by taking a gamble with a large chance at a small gain and a small chance at a catastrophic loss cutting a legal corner for an extra bit of money they didn't need risking their reputation and tranquility for a meaningless fling end quote yes but casting this in terms of probabilities and mentally multiplying probabilities by outcomes is not the way to think about this the way to think about this is in terms of explanations having a good explanation if you don't have a good explanation in other words something like cutting corners or having a meaningless fling risking your relationship well these are bad explanations after all you're choosing short-term gain over long-term prosperity something like that it's a bad idea it's a bad idea we don't need to estimate probabilities that's not what's going on here we have good and bad explanations we have moral principles as well to help guide us it's

### 1h 23m

not merely about success it's about being able to live with yourself let's say so that even if you succeeded even if you actually were able to get through the short-term fling the meaningless fling or even if you're able to cut the corner and get away with it that's not the only consideration here you've got to live with yourself live with being dishonest you've got to live with being honest let's say pink goes on to say switching from losses to gains how many lonely singles forgo the small chance of a lifetime of happiness with a soul mate because they think only of the large chance of a tedious coffee with a bore as for betting your life have you ever saved a minute on the road by driving over the speed limit or indulged your impatience by checking your new text while crossing the street if you weighed the benefits against the chance of an accident multiplied by the price you put in your life which way would it go and if you don't think this way can you call yourself rational end quote and that's where he ends the chapter and it's a nice way to end the chapter because i can answer can you call yourself

### 1h 24m

rational in those situations by not multiplying the chance of an accident by the price you put on your life i don't do that i don't think honestly anyone does including pinker or anyone involved in decision theory i just don't think that that's what they do they have an explanation now sometimes people are unconsciously moving throughout the world with no explanation that's a bad thing so unthinkingly doing things like speeding in their car or checking texts while driving bad idea it's not about the probability of crashing your car it's that it's a bad idea that's a bad explanation that you can both concentrate on your phone and what text messages you've received and drive at the same time these things even for very good drivers are not compatible we have a good explanation of how a person a human being is able to control a vehicle and they need to have all their attention focused on the road and when you're crossing the street and walking across the street you should

### 1h 25m

be looking around it's got nothing to do with multiplying probabilities you can be rational rational without being ever concerned about probabilities except perhaps when you go to the casino and even then if what you're there for is to have fun the probabilities might not mean anything to you anyway so there we are the chapter chapter six about how to make rational decisions where even pinker himself says that maybe this scheme doesn't really apply to real life and many of the examples are contrived yet nevertheless he still asks us the question at the end and if we don't think this way in terms of rational choice theory and probabilities then are we rational well i can answer in the positive yes you can still be rational you can still call yourself rational but only if you have good explanations good explanations to guide your decision making where you don't you might want to rely upon your intuitions but if you don't have any of that then maybe what you want to do is to

### 1h 26m

sit down carefully and think if you have the time to and to come up with an explanation using your creativity and where you're pressed for time and like captain sully was at the beginning again we're not calculating probabilities we are quickly trying to conjecture explanations and the deciding on the best one on the best one on the best one on the best one on the best one on the best one on the best way forward by ruling out all of those other explanations that will lead to ruin and disaster until next time bye

