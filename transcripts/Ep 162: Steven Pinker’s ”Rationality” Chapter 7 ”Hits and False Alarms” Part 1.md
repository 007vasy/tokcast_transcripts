# Ep 162: Steven Pinker’s ”Rationality” Chapter 7 ”Hits and False Alarms” Part 1

Original Episode: [Ep 162: Steven Pinker’s ”Rationality” Chapter 7 ”Hits and False Alarms” Part 1](https://www.podbean.com/site/EpisodeDownload/PB13035573MQG5)

Audio Download: [MP3](https://mcdn.podbean.com/mf/download/ivutgi/Pinker_Hit_and_Miss_for_editaorlr.mp3)

## Transcript

### 0m

Welcome to the TopCast, where today I'll be talking about Chapter 7, Hits and False Alarms, subtitled Signal Detection and Statistical Decision Theory, from Steven Pinker's book Rationality. I'm not going to get far through the chapter today, indeed, just a couple of pages, because it's going to set the scene for the way in which you will see the rest of the chapter is going to go. This chapter follows on from the previous two, which were, of course, about Bayesian reasoning and rational choice theory, all about the uses of probability and statistics. And here we're going even deeper into the whole of statistical thinking and how statistical thinking might be used in order to make decisions. I'm going to have a lot of criticism about this very early on, and so it might be frustrating to the listener, and I apologize for that up front. But as a listener... We're stopping and starting, and we're not going to get very far through the chapter. I'm going to make very little progress.

### 1m

But there's no way around it, because early on, Professor Pinker is making a whole bunch of competing claims, making a bunch of claims that are at odds with the things that I talk about on TopCast so very often. And I think it's important to, again, as I keep on saying in my discussion of this book, to compare what is mainstream academic intellectual musings on this topic of rationality with what I would simply regard as actual rationality, actual epistemology, as explained by Karl Popper and David Deutsch, unfortunately ignored in a book like this, and shouldn't be, because it really is, that epistemology really is the way in which we can come to a rational understanding of the world using our reason. This chapter contains a lot of misconceptions, but whatever the case. Chapter 7, Hits and False Alarms. It's basically a summary. It's a summary of the previous two chapters and going a little bit further to try and explain ways in which Bayesian reasoning and the use of probability and now statistics

### 2m

can be utilized in making decisions. I'm going to have multiple problems throughout this chapter with the way in which examples attempt to be deployed, because as I've been saying on other episodes of TopCast recently, it seems to me that in academic philosophy, and this is really what we're doing here, we're doing a form of epistemology, which is a branch of philosophy, that when people engage in this sort of theorizing about how thinking and reasoning are done, or should be done, most rationally, let's say, how rationality works, they do so in the abstract. And when they try to bring it into the real world by talking about specific examples, it's still a fictional example, a thought experiment of some kind, or imagine this scenario rather than giving us something precise with meat on the bone, something with a place and a time and a date, people involved, where they actually use this stuff.

### 3m

This is one of the reasons that the work of Karl Popper and David Deutsch appeals to me, because we don't talk about just stuff occurring in the abstract. Karl Popper talks about what particular scientists did and when, what particular thinkers were thinking at a particular time and how they disagreed with other thinkers. And how to resolve these conflicts between ideas, which we call problems. Popper wanted to understand, my trope example that I always go to, as to how it was that the transition was made from Newtonian gravity through to Einstein's theory of general relativity. What was the role of Eddington's experiment in this? This is why I go to this particular example so often. It's a neat example. But it also exists as a model for every other kind of situation. A situation involving competing ideas, where we need to make, as this chapter will come

### 4m

to, a decision. A decision about what is the best theory, what is the best idea, what is the best explanation. An explanation is a word that is sorely missing from this chapter, unfortunately. It's not to say that it's wholly misconceived. There are parts of Rationality the Book by Steven Pinker that indeed hit the nail on the head. But it's the important misconception. It's the misconceptions that are worth lingering over. Recently on TopCast, I've also been talking about part of Popper's paper, or lecture rather, on the sources of knowledge and of ignorance. And what is amazing about this paper, apart from the fact that it is just written so clearly, it provides you with specific cases of philosophers engaged in debates and engaged in trying to make progress in philosophy itself, in trying to solve problems and to make progress. And they do. Popper speaks about the escape from authoritarianism, the deference that people used to have, sometimes we still do, but used to have for the priest, or for the medicine man, or for the king

### 5m

and so on and so forth. We escaped from that through empiricism. A famous empiricist was Francis Bacon, an Englishman who figured out that observation had a key role to play in coming to understand the world. I got the details wrong. But at least he understood. He understood that each person individually could use their senses in order to try and uncover the truth. They didn't have to defer to the king and to the priest. They had their own senses. They had their own way of getting information and checking their ideas against reality. Now, of course, Bacon thought that you could just see the facts of reality. He got kind of that wrong. And simultaneously, over in Europe, the rationalists, chief among them that Popper talks about is René Descartes. And what Descartes was doing was speaking about the use of reality. And what Descartes was doing was speaking about the use of reality. And simultaneously, over in Europe, the rationalists, chief among them that Popper talks about, is the use of rationality. The use of reason and how it didn't go wrong. It was a way in which you could avoid error. So he partly got the idea.

### 6m

Indeed, it is a way to help correct errors. It's just that you can't avoid them altogether. You can't see the truth. Both of these ideas, pure reason of the Cartesian kind and empiricism of Bacon's kind, endorsed the idea of manifest truth. And so, ultimately, they got things wrong. And in fact, they didn't. It led to a whole bunch of terrible errors. Once people think they're in possession of the manifest truth, once they think that they can see and identify truth in the world, they're liable to fall into tyranny. And this is Popper's great quip, that manifest truth is the root of all tyranny. Nevertheless, nevertheless, despite the errors and misconceptions in those two ideas, empiricism and pure reason, there is still truth to be found there. There is still truth to be found there. There is something correct in those ideas. There is virtue in endorsing the idea that, yes, observation is important, yes, reason is important.

### 7m

These things together are an escape from authority. It's just that the way in which these early philosophers conceived of it wasn't quite right. That in both cases, we are fallible. We need these things, but we're still fallible. And we can still generate knowledge, although that is going to be error-prone. But it's only through our observations and deployment of reason that we can continue to correct errors and make progress. So there is virtue in the misconception, and there is virtue in the misconception today that we'll talk about when it comes to rationality. It's just a shame that so few people understand and appreciate Popper, even now, publishing books in 2020, 2021, 2022. So this may get a little bit frustrating to begin with. I just don't find it's going to be illuminating for my particular audience. You will see that the errors are coming at us thick and fast, and so we're going to be pausing and just recognizing the errors are there. And we can conclude where one is going to go with this style of thinking, where the author is going to go with the style of thinking that he endorses.

### 8m

And I must say, early on, he begins really well with a concept of uncertainty, but quickly falls back into, let's say, manifest truth errors. So Pinker writes at the beginning here, quote, Rationality requires that we distinguish what is true from what we want to be true, that our heads are in the sand to build castles in the air or decide that the grapes just out of reach are sour. The temptations of wishful and magical thinking are always with us because our fortunes hinge on the state of the world which we can never know with certainty, end quote. Now that ending there of that section is beautiful, absolutely. We can never know with certainty. So here he is endorsing a form of fallibilism. Will he continue with this? We'll come to see that he doesn't quite, and that's a shame. He seems to forget rather quickly what he's just said there about, it's impossible to know with absolute certainty.

### 9m

But this doesn't deny us the capacity to know. Because to know does not mean to be certain of. To be certain of. These are separate things indeed. Certainty is a feeling, and a feeling is not the way we cash out knowledge claims. Knowledge claims are objective, independent of how we feel about them, call it certainty or not. This is why probability is inherently subjective. Different people place different values on how certain they are about something. So Pinker has begun reasonably well, reasonably well. He does say there at the very beginning that rationality requires that we distinguish what is true from what we want to be true. Yes, kind of. I'll give him a pass there. But of course. We don't know what is true. So really what rationality is doing is allowing us to distinguish between what we know to be an error and what we do not know yet contains error.

### 10m

And so we can sift between, again, Newtonian gravity and Einstein's general relativity because we haven't found any errors with Einstein's general relativity. It works. It's an explanation and description of reality. But we've found errors, errors with Newtonian gravity. It postulates a force. It postulates actions. It says there's an inverse square law where strictly there's not an inverse square law. So it's making multiple errors, useful as it is in many circumstances, it fails catastrophically in other circumstances. Okay. So it's not so much distinguishing what is true, namely we do not regard general relativity as true, but rather to distinguish between what we know is false, which is to say we have an explanation of how it's false and why, Newtonian gravity, but we do not yet know how general relativity works. We expect it to turn out false in the final analysis. One day there will be a successor theory to it. So we expect it to be false. We just don't know how it's false yet.

### 11m

So this is really the purpose of rationality. This is the better way to have started this particular chapter. Nonetheless, we'll give him a pass and we will say that we can't know with certainty is very good. Okay. He says that we can never know with certainty. Excellent. Full marks on that. I shouldn't be grading him, but okay. Let's keep going. And he writes, quote, to keep up on our gumption and safeguard against taking painful measures that may prove unnecessary. We are apt to see what we want to see and disregard the rest. We teeter on the edge of the bathroom scale in a way that minimizes their weight, procrastinate getting a medical test and may return an unwelcome result and try to believe that human nature is infinitely malleable end quote. Now, this is telling in the sense that of course, Steven Pinker is a very accomplished, renowned psychologist, cognitive scientist, so he is fixated very much on the individual, on the person moving about their day to day life.

### 12m

Now, the rules do not change so far as I'm concerned, of course. It's just that a person's individual reasoning in the individual day to day life is sometimes not something that is easily accessible to the average person. You are not readily able to understand your own thoughts. Okay. And that's why Popperian philosophy, Popperian epistemology is richer because we can all, all of us, objectively look at historic examples of what's going on in science and how knowledge was created there. How knowledge is created there is precisely how learning occurs in an individual person. How errors are corrected in science is how you go about correcting errors in your own life, moving around your own life. But it's useful to be able to talk about the common knowledge, the common knowledge we have of historic events. Historic philosophers, historic scientists, particular problems that are out there in the world that we can talk about these instances and examples of where the general abstract philosophy comes to bear on these things.

### 13m

If we begin to talk about these, yes, the interesting, quirky, somewhat humorous ideas that, you know, someone will stand on a scale in a way that minimizes their weight, well, if they are concerned about being overweight, yes, this is a thing that happens now. But these are not so interesting, I think, to me. I've written to some other people who are interested in epistemology and rationality. If you're interested in the peculiarities of human psychology, then yes, okay, okay. And this may be where Pink is coming from, but it just means that some of these examples are harder to talk about, and whether or not the conclusion is drawn about a particular individual person's irrationality generalizes to the broader case of rationality is another matter. I think that I can draw the conclusion that I can draw the conclusion that I can draw all the conclusions about what is happening in the philosophy of physics and extend that out to the philosophy of science more broadly and extend that out to reasoning more broadly

### 14m

because we can talk about these specific examples, but whether or not we can take one person's peccadilloes about standing on scales, okay, okay, that's a particular example, or procrastinating getting a medical test that might return an unwelcome result, yes, these are things that people do out of fear and emotion and that kind of thing. Okay. Okay. But the whole point of science and rationality is that we should aim to be taking away the emotion, distilling it out in some way, shape, or form, except for the curiosity, of course. We want to keep the curiosity there. What's going on, and many scientists and philosophers have made this point before, what's going on in science is we have a third-person approach to these things. It doesn't matter how people feel about stuff, but of course, psychology is very much focused on how. How people feel about stuff and trying to resolve particular individual problems, but that's not so much an objective science at the moment. It's not a precise objective science at the moment because it's about the contents of

### 15m

people's subjective minds. Let's just, anyway, go back to the book and just focus on what he says at the end of this particular paragraph, so it's worth reading that sentence again. Apologies to the reader. I'm going back. He says, quote, We teeter on the edge of the bathroom scale in a way that minimizes our weight, procrastinate getting a medical test that may return an unwelcome result, and try to believe that human nature is infinitely malleable, end quote. And that last bit there is just an unfortunate fallacy, especially from a psychologist and a renowned psychologist at that, someone who clearly does not understand universality. Now, perhaps universality is a... new idea, cutting-edge epistemology and psychology, perhaps, but it's true. We can understand anything that is understandable. We can understand any physical phenomena because any physical phenomena is computable, which

### 16m

explanations are a kind of computation. We can construct explanations about physical phenomena out there in the universe, and that includes ourselves. In other words, human nature is infinitely malleable. This is not a bias or a prejudice or an error. It simply is the case that it's infinitely malleable. Now, whether or not we can, as a matter of personal psychology, go about solving our problems and getting over our anti-rational memes, as we say here, well, that's another matter. But in principle, we're infinitely malleable. And to deny that we're infinitely malleable is just an error. It's a misconception. So we should, or believe, I don't like that word, okay? We should understand. That it simply is the case that our best explanation of what human minds can do is to be infinitely malleable, is to take on any problem and solve it, to become the kind of person that you want to. You are infinitely malleable, and it's a pessimistic idea, I would say, for a psychologist

### 17m

to be telling the reader that they can't do anything they like with their mind, but they can. But Professor Pinker, like so many others, the Brett Weinsteins of the world and other famous psychologists, I think Jordan Peterson endorses a version of this. It's a version of this idea, we inherit certain genes, and the genes are the things that cause us to behave in certain ways, and these things are just baked in to our psychology. And this is false. This is wrong. We can change our minds. It doesn't matter what the antecedents are of the ideas. The idea might be genetic. Okay, let's grant that. And I don't know if it's true, but let's grant that some ideas come from the DNA. Okay, they're implanted in there in the DNA, and they're fixed in the brain. And then... And then they're part of our mind. But the mind is not the brain. The mind can change itself. The mind is infinitely malleable. It doesn't matter what the genes say. After all, as David Deutsch has pointed out, we might all have genes for survival.

### 18m

Genes for, let's say, eating stuff. But people routinely go on diets and refuse to eat. People sadly commit suicide as well. So if we have these genes for survival and eating, how is it that we explain, that some people defy this genetic compulsion, this genetic requirement, this genetically determined behavior? Well, of course, I suppose the evolutionary psychologists come back and say, well, they've got a quirky gene. They've got a mutation. That determines that they do the opposite thing, which, of course, is, what do we say? A bad explanation. Because it can explain any sort of behavior. It can explain anything at all. Whereas we say, it's the memes and the ideas that explain people's behavior. And that's not true. That's not easily variable, because you need to talk about specific ideas. And by the way, no one's ever identified specific genes as causing specific ideas. So that's another matter. So let's keep going. This is a very slow process through this chapter.

### 19m

He then goes on to say, quote, There is a more rational way to reconcile our ignorance with our desires. The tool of reason called signal detection theory, or statistical decision theory. It combines the big ideas of the two preceding chapters, estimating the probability that something is true of the world, Bayesian reasoning, and deciding what to do about it by weighing its expected costs and benefits. Rational choice. End quote. Okay, so he's going to be relying upon the two pillars that are made entirely of misconceptions from the previous chapters. Bayesian reasoning, which is about a probabilistic assessment of your options, when usually you don't have that many options to assess. You either have one, and if you're lucky, you have two. And in case you can do a crucial test to figure out which one is to be refuted. And rational choice, which, as we've said before, we cannot have these fixed set of rules that determine what our most rational choice should be. Because rather often, the best choice to make is the one not yet.

### 20m

Let's create it, and we need to create that choice, we need to bring it into being. So it's not choosing among existing options, let alone weighing those options. It's creating new options, which are better than all the existing ones. And once you have that one that's better than all the existing ones, there's no role for weighting or Bayesian reasoning. You just do the best thing. You follow the good explanation, because all the others are bad explanations by the light of the existence of a solitary, single, good explanation. We're about to finish. We're about to see this in the next paragraph, where Pinker tries to conjure a bunch of examples, but the examples are too abstract. And when taken seriously and looked at carefully, we will see there's no role for Bayesian reasoning or rational choice theory. There's a role instead for what's the best explanation. So let's read what he has to say. Quote, The signal detection challenge is whether to treat some indicator as a genuine signal from the world

### 21m

or as noise in our imperfect perception of it. It's a recurring dilemma in life. A sentry sees a blip on a radar screen. Are we being attacked by nuclear bombers, or is it a flock of seagulls? End quote. So here's our first example from the supposed real world. So Pinker is going to, throughout this chapter, make a big deal of the historic origins of signal detection theory. And this is a quirk. This is a quirky kind of idea. Signal detection theory was invented, or arose, out of early use of radar in World War II. And the radar was primitive, and it had all sorts of problems. And in these early radar signals, you would have seen them in movies and so on and so forth, unless there are any actual radar operators out there listening to me. What happened was you had a series of concentric rings, and then there was a sweeping line that went around. And if the radar detected something, it would go beep, beep, and little dots would flash up on the screen, which would indicate something.

### 22m

It would indicate, Now, the question for signal detection is, well, are you detecting enemy aircraft, or are you detecting a flock of birds or something else? Okay, so do we generalize from this situation to the rest of physical reality and the rest of decision theory? It's rather like the idea of, well, Cardano invented the early versions of probability theory for figuring out the rules and how to win at games of chance and rolling dice and playing cards. Does that generalize? Does that generalize to the rest of physical reality? Or is it just a kind of useful mathematical tool sometimes? Is it, as David Deutsch has said, is it mistaking a misconception called signal detection theory with the real process of the same name? There might be a real process of the same name signal detection theory, which isn't really analogous to the problems had with early versions of radar. After all, today, what do you do?

### 23m

Well, you have multiple radars. There's checking of these things. There's various ways of correcting to see whether or not what's being detected on the radar really is what is being detected on the radar. Namely, you don't only use radar. These days, you can use satellite imagery and different wavelengths of light and sound and sonar and so on and so forth. One can imagine, with technology today, not having to worry about whether or not the radar has detected the right thing or not because you have multiple radars and you have multiple other systems doing the checking. But in any case, what we're after, and the point of the chapter is to figure out, are we seeing something in reality or is it noise? Is it a true signal or is it an error? Okay, that's a fair question. As Pinker asks, are we being attacked by nuclear bombers or is it a flock of seagulls? Okay, so his question there is a fair one, okay? But in real life, in real life, let's imagine, if this situation arises,

### 24m

do we only have one radar? Do we only have one radar picking up this stuff? Is radar today so insensitive, so imperfect, it would mistake a flock of seagulls for an incoming intercontinental ballistic missile? Is there satellite technology that makes the radar signal just one among many other different ways of imaging what's going on on the ground? Is there a reason we have for thinking the intercontinental ballistic missile is heading towards us? Or have we just detected something on the radar? Is the computer, the system that is able to interpret whatever the signals are from the radar, able to actually interpret things better than what a human can? Because these days, apparently, this is true of much technology, that the technology has actually got a better hit rate in being able to diagnose stuff than what a person can. Apparently, this happens in medicine now routinely, that the machine can detect the tumor, the existence of a tumor, more reliably than the radiologist or the radiographer can.

### 25m

And indeed, that's the next thing that Pinker says. He goes on to say, so this is the list of the problems. Quote, A radiologist sees a blob on a scan. Does the patient have cancer or is it a harmless cyst? End quote. So in that real-life situation, again, what are we going to do in real life? We're going to take multiple images and we're going to possibly use multiple instruments as well. Mistakes will still happen. But are we going to do statistical analysis? Are we really going to do that? Is that what's going? Is the radiologist and the doctor going to pull out the pocket calculator to try and figure out their confidence level using Bayesian reasoning as to whether or not the cancer is cancer or it's a harmless cyst? As far as I know, what goes on is you take a biopsy, you take a sample to figure it out before you start cutting a lot out of people. Pinker goes on, quote, A jury hears eyewitness testimony in a trial. Is the defendant guilty or did the witness misremember?

### 26m

We meet a person who seems vaguely familiar. Have we met her before? Or is it a free-floating pang of deja vu? A group of patients improves after taking a drug. Did the drug do anything or was it a placebo effect? End quote. All of these cases require us to have good explanations. And if we lack a good explanation, then we just don't know. We just don't know. And repeating our observations, our mistaken observations, doesn't help. As for the last one there, that's one really worth talking about. I'm lingering over for a moment. The question there was, did the drug do anything or was it a placebo effect? I was surprised in recent years by following the work of a Dr. Mark Crislop, who has a wonderful podcast. I used to listen to his podcast, QuackCast, quite regularly, where he would go into alternative therapies and the basis for these alternative therapies, whether they're reliable or not, things like acupuncture, things like homeopathy. Things we know didn't have much of a good explanation,

### 27m

behind them, let alone any studies that sort of suggest that they are efficacious at all. He has a whole bunch of podcasts, actually. But anyway, one of the blog posts I remember reading from him in a couple of his episodes was about how the placebo effect isn't even a real thing. There is no placebo effect. For almost any medicine you can think of, it has an objective effect on people or it does not. There is no placebo effect. Now, everyone thinks, of course, there's a placebo effect. You know, you... You can give someone a sugar pill and they feel better. But that's not what medicine is about, typically speaking. Okay? A person comes in and they've got dangerously high blood pressure. You give them a blood pressure tablet. You don't ask them, after the blood pressure tablet, how do you feel? Well, you might, of course, ask them how you feel. But the objective measure is you take their blood pressure. You take their blood pressure and you check to see, okay, has it fallen back down into a non-dangerous level? In which case, it doesn't matter whether the person says they feel good or don't feel good.

### 28m

Well, okay. If they don't feel good, that's a problem. But if they do feel good but the blood pressure is still high, it doesn't matter. There is no placebo effect. It hasn't caused the person's blood pressure to go down. Or consider a vaccine. Is there any such thing as the placebo effect from the vaccine? You give someone a fake vaccine and it prevents them from being infected by the virus? Of course not. An antibiotic is going to either kill the bacteria or not. Okay? There's no placebo effect here. But I know what people think. People think, well, okay. In some cases, you've got a mild headache and you're given a sugar pill and then you've got the placebo effect, okay? It helps you feel better. Well, again, that's a subjective measure, okay? And Mark Crislip points this out. If the placebo effect is nothing but just a subjective feeling, this isn't objective medicine, about which he's quite right, okay? If it's all about just making people feel a little bit better, then fine, okay. Call it what you like, but it's not a genuine, objective effect

### 29m

that you can measure in the world except by asking people survey questions. But this is typically not what you go to a doctor for. You want to go to the doctor to cure the disease or to prevent getting some disease, to remove the tumor. It's not merely about feeling better. I know that people talk in this way, but really what it's about is fixing the problem, curing the problem, which isn't always just about feeling better. There is no such thing as a placebo effect because the way that we think about that is we think about it as an infection for tumors, for broken legs and so on. So, in that sense, the drugs are known to either do something or not do something because you have an objective measure. The blood pressure changes, the infection is gone, and importantly, there's a mechanism of action known. Mechanism of action known. So, we know how the particular drugs

### 30m

the virus from ever taking hold in someone's body let's keep going and pinker writes quote the output of statistical decision theory is not a degree of credence but an actionable decision to have surgery or not to convict or acquit in coming down on one side or the other we are not deciding what to believe about the state of the world we're committing to an action in expectation of its likely costs and benefits end quote but are we really the output of statistical decision theory is not a degree of credence but an actionable decision to have surgery or not no this idea of to have surgery or not is not down to statistical decision theory it's down to a good explanation as to whether or not you need that surgical intervention or not the doctor may of course consult studies that say you know that that this particular procedure 90 of the time is effective or not but in general they don't need to because they're an expert in the field so they're they're performing an operation

### 31m

that they know works because they've done it x amount of times before and are expert in performing this particular operation they know they know that it works regardless of what the statistics are okay these things surely are published and so on and so forth but for an individual person a patient sitting in front of them we're not talking decision theory in this way we're talking about you have a tumor in your left arm we've got a few options here we've taken a biopsy the thing is malignant we can remove it surgically or you can have radiation therapy or you can have chemotherapy this is not a discussion about statistics the decision comes down to how to remove this tumor and what the best ways are and you are talking to a specific expert and you might get another opinion from another expert but in all cases they're giving you you want to hope they're giving you good explanations about what this thing is if if the second expert says oh dr so-and-so said it's a malignant cancer i think it's just a cyst well then you want a third opinion and you want a second opinion and you want a third opinion and you want a third opinion don't you and you personally want to see the results of the biopsy you want to see the

### 32m

pathology report about what this thing is and you're not going to take anyone's word for it and again it's not down to statistics to convict or acquit i would want to hope i would want to hope that if someone is accusing a person of a crime that it's not coming down to statistics it's coming down to a good explanation about whether or not the evidence is explained by this person having committed the crime or not and therefore to be convicted or not in which case acquitted again not statistics and no one on the jury should be thinking statistics they should be thinking do i have a good explanation about what's going on here never mind the statistics i don't know whether statistics would ever even come into this i don't know jurors who are again pulling out their pocket calculators drawing graphs and so on about the amount and preponderance of evidence they're talking about how the evidence is explained you best explained now the next section of this chapter is a quite long discussion about the normal distribution and what the normal distribution is it's kind of a primer i suppose for anyone who's

### 33m

never studied introductory statistics now as illuminating as this is and useful in some circumstances as it is i don't find it generally applicable to decision making or to explanation creativity anything like this there are situations where people are interested in the normal distribution statisticians and so on and so forth but in general it's not lawyers consulting statisticians it's not physicists consulting statisticians it's not doctors consulting statisticians it's not pilots consulting statisticians when problems need to be solved these are separate domains i remember when i myself taught mathematics and the mathematics of the normal distribution and we'd have things that we talked about like z scores and the standard deviation and whenever the

### 34m

textbook tried to conjure problems the examples that were used were always very abstract or at least very narrow in the possible ways in which they could be applied to real life scenarios in school-based and even university-based discussions the examples were always something like in a particular math test the average math score was very abstract and the average math score was very abstract and the average math score was 60 with a standard deviation of 15 john scores 82 in this particular exam what percentage of students did he perform better than in this particular test stuff like this these are the kind of examples where the normal distribution was deployed in order to provide information that was supposedly useful to a particular user of this kind of statistical data but how often is that kind of thing applicable to the problems of chemistry and physics and real life science and the legal system and what police or doctors do i don't know and therefore how often is

### 35m

it useful for people in making decisions actual decisions can pinker do anything with this kind of stuff well he spends quite a while explaining what the normal distribution is and i think because well he's a psychologist again and so he's not going to be able to do anything about it zwrou das music so look we're seeing normal distributions everywhere because we're studying people and people range across certain features where there's always an average that can be calculated in some way shape or form which apparently they're interested in this kind of thing and people like to know whether they're below the average or above the average so they're they're interested in this kind of thing and people like to know whether they're below the average or above the average so it's not a question of whether they're below the average or above the average in terms of height, intelligence, attractiveness, and so on and so forth. Let's see what is said in this part of the book about this stuff. He says, quote, how should we think about

### 36m

some erratic indicator of the state of the world? Begin with the concept of a statistical distribution. Suppose we measure something that varies unpredictably, a random variable, like scores on a test of introversion. From 0 to 100, we set the scores into bins, 0 to 9, 10 to 19, and so on, and we count the number of people who fall into each bin. Now we stack them into a histogram, a graph that differs from the usual ones we see in that the variable of interest is plotted along the horizontal axis rather than the vertical one, end quote. Okay, and so then he moves from the histogram way of representing things to, well, now imagine that we test several million people with this same test of so-called introversion. These tests always annoy me, by the way. It's like I used to say to my lecturers, and I think I might have mentioned this on the podcast before, if you gave me the survey in the morning, I'd get a particular score on the personality test. And then if you gave me the test in the middle of the day, I got a particular

### 37m

score. And then if you gave me the test on a Friday night, I got a different score. Still, people have moods. My personality, apparently, was widely changing, even though I think I'm a relatively stable person, which made me think, even at this stage, this was like first year university, encountering some early ideas about psychology, that this entire field just seemed to me to be grappling with something in the wrong way, trying to measure that which couldn't be measured. Exactly. Introversion is one such thing. What does it really mean? Anyway, so people can do a survey and they can score something. And if you survey a million such people, then what tends to happen is that you have this smooth distribution of variation when it comes to introversion. Only a very few people are very introverted. And only a very few people are highly extroverted. Most people are clustered near the middle, and so you have this normal distribution. Okay, the bell-shaped curve. Pinker makes a big deal about

### 38m

how common this bell-shaped curve is in reality. Okay, very well. He says of them, quote, these bell-shaped curves arise whenever a measurement is the sum of a large number of small causes, like many genes together with many environmental influences. And he goes on, quote, end quote. Well, is that quite right? Under the Popperian framework of looking at these things? Yes. Observations on whether or not something happened in the world, we only get that through our measurements, he says. Hmm. Observations are theory-laden. We get observations through

### 39m

our explanations of the observation process. It's not simply go out into the world and look or measure. We have to have a theory of how our measuring devices work or how our observation works and what we should be looking for. All of this stuff comes first. The theory comes first. And while it is true when he says that if you make a measurement, then if you repeat the measurement, he's sort of implying that here, then the measurement will cluster around the signal, the true value one should hope. But is that true? What we're getting there is increased precision of a particular measurement, but that does not mean we're getting actual accuracy of a particular measurement. Accuracy is what is the true value of what you're looking at? What is the reality? Now, you can't know the reality, and Pinker's quite right about that. We can't divine it perfectly. We're not God. But he may be misinterpreting what all this stuff is about. Confusing. Precision

### 40m

for accuracy. What do I mean? I've talked about this before. Let's say you want to measure the height of someone. And I think I've mentioned how I used to do this as a physics teacher. You can measure the height of students, and you can say to groups of students, hey, go and measure your height. Use whatever technique you want. Use rulers, whatever. And sometimes I would do the somewhat deceptive, for pedagogical reason, act of measuring someone really precisely over and over again, using rulers, using tape measures, using some sort of laser apparatus thing, taking a video, putting it onto a computer screen, and using the computer software to do a full measurement of this person's height, highly precisely, repeating the measurement over and over again. By the way, I've talked about this before. I've talked about this before. I've talked about this for anyone who hasn't done physics before, whether at school or university. This is one of the most boring things that physics students do. You would take some vernier calipers or perhaps a micrometer

### 41m

and measure very precisely something like the diameter of a metal sphere. Now, the curious thing is, if you get down to a highly precise measurement, that you repeat the measurement of exactly the same sphere using exactly the same instrument, and it often wouldn't come out exactly the same each time. That's a curious thing. Just about instruments and physics, and when you get down to really precise measurements, whatever the case. But let's say we're measuring the height of Mary in the classroom, and we've got her up the front of the class, and she's up against the wall, and we're trying to figure out how tall she is. And we get 10 different students to measure Mary's height. And they all tend to cluster around 161 centimeters, but not exactly. We've got some people who say it's 161.5. Someone who says it's 162.0, some people who say it's 160 centimeters. So we've got this range. But they're clustering around a particular value of about 161 centimeters tall. So do we

### 42m

conclude that the reality is 161 centimeters tall? That's the most precise measurement that we can have. And we can say something like 161 plus or minus 2 centimeters. centimeters okay so it's somewhere in that range of 161 plus 2 so 163 is the highest possible height she could have all the way down to 159 centimeters tall so she might be as short as that but she's somewhere in that range and we expect the expected value is right there in the middle of 161 centimeters tall so is she somewhere in that value well we don't know we can be as precise as we like and we can continue to repeat that measurement over and over again using all the fancy apparatus in the world clustering ever more closely to 161 centimeters maybe eventually after a million such measurements we end up with 161.025 centimeters tall we think we are highly precise

### 43m

and if you were to read explanations such as appear in this book rationality about how measurement is done you might think well now we're being very precise and we're being very precise and we're being very precise and we're being very precise accurate we're getting closer and closer to the truth but we might not be because there are different kinds of errors we can make in the world the error of how big the error bar is so to speak so when we say it's 161 plus or minus two centimeters we're talking there about the random error and the random error can be made smaller by simply repeating the experiment over and over again and making that smaller and smaller so instead of 161 plus or minus two centimeters a more precise reading would be 161 plus or minus one centimeter that would be a better reading a smaller margin of error so to speak as people call it however and here's the key here's the key for science this particular measurement might be completely inaccurate

### 44m

completely inaccurate way off and why because our methodology of measuring might be wrong our theory of measurement might be wrong our theory of observation might be wrong observations might be wrong our theory of measurement might be wrong our theory of measurements are theory laid and measurement is theory laid and evidence is theory laid and we need to understand the theory of what we're doing pretty well before we go around reporting with high confidence what we think is the truth and here when we're measuring mary's heart and we're saying it's 161 centimeters and we are very confident because we've been highly precise and we've been using lasers and repeated this experiment over and over again and in fact we've got fancy statistics that tell us that with the five sigma confidence level we can be sure because of the millions of repeat experiments we've done that her height is 161.025 centimeters or something like that you get my point i'm over egging it and i'm over egging it for a good reason and listeners to top cast will know what's coming next mary failed to take off her shoes and no one

### 45m

noticed that she didn't take off her shoes we never wanted the whole point of the experiment was to determine mary's height not mary's height plus shoes that wasn't the question there could be a thousand and one different ways in which mary's height is completely inaccurate because we failed to account for something no one thought of during the methodology namely if you want someone's height the first thing that you should do is ask them to remove their shoes and if you don't ask them to remove their shoes and they walk away later on and they throw those shoes away and you've got nothing but the record of this data the data is completely useless you can never correct it because you don't know how tall the shoes were so how can you know how tall mary is given just this data it's highly precise but completely inaccurate completely divorced from the truth because there's an error there that you never corrected you never knew about because your methodology was wrong you

### 46m

didn't understand your own theory of measuring something as simple as someone's height and this is just measuring the height of someone can you imagine what goes on in real life science well we know what goes on in real life science we know there's been errors in methodology we try as hard as we can to avoid those errors but we can't at times because this is what it means to make a systematic error a systematic error is an error with the methodology and if there's an error in the methodology that you aren't aware of and this can always be the situation always you can't guard against these things these are things these are phenomena that are going on in the background that you're not aware of yet perhaps you can't guard against these things because you can't guard against these things perhaps this is why you need to be careful and critical and never be certain that you're being accurate accuracy is a measurement of closeness to truth you can't know how close to the truth you are precisely for this reason that when you measure or observe something you don't know if

### 47m

there's an error not being made in the background something as trivial as the an analog to mary keeping her shoes on when her height is being measured and if she walks away and she takes her shoes off you can never correct it you can never correct it you can never correct it you can never here are my two preferred stories about that again listeners to talk cast would have heard these before both from physics one mentioned in the beginning of affinity and one that i've talked about because it was involving some lecturers of my own and the people that i looked up to and thought these are brilliant people and they are but they made a mistake and well this happens in science and in fact this was kind of a good mistake because it allowed them to develop special techniques of even though initially their conclusions were quite false the story is this researchers at the university of new south wales astrophysicists were pointing telescopes at the sky and measuring using spectroscopy the absorption of light from distant quasars as it traveled towards the earth

### 48m

and along the way passed through distant galaxies and as that light from those distant quasars passed through those galaxies it was absorbed by clouds of gas in those distant galaxies and when it arrived we were able to analyze it using our telescopes spectroscopes and computers now what these physicists did was something really interesting they looked at the distance between the absorption lines and the distance between the absorption lines tell us something about the what's known as the fine structure constant the fine structure constant is a dimensionless constant made up of other constants made up of the the the speed of light and Planck's constant and the charge on an electron so these things together in a certain fancy formula give you the fine structure constant a measurement of the force the strength of the force between the nucleus and the electrons so it's something to do with this electrostatic force now this is supposed to be

### 49m

constant throughout the entire universe it would be a great turn up for the books if we started finding differences in the value of this fine structure constant this is what they were looking for and this is what they were looking for they found they found a difference in distant galaxies the value of the fine structure constant in distant galaxies by analyzing the spectra of absorption light of the light that had been absorbed the absorption spectra when imaged by telescopes it's broken up by spectroscopes put into a computer and they carefully measured the distance between these lines these spectral absorption lines using the computer when compared with similar spectra in the laboratory there was a difference the fine structure constant was different in those distant galaxies which means it was different in the past and this different further away this was so exciting now at the time i was a much younger person and a more naive physicist i suppose and i thought aha this is

### 50m

you know evidence of something like seeing other universes perhaps we're able to see a place where the laws of physics were subtly changing and if you could look even further the fine structure constant was different in those distant galaxies which means it was different in the past and this would be different again more different the further you looked the more different the fine structure constant would be and of course these physicists repeated the experiment over and over and over again and they had other people checking their results over and over and over again they were using the keck telescopes they were using fancy stuff these people were from prestigious universities they understood what they were doing or did they because although they published many papers and they got a lot of publicity and prestigious not only science journals but also popular science magazines it was an exciting time of thinking the fine structure constant might not be a constant these constants of nature might very well vary across the universe it had long been thought that perhaps the value of g the universal gravitational

### 51m

constant could be different in different parts of the universe there was no theory there was no theory about why it should be but hey maybe we could measure this and this would be an interesting this would be a problem in the popperian sense it would be a problem to be it shouldn't be regarded as a refutation of the claim that the constants really are constants because what do we say when we make a measurement like this either yeah the constants might in fact be varying or there's a problem with the measurement there's been a systematic error made somewhere and yes that's the punch line it took them many years to correct the error but another team did they figured out what was wrong something to do with the mirror of the keck reflecting telescope they weren't calibrated properly or there was an insufficient understanding of the actual telescope itself and how it was making the measurements that it made making the observations that it made and so all of this talk about seeing far distant reaches of the universe and

### 52m

peering into possibly other universes other regions of space obeying different physical laws disappeared vanished into a puff of systematic error and so it wasn't true and so now although these visitors did indeed develop a precise technique for making these kind of measurements they didn't actually measure what they thought they'd measured and what would have been the exciting kind of measurement so all the statistical analysis in the world that they did quoting how confident they were because they'd repeated the same experiment over and over again getting the same result over and over again meaning they become statistically more confident they quote sigma levels and high sigma levels at that was highly precise but completely inaccurate it was wrong there fine structure constant was not changing now a similar thing happened and was reported in the beginning of infinity david deutsch talks about the occasion where

### 53m

it was said at the large hadron collider certain experiments had shown that neutrinos were traveling faster than light in violation einsteins theory of special relativity nothing no matter can be done about this nothing no matter can be done about this nothing no matter can be done about this can go faster than the speed of light or at least if it's traveling at sub light speed it should never at any point travel at the speed of light but here when you treat us which have mass however small traveling beyond the speed of light apparently and many reported the time okay the the popular science was saying einstein proved wrong you know they're the the classic headline comes through in these situations where of course the correct headline is problem for physicists what's going on here maybe just maybe or just maybe general relativity and special relatively have a problem which just maybe this experiment contained within a mistake in the methodology a systematic takes a long time to try to get a normal man of repeating the experiment over and

### 54m

over getting getting the same results ever going to correct a problem with the methodology you don't know that is a problem with the methodology unless some clever person comes along and points out what's wrong with your methodology so it's not that extraordinary claim that we've made and we've come out of it as a Об dangling extraordinary claims require extraordinary evidence. It's that extraordinary claims require extraordinary explanations behind them. This is the key. It's not about just repeating your experiment over and over again and collecting this astonishing, amazing evidence. It's about being able to account for this astonishing evidence with an astonishing explanation of what's going on, or perhaps a mundane explanation. But you need a good explanation of why it is that this long-standing good explanation of physical reality is now being pushed aside for something better. Evidence alone won't do that. You need an explanation of the evidence. Evidence that contradicts a good explanation does not refute the good explanation, does not successfully refute

### 55m

the good explanation. It's merely a problem to be explained. And so, this is one of the difficulties here with this book, Rationality. I don't think it quite grapples with precisely that. This discussion of signal and noise, it kind of talks about, okay, well, you're seeing a signal, but is the signal really telling you, even if you're repeatedly getting the signal, is that telling you something true about reality? Or is it telling you that, in fact, something about your methodology has gone wrong? After all, in the two examples I gave, the signal was extremely strong, extremely strong, that the fine structure constant was varying throughout the universe. The signal was extremely strong that neutrinos were traveling faster than light. And repeating the observations over and over again and getting a cluster of measurements with a binomial distribution that showed that there was a signal didn't matter, ultimately, because

### 56m

the methodology was wrong. And how do you know your methodology is wrong? That is a harder question. And that is something that I'm going to have to come back to next episode, because I think we've talked for long enough about just a few pages here into this particular chapter, all about hits and false alarms. Because the false alarm about whether or not your cherished theory has actually been refuted by a strong signal doesn't come down to how strong the signal is. It comes down to what your explanation is. What your explanation of the signal is. And this is missing, I think, from this chapter. And we'll see more of that as we move throughout the chapter. But for now, we've talked enough about this. Until next time, bye-bye.

